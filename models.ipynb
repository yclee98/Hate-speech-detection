{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum text\n",
    "# sb.set()\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    counter = 0\n",
    "    for i in text:\n",
    "        counter += len(i.split())\n",
    "    return counter\n",
    "\n",
    "def count_token(text):\n",
    "    s = set()\n",
    "    for i in text:\n",
    "        tokenize = i.split()\n",
    "        for j in tokenize:\n",
    "            s.add(j)    \n",
    "    return len(s)\n",
    "\n",
    "\n",
    "def load_dataset(ds, opt=2):\n",
    "    if ds == 1:\n",
    "        dataset_name = \"GabHateCorpus\"\n",
    "    elif ds == 2:\n",
    "        dataset_name = \"Implicit_hate_corpus\"\n",
    "    elif ds == 3:\n",
    "        dataset_name = \"SE2019\"\n",
    "    else:\n",
    "        dataset_name = \"Balanced\"\n",
    "\n",
    "    filepath = \"Dataset/\"+dataset_name\n",
    "    if opt==1:\n",
    "        df = pd.read_csv(filepath+\"/data_processed.csv\")\n",
    "    elif opt==2:\n",
    "        df = pd.read_csv(filepath+\"/data_processed2.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(filepath+\"/data_needed.csv\")\n",
    "    print(df['class'].value_counts(normalize=True))\n",
    "    return df, dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Hate        0.5\n",
      "Non-Hate    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82692"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, ds_name = load_dataset(4,3)\n",
    "count_token(df['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34002 entries, 0 to 34001\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   34002 non-null  object\n",
      " 1   text    34002 non-null  object\n",
      " 2   hate    34002 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 797.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Hate</td>\n",
       "      <td>feminsts sjws gets owned cringe compilation co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate</td>\n",
       "      <td>hey fellow whites sit let lecture terrible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Hate</td>\n",
       "      <td>evolved potential currency asset soon become r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate</td>\n",
       "      <td>mil milstalin milhitler milmao milpolpot miln ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate</td>\n",
       "      <td>liberalism mental disorder much dangerous thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text  hate\n",
       "0  Non-Hate  feminsts sjws gets owned cringe compilation co...     0\n",
       "1      Hate         hey fellow whites sit let lecture terrible     1\n",
       "2  Non-Hate  evolved potential currency asset soon become r...     0\n",
       "3      Hate  mil milstalin milhitler milmao milpolpot miln ...     1\n",
       "4      Hate  liberalism mental disorder much dangerous thou...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, text, hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 12974\n"
     ]
    }
   ],
   "source": [
    "filepath = \"Dataset/SE2019/\"\n",
    "df_need = pd.read_csv(filepath+\"data_needed.csv\")\n",
    "df_processed = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "print(len(df_need), len(df_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_need = np.array(df_need[\"text\"])\n",
    "text_processed = np.array(df_processed[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "need:  281058\n",
      "pro:  156009\n",
      "token\n",
      "need:  53046\n",
      "pro:  22855\n"
     ]
    }
   ],
   "source": [
    "print(\"word\")\n",
    "print(\"need: \", count_words(text_need))\n",
    "print(\"pro: \", count_words(text_processed))\n",
    "\n",
    "print(\"token\")\n",
    "print(\"need: \", count_token(text_need))\n",
    "print(\"pro: \", count_token(text_processed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    test_size = 0.20\n",
    "    x = np.array(df[\"text\"])\n",
    "    y = np.array(df[\"class\"])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = test_size, random_state=42) #random state ensure same sample\n",
    "    print(\"Train Set :\", x_train.shape, y_train.shape) \n",
    "    print(\"Test Set  :\", x_test.shape, y_test.shape) \n",
    "    print(\"Total \", len(df))\n",
    "    # y in digit form\n",
    "    y_train_binary = np.array(list(map(lambda x:1 if x==\"Hate\" else 0, y_train)))\n",
    "    y_test_binary = np.array(list(map(lambda x:1 if x==\"Hate\" else 0, y_test)))\n",
    "    return x_train, y_train, y_train_binary, x_test, y_test, y_test_binary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering - Word embeding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "- CountVectorizer, Tfidftransformer & Tfidfvectorizer are Frequency based Word Embedding technique\n",
    "- Tfidftransformer acts on sparse matrix and Tfidfvectorizer acts on raw text data\n",
    "- Tfidfvectorizer = countVectorizater + Tfidftransformer\n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/\n",
    "- vectorizer = word embedding process of converting text data to numerical vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#:~:text=Word2Vec%20is%20a%20popular%20algorithm,a%20large%20corpus%20of%20text\n",
    "- Word2vec is not a single algorithm but a combination of two techniques – CBOW(Continuous bag of words) and Skip-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2vVectorizer():\n",
    "    def __init__(self) -> None:\n",
    "        self.w2v_model = None\n",
    "    \n",
    "    def w2v_vectorizer(self,sentence):\n",
    "        # vectorize the text data\n",
    "        words = sentence.split()\n",
    "        words_vec = [self.w2v_model.wv[word] for word in words if word in self.w2v_model.wv]\n",
    "        if len(words_vec) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vec = np.array(words_vec)\n",
    "        return words_vec.mean(axis=0)\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        # train the model when fit the pipeline\n",
    "        sentences = [sentence.split() for sentence in x]\n",
    "        self.w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        # when use fit or transform on the pipeline \n",
    "        return np.array([self.w2v_vectorizer(sentence) for sentence in x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(model, model_name):\n",
    "    filename = f\"models/{model_name}.pickle\"\n",
    "    pickle.dump(model, open(filename,\"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert given text to a vector base\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- supervisied learning algorithm\n",
    "- Unlike neural networks, SVMs can work with very small datasets and are not prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "model_name = \"svm\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "              ])\n",
    "model_name = \"svm-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "               ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "              ])\n",
    "model_name = \"svm-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict data\n",
    "print(\"Test Data Accuracy  :\\t\", model.score(x_test, y_test))\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow gpu \n",
    "- https://www.tensorflow.org/install/pip#windows-native\n",
    "- https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=oWo9SNcyxlI\n",
    "- good read for = https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-022-01665-y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding\n",
    "from keras.layers import Conv1D, LSTM, SpatialDropout1D, Bidirectional, GRU, SimpleRNN, TextVectorization\n",
    "\n",
    "from keras.metrics import BinaryAccuracy,Precision,Recall\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models import FastText, Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        super(TimingCallback, self).__init__()\n",
    "\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self.starttime = time.time()\n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        self.stoptime = time.time()\n",
    "        print(f\"training time {self.stoptime - self.starttime}\")\n",
    "        \n",
    "METRICS = [\n",
    "    BinaryAccuracy(name=\"accuracy\"),\n",
    "    Precision(name=\"precision\"),\n",
    "    Recall(name=\"recall\")\n",
    "]\n",
    "\n",
    "def get_classification_report(i, cr):\n",
    "    return [i, cr['accuracy'], cr['macro avg']['precision'], \n",
    "            cr['macro avg']['recall'], cr['macro avg']['f1-score'],\n",
    "            cr['Hate']['f1-score'],cr['Non-Hate']['f1-score'], \n",
    "            cr['Hate']['support'],cr['Non-Hate']['support']]\n",
    "\n",
    "def get_result_table():\n",
    "    c = ['Model', 'Accuracy', 'precision', 'recall', 'f1-score', 'hate f1', \"non-hate f1\", 'hate support', 'non-hate support']\n",
    "    result_table = pd.DataFrame(columns=c)\n",
    "    return result_table\n",
    "\n",
    "def get_result_single(y_test, y_test_pred, model_name, result_table):\n",
    "    # c = ['Model', 'Accuracy', 'precision', 'recall', 'f1-score', 'hate f1', \"non-hate f1\", 'hate support', 'non-hate support']\n",
    "    # result_table = pd.DataFrame(columns=c)\n",
    "\n",
    "    cr = classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"], output_dict=True)\n",
    "    result_table.loc[len(result_table)] = get_classification_report(model_name, cr)\n",
    "    # return result_table\n",
    "\n",
    "def get_result_multiple(x_test, y_test, model_to_load):\n",
    "    c = ['Model', 'Accuracy', 'precision', 'recall', 'f1-score', 'hate f1', \"non-hate f1\", 'hate support', 'non-hate support']\n",
    "    result_table = pd.DataFrame(columns=c)\n",
    "    for i in model_to_load:\n",
    "        filename = f\"models/{i}\"\n",
    "        print(filename)\n",
    "        old_model = load_model(filename)\n",
    "\n",
    "        y_test_pred = old_model.predict(x_test, verbose=0)\n",
    "        y_test_pred = np.where(y_test_pred > 0.5, \"Hate\", \"Non-Hate\") \n",
    "        y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "        cr = classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"], output_dict=True)\n",
    "        result_table.loc[len(result_table)] = get_classification_report(i, cr)\n",
    "    return result_table.style.highlight_max(color = 'red', axis = 0)\n",
    "\n",
    "def nn_predict(model,x_test, y_test_binary):\n",
    "    score = model.evaluate(x_test, y_test_binary, verbose=0)\n",
    "    print(\"Score: \", score[0])\n",
    "    print(\"Accuracy: \", score[1])\n",
    "\n",
    "    y_test_pred_percent = model.predict(x_test, verbose=0)\n",
    "    y_test_pred = np.where(y_test_pred_percent > 0.5, \"Hate\", \"Non-Hate\") \n",
    "    y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "    return y_test_pred\n",
    "\n",
    "def save_model_nn(model, model_name, embedding_name, dataset_name):\n",
    "    filename = f\"models/{dataset_name}_{embedding_name}_{model_name}\"\n",
    "    model.save(filename)\n",
    "    return filename\n",
    "\n",
    "def load_model_nn(model_name):\n",
    "    filename = f\"models/{model_name}\"\n",
    "    print(filename)\n",
    "    return load_model(filename) \n",
    "\n",
    "def compile_fit_save(x_train, y_train_binary, x_test,y_test_binary, model, model_name, embedding_name, dataset_name, save, epoch=5, batch_size=32, lr=0.01):    \n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)\n",
    "    \n",
    "    history = model.fit(x_train, y_train_binary, epochs=epoch,\n",
    "                        validation_data=(x_test,y_test_binary),\n",
    "                        batch_size = batch_size,\n",
    "                        callbacks=[TimingCallback()])\n",
    "\n",
    "    if save: \n",
    "        save_model_nn(model, model_name, embedding_name, dataset_name)        \n",
    "    print(f\"acc {history.history['val_accuracy'][0]}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n",
      "Keras Version: 2.10.0\n",
      "GPU is available\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_em(x_train):\n",
    "    embedding_name = \"glove\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    # load glove to dictionay\n",
    "    embeddings_dic = dict()\n",
    "    glove_file = open(\"Dataset/trained/glove.42B.300d.txt\", encoding=\"utf8\")\n",
    "\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dic[word] = vector_dimensions\n",
    "    glove_file.close()\n",
    "    print(\"Total words \", len(embeddings_dic))\n",
    "\n",
    "    # create vocab length is the size of token in dictionary\n",
    "    # Size of the vocabulary\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = 300 #each glove word is 100 long\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "    missWord = []\n",
    "\n",
    "    # create embedding matrix having 100 col\n",
    "    # for all vocab word we give it a vector value from glove\n",
    "    # for those not found in glove will be empty 0\n",
    "    # size of embedding_matriz = size of word_tokenizer.word_index.items()\n",
    "    # embedding_matrix is the weight \n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        embedding_vector = embeddings_dic.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "            missWord.append(word)\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    \n",
    "    return custom_encoder, custom_embedding, embedding_name, missWord"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText + word2vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/@93Kryptonian/word-embedding-using-fasttext-62beb0209db9\n",
    "- It treats each word as composed of n-grams. In word2vec each word is represented as a bag of words but in FastText each word is represented as a bag of character n-gram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_model():\n",
    "    model_name=\"fasttext_trained\"\n",
    "    return KeyedVectors.load_word2vec_format(\"./Dataset/trained/wiki-news-300d-1M-subword.vec\", binary=False), model_name\n",
    "\n",
    "def get_word2vec_model():\n",
    "    model_name = \"word2vec_trained\"\n",
    "    return KeyedVectors.load_word2vec_format(\"./Dataset/trained/GoogleNews-vectors-negative300.bin\", binary=True), model_name\n",
    "\n",
    "def pre_trained_em(x_train, model_em, embedding_name):\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = 300 \n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "    missWord = []\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    keyVector_key = model_em.index_to_key\n",
    "    print(f\"total vector {len(keyVector_key)}\")\n",
    "    for word, index in vocab_dict.items():\n",
    "        if word in keyVector_key:\n",
    "            embedding_vector = np.array(model_em[word])\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[index] = embedding_vector\n",
    "                hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "            missWord.append(word)\n",
    "            \n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    \n",
    "    return custom_encoder, custom_embedding, embedding_name, missWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = dict()\n",
    "glove_file = open(\"Dataset/trained/glove.42B.300d.txt\", encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    m2[word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_word2vec_model()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61790377]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men = m['hate']\n",
    "women = m['detest']\n",
    "cosine_similarity(men.reshape(1,-1), women.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5600246]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7674937"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity(\"men\", \"women\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_em(x_train):\n",
    "    embedding_name = \"fasttext\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size=100\n",
    "\n",
    "    sentences = [sentence.split() for sentence in x_train]\n",
    "    ft_model = FastText(sentences, vector_size=vector_size, window=5, min_count=2, workers=4, seed=42, sg=1, epochs=10) # skip gram or cbow=0\n",
    "    ft = ft_model.wv\n",
    "    ft_vocab = ft.index_to_key\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "        vocabulary = ft_vocab\n",
    "    )\n",
    "\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        embedding_vector = ft[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_em(x_train):\n",
    "    embedding_name = \"word2vec\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size=100\n",
    "\n",
    "    sentences = [sentence.split() for sentence in x_train]\n",
    "    w_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4, seed=42, sg=1, epochs=10)\n",
    "    w = w_model.wv\n",
    "    w_vocab = w.index_to_key\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "        vocabulary = w_vocab\n",
    "    )\n",
    "\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        if word in w.key_to_index:\n",
    "            embedding_vector = w[word]\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[index] = embedding_vector\n",
    "                hits += 1\n",
    "            else:\n",
    "                print(word)\n",
    "                miss +=1\n",
    "        else:\n",
    "            print(word)\n",
    "            miss +=1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test without pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noTrained_em(x_train):\n",
    "    embedding_name = \"no_train\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size= 300\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_connected_layer(model):\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"cnn\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    add_connected_layer(model)\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n",
    "\n",
    "def rnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"rnn\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(SimpleRNN(128))\n",
    "    add_connected_layer(model)\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n",
    "\n",
    "def lstm(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"lstm\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    # model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    add_connected_layer(model)\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n",
    "\n",
    "def gru(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"gru\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    # model.add(SpatialDropout1D(0.2))\n",
    "    model.add(GRU(128))\n",
    "    add_connected_layer(model)\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GOOD = https://medium.com/mlearning-ai/the-classification-of-text-messages-using-lstm-bi-lstm-and-gru-f79b207f90ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"lstm\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    # model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    add_connected_layer(model)\n",
    "\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm(custom_encoder, custom_embedding, embedding_name):\n",
    "    print(\"bilstm\")\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(x_train, y_train_binary, epochs=10,\n",
    "                        validation_data=(x_test,y_test_binary))\n",
    "\n",
    "    save_model_nn(model, \"bilstm\", embedding_name, dataset_name)\n",
    "    print(f\"acc {history.history['val_accuracy'][0]}\")\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"gru\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    # model.add(SpatialDropout1D(0.2))\n",
    "    model.add(GRU(128))\n",
    "    add_connected_layer(model)\n",
    "\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/text/tutorials/text_classification_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name, save = True, epoch = 10, batch_size=32, lr=0.01):\n",
    "    model_name = \"rnn\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(SimpleRNN(128))\n",
    "    add_connected_layer(model)\n",
    "\n",
    "    return compile_fit_save(x_train, y_train_binary, x_test,y_test_binary,model, model_name, embedding_name, dataset_name, save, epoch, batch_size, lr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gpt word embedding and bert\n",
    "- based on transformer architecture\n",
    "- uses deep learning for word embedding \n",
    "- Yes, transformer-based word embeddings are a form of deep learning. The transformer model architecture, which is the foundation of transformer-based word embeddings, is a deep learning architecture widely used in natural language processing (NLP) tasks.\n",
    "- transformer-based word embeddings are a type of deep learning technique that utilizes the power of deep neural networks to learn contextually rich representations of words or tokens in natural language text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPT-2 belongs to a family of deep learning models called “Transformers”. Transformers are the building block of the current state-of-the-art NLP architecture\n",
    "- A typical transformers design contains two parts, encoder and decoders, both working as vectorized representation of word relationships.\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb\n",
    "- can do through fine tunning or word embedding \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tuining "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://platform.openai.com/docs/api-reference/fine-tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SE2019'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17182\n",
      "4296\n"
     ]
    }
   ],
   "source": [
    "# dataset for gpt\n",
    "df_gpt = pd.DataFrame(zip(x_train,y_train_binary), columns = ['prompt', 'completion'])\n",
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_train.jsonl\", orient='records', lines=True)\n",
    "print(len(df_gpt))\n",
    "\n",
    "df_gpt = pd.DataFrame(zip(x_test,y_test_binary), columns = ['prompt', 'completion'])\n",
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_test.jsonl\", orient='records', lines=True)\n",
    "print(len(df_gpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai tools fine_tunes.prepare_data -f Dataset/Implicit_hate_corpus/gpt_data_train.jsonl\n",
      "openai tools fine_tunes.prepare_data -f Dataset/Implicit_hate_corpus/gpt_data_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset for fine tune do in cmd\n",
    "print(f\"openai tools fine_tunes.prepare_data -f Dataset/{dataset_name}/gpt_data_train.jsonl\")\n",
    "print(f\"openai tools fine_tunes.prepare_data -f Dataset/{dataset_name}/gpt_data_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-cxPIEDLcM27LxmNHvyTaApFk uploaded\n",
      "file-0hSnroAPuDSU8iiCFwTAzaLk uploaded\n"
     ]
    }
   ],
   "source": [
    "# upload file to openai and create fine tune model\n",
    "train_create_output = openai.File.create(\n",
    "  file=open(f\"Dataset/{dataset_name}/gpt_data_train_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_train_id = train_create_output.get('id')\n",
    "print(file_train_id, train_create_output.get('status'))\n",
    "\n",
    "test_create_output = openai.File.create(\n",
    "  file=open(f\"Dataset/{dataset_name}/gpt_data_test_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_test_id = test_create_output.get('id')\n",
    "print(file_test_id, test_create_output.get('status'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft-j51edHpwX7ZfLBe3GRrXKnDT\n"
     ]
    }
   ],
   "source": [
    "fine_tune_create_output = openai.FineTune.create(training_file =file_train_id,\n",
    "                       validation_file=file_test_id,\n",
    "                       model = \"ada\",\n",
    "                       compute_classification_metrics = True,\n",
    "                       classification_positive_class = \" 0\"\n",
    "                       )\n",
    "fine_tune_id = fine_tune_create_output.get('id')\n",
    "print(fine_tune_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft-VwKO2vWcNtBJrPoZorUtFTVV succeeded ada:ft-personal-2023-06-26-14-43-42\n",
      "ft-LAcA6GtvgJ0lksqRT8jwtzSx succeeded ada:ft-personal-2023-06-26-17-27-28\n",
      "ft-XGDLqYtbnvM9gy4Mrm8AWGay cancelled None\n",
      "ft-g85PjO2OHcdlpGjn53IPW3Ed succeeded ada:ft-personal-2023-08-01-08-11-24\n",
      "ft-WNSM4A5PrnGNMJOBLcy9SFSY succeeded ada:ft-personal-2023-08-04-09-17-15\n",
      "ft-j51edHpwX7ZfLBe3GRrXKnDT succeeded ada:ft-personal-2023-08-04-20-03-44\n"
     ]
    }
   ],
   "source": [
    "# fine tune list\n",
    "all_finetune = openai.FineTune.list()\n",
    "all_finetune_data = all_finetune.get('data')\n",
    "for i in range(len(all_finetune_data)):\n",
    "    print(all_finetune_data[i].get('id'), all_finetune_data[i].get('status'), all_finetune_data[i].get('fine_tuned_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ada:ft-personal-2023-08-01-08-11-24\",\n",
      "  \"object\": \"model\",\n",
      "  \"created\": 1690877485,\n",
      "  \"owned_by\": \"user-g61vq7zfiw7gw7twk60losib\",\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"id\": \"snapperm-4nfXiuUpIdcrwXWgqZt0Th1J\",\n",
      "      \"object\": \"model_permission\",\n",
      "      \"created\": 1690877485,\n",
      "      \"allow_create_engine\": true,\n",
      "      \"allow_sampling\": true,\n",
      "      \"allow_logprobs\": true,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": true,\n",
      "      \"allow_fine_tuning\": true,\n",
      "      \"organization\": \"org-57m2RCBaIU5pd9nsTDikjeLg\",\n",
      "      \"group\": null,\n",
      "      \"is_blocking\": false\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"ada:2020-05-03\",\n",
      "  \"parent\": \"ada:2020-05-03\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada:ft-personal-2023-08-04-20-03-44\",\n",
      "  \"object\": \"model\",\n",
      "  \"created\": 1691179424,\n",
      "  \"owned_by\": \"user-g61vq7zfiw7gw7twk60losib\",\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"id\": \"snapperm-31KeDobwaofIYMANJBkJRTeP\",\n",
      "      \"object\": \"model_permission\",\n",
      "      \"created\": 1691179424,\n",
      "      \"allow_create_engine\": true,\n",
      "      \"allow_sampling\": true,\n",
      "      \"allow_logprobs\": true,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": true,\n",
      "      \"allow_fine_tuning\": true,\n",
      "      \"organization\": \"org-57m2RCBaIU5pd9nsTDikjeLg\",\n",
      "      \"group\": null,\n",
      "      \"is_blocking\": false\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"ada:2020-05-03\",\n",
      "  \"parent\": \"ada:2020-05-03\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada:ft-personal-2023-08-04-09-17-15\",\n",
      "  \"object\": \"model\",\n",
      "  \"created\": 1691140635,\n",
      "  \"owned_by\": \"user-g61vq7zfiw7gw7twk60losib\",\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"id\": \"snapperm-ZlfTiBt3ZhUPsNPuvQvFZtFu\",\n",
      "      \"object\": \"model_permission\",\n",
      "      \"created\": 1691140635,\n",
      "      \"allow_create_engine\": true,\n",
      "      \"allow_sampling\": true,\n",
      "      \"allow_logprobs\": true,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": true,\n",
      "      \"allow_fine_tuning\": true,\n",
      "      \"organization\": \"org-57m2RCBaIU5pd9nsTDikjeLg\",\n",
      "      \"group\": null,\n",
      "      \"is_blocking\": false\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"ada:2020-05-03\",\n",
      "  \"parent\": \"ada:2020-05-03\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model list\n",
    "all_models = openai.Model.list()\n",
    "all_models_data = all_models.get('data')\n",
    "owned_by_list = ['openai','openai-dev', 'openai-internal']\n",
    "for i in range(len(all_models_data)):\n",
    "    if all_models_data[i].get('owned_by') not in owned_by_list:\n",
    "        print(all_models_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=ada:ft-personal-2023-06-26-17-27-28 at 0x2153fc084f0> JSON: {\n",
       "  \"id\": \"ada:ft-personal-2023-06-26-17-27-28\",\n",
       "  \"object\": \"model\",\n",
       "  \"deleted\": true\n",
       "}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_id = \"ft-j51edHpwX7ZfLBe3GRrXKnDT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_output = openai.FineTune.retrieve(id=fine_tune_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-j51edHpwX7ZfLBe3GRrXKnDT at 0x1c0f3b0a200> JSON: {\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"id\": \"ft-j51edHpwX7ZfLBe3GRrXKnDT\",\n",
       "  \"hyperparams\": {\n",
       "    \"n_epochs\": 4,\n",
       "    \"batch_size\": 32,\n",
       "    \"prompt_loss_weight\": 0.01,\n",
       "    \"learning_rate_multiplier\": 0.1,\n",
       "    \"classification_positive_class\": \" 0\",\n",
       "    \"compute_classification_metrics\": true\n",
       "  },\n",
       "  \"organization_id\": \"org-57m2RCBaIU5pd9nsTDikjeLg\",\n",
       "  \"model\": \"ada\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-cxPIEDLcM27LxmNHvyTaApFk\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 2285703,\n",
       "      \"created_at\": 1691169517,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"validation_files\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-0hSnroAPuDSU8iiCFwTAzaLk\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"filename\": \"file\",\n",
       "      \"bytes\": 535182,\n",
       "      \"created_at\": 1691169519,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"object\": \"file\",\n",
       "      \"id\": \"file-AXj8W44wfdgrfGtoofhXad4X\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"bytes\": 140189,\n",
       "      \"created_at\": 1691179425,\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"created_at\": 1691169531,\n",
       "  \"updated_at\": 1691179425,\n",
       "  \"status\": \"succeeded\",\n",
       "  \"fine_tuned_model\": \"ada:ft-personal-2023-08-04-20-03-44\",\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-j51edHpwX7ZfLBe3GRrXKnDT\",\n",
       "      \"created_at\": 1691169531\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune costs $0.71\",\n",
       "      \"created_at\": 1691177960\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued. Queue number: 4\",\n",
       "      \"created_at\": 1691177960\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 3\",\n",
       "      \"created_at\": 1691178148\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
       "      \"created_at\": 1691178194\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
       "      \"created_at\": 1691178207\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
       "      \"created_at\": 1691178209\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"created_at\": 1691178229\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/4\",\n",
       "      \"created_at\": 1691178478\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 2/4\",\n",
       "      \"created_at\": 1691178769\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 4/4\",\n",
       "      \"created_at\": 1691179343\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: ada:ft-personal-2023-08-04-20-03-44\",\n",
       "      \"created_at\": 1691179424\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-AXj8W44wfdgrfGtoofhXad4X\",\n",
       "      \"created_at\": 1691179425\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"created_at\": 1691179425\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded ada:ft-personal-2023-08-04-20-03-44\n"
     ]
    }
   ],
   "source": [
    "if retrieve_output.get(\"status\") == \"succeeded\":\n",
    "    model_id = retrieve_output.get('fine_tuned_model')\n",
    "    print(\"succeeded\", model_id)\n",
    "else:\n",
    "    print(retrieve_output.get(\"status\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x209db1dfb00> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-WNSM4A5PrnGNMJOBLcy9SFSY\",\n",
       "      \"created_at\": 1691130661\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune costs $0.61\",\n",
       "      \"created_at\": 1691138888\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued. Queue number: 3\",\n",
       "      \"created_at\": 1691138888\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
       "      \"created_at\": 1691138896\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
       "      \"created_at\": 1691139081\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
       "      \"created_at\": 1691139083\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"created_at\": 1691139147\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/4\",\n",
       "      \"created_at\": 1691139454\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 3/4\",\n",
       "      \"created_at\": 1691140180\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: ada:ft-personal-2023-08-04-09-17-15\",\n",
       "      \"created_at\": 1691140635\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-ap2NF83oov7SNzKbbIlAqXzk\",\n",
       "      \"created_at\": 1691140636\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"created_at\": 1691140637\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTune.list_events(id=fine_tune_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai api fine_tunes.results -i ft-g85PjO2OHcdlpGjn53IPW3Ed > result.csv\n"
     ]
    }
   ],
   "source": [
    "# get result of model\n",
    "print(f\"openai api fine_tunes.results -i {fine_tune_id} > result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>elapsed_tokens</th>\n",
       "      <th>elapsed_examples</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_sequence_accuracy</th>\n",
       "      <th>training_token_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_sequence_accuracy</th>\n",
       "      <th>validation_token_accuracy</th>\n",
       "      <th>classification/accuracy</th>\n",
       "      <th>classification/precision</th>\n",
       "      <th>classification/recall</th>\n",
       "      <th>classification/auroc</th>\n",
       "      <th>classification/auprc</th>\n",
       "      <th>classification/f1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>3138</td>\n",
       "      <td>1017808</td>\n",
       "      <td>25104</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.837239</td>\n",
       "      <td>0.844728</td>\n",
       "      <td>0.890362</td>\n",
       "      <td>0.914601</td>\n",
       "      <td>0.840967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  elapsed_tokens  elapsed_examples  training_loss   \n",
       "3137  3138         1017808             25104       0.030316  \\\n",
       "\n",
       "      training_sequence_accuracy  training_token_accuracy  validation_loss   \n",
       "3137                         1.0                      1.0              NaN  \\\n",
       "\n",
       "      validation_sequence_accuracy  validation_token_accuracy   \n",
       "3137                           NaN                        NaN  \\\n",
       "\n",
       "      classification/accuracy  classification/precision   \n",
       "3137                 0.814333                  0.837239  \\\n",
       "\n",
       "      classification/recall  classification/auroc  classification/auprc   \n",
       "3137               0.844728              0.890362              0.914601  \\\n",
       "\n",
       "      classification/f1.0  \n",
       "3137             0.840967  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result view\n",
    "results = pd.read_csv('result.csv')\n",
    "results[results['classification/accuracy'].notnull()].tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Implicit_hate_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ada:ft-personal-2023-08-04-20-03-44\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = None\n",
    "\n",
    "def gpt_complete_create(prompt_text):\n",
    "    #model_id = \"ada:ft-personal-2023-06-26-17-27-28\" \n",
    "    result_gpt = openai.Completion.create(model=model_id, prompt=prompt_text, max_tokens=1, temperature=0)\n",
    "    return result_gpt\n",
    "\n",
    "def gpt_predict(start = 0, step = 10, max_s=10):\n",
    "    prompts_tosend = []\n",
    "    for i in range(start, start+step):\n",
    "        if i == max_s: break\n",
    "        p = df_gpt.loc[i]['prompt']\n",
    "        prompts_tosend.append(p)\n",
    "    \n",
    "    predict_result = gpt_complete_create(prompts_tosend)\n",
    "    choices_gpt = predict_result.get('choices')\n",
    "    \n",
    "    for i in range(len(choices_gpt)):\n",
    "        j = choices_gpt[i]['index']\n",
    "        df_gpt.loc[start+j, 'predicted'] = int(choices_gpt[i]['text']) \n",
    "\n",
    "    print(f\"predicted {start} to {start+len(prompts_tosend)-1}\")\n",
    "\n",
    "    return prompts_tosend, predict_result\n",
    "\n",
    "def loop_gpt(start, end, step, max_s):\n",
    "    for i in range(start, end, step):\n",
    "        bb, cc = gpt_predict(i, step, max_s)\n",
    "        time.sleep(50)\n",
    "    return bb, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: . poll flawed - didn't offer option of enfor...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you will not succeed in your goal of a white e...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a white supremacist when they are conservativ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>then why do you use the word white ? youre the...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retweeted elder lansing ( ): forget this white...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion  predicted\n",
       "0  : . poll flawed - didn't offer option of enfor...           0         -1\n",
       "1  you will not succeed in your goal of a white e...           0         -1\n",
       "2   a white supremacist when they are conservativ...           0         -1\n",
       "3  then why do you use the word white ? youre the...           0         -1\n",
       "4  retweeted elder lansing ( ): forget this white...           0         -1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = f\"Dataset/{dataset_name}/gpt_data_test_prepared.jsonl\"\n",
    "df_gpt = pd.read_json(filepath, lines=True)\n",
    "df_gpt['predicted'] = -1\n",
    "df_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4296"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_s = len(df_gpt)\n",
    "max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 600 to 1099\n",
      "predicted 1100 to 1599\n",
      "predicted 1600 to 2099\n",
      "predicted 2100 to 2599\n",
      "predicted 2600 to 3099\n",
      "predicted 3100 to 3599\n",
      "predicted 3600 to 4099\n",
      "predicted 4100 to 4295\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    p, r = loop_gpt(600, max_s, 500, max_s)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_gpt.loc[df_gpt['predicted'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, completion, predicted]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt.loc[df_gpt['predicted'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_test_result1.jsonl\", orient='records', lines=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SE2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_csv(f\"Dataset/{dataset_name}/gpt_data_test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_gpt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDataset/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_name\u001b[39m}\u001b[39;49;00m\u001b[39m/gpt_data_test_result1.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m, orient\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrecords\u001b[39;49m\u001b[39m'\u001b[39;49m, lines\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m df_gpt\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\pandas\\io\\json\\_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\pandas\\io\\json\\_json.py:973\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    971\u001b[0m         data \u001b[39m=\u001b[39m ensure_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    972\u001b[0m         data_lines \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 973\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_lines(data_lines))\n\u001b[0;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\pandas\\io\\json\\_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    999\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1001\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\pandas\\io\\json\\_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 1134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[0;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\pandas\\io\\json\\_json.py:1347\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m parse_table_schema(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\n\u001b[0;32m   1345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1347\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "df_gpt = pd.read_json(f\"Dataset/{dataset_name}/gpt_data_test_result1.jsonl\", orient='records', lines=True)\n",
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>hate f1</th>\n",
       "      <th>non-hate f1</th>\n",
       "      <th>hate support</th>\n",
       "      <th>non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SE2019_GPT</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.809284</td>\n",
       "      <td>0.809436</td>\n",
       "      <td>0.809359</td>\n",
       "      <td>0.778565</td>\n",
       "      <td>0.840153</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>1565.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Accuracy  precision    recall  f1-score   hate f1  non-hate f1  \\\n",
       "0  SE2019_GPT  0.814333   0.809284  0.809436  0.809359  0.778565     0.840153   \n",
       "\n",
       "   hate support  non-hate support  \n",
       "0        1128.0            1565.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_gpt['completion'].to_numpy()\n",
    "y_test_pred = df_gpt['predicted'].to_numpy()\n",
    "\n",
    "y_test = np.where(y_test == 1, \"Hate\", \"Non-Hate\") \n",
    "y_test_pred = np.where(y_test_pred == 1, \"Hate\", \"Non-Hate\") \n",
    "# get_result_single(y_test, y_test_pred, \"GPT\")\n",
    "get_result_single(y_test, y_test_pred, dataset_name+\"_GPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4296, 5400]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_test_pred, labels\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mHate\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mNon-Hate\u001b[39;49m\u001b[39m\"\u001b[39;49m], digits\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m))\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   2406\u001b[0m     {\n\u001b[0;32m   2407\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2431\u001b[0m ):\n\u001b[0;32m   2432\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2536\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2537\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2541\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2542\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\FYP codes\\.venv10\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4296, 5400]"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"], digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: Actual\n",
      "Non-Hate    1565\n",
      "Hate        1128\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count: Predict\n",
      "Non-Hate    1563\n",
      "Hate        1130\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(y_test, y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n",
    "- https://www.youtube.com/watch?v=hOCDJyZ6quA\n",
    "- tensorflow hub bert https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
    "- bert will convert sentence into embeding vector which will feed to neural network for training \n",
    "- consist of preprocess and embeding \n",
    "- (4)BERT-RNN: The corresponding representational word vectors were trained by BERT model for the input text, which were then classified by RNN neural network. (5)word2vec-RNN: This model is a traditional text classification model. 4.3.\n",
    "- BERT is a neural-network-based technique for language processing pre-training\n",
    "- it is not a classification algorithm \n",
    "- BERT generates <b>contextual embeddings</b>, the input to the model is a sentence rather than a single word.\n",
    "- BERT learns contextualized word representations, often referred to as contextual word embeddings or contextualized embeddings. Unlike traditional word embeddings, which assign a fixed vector representation to each word, BERT's word representations are sensitive to the context in which the word appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    # Model performance charts\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "\n",
    "    plt.title(f'{model_name} model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.ylim(None, 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "\n",
    "    plt.title(f'{model_name} model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='lower right')\n",
    "    plt.ylim(0, None)\n",
    "    \n",
    "    \n",
    "    # plt.figure(figsize=(4,4))\n",
    "    # plt.plot(model_history.history['loss'])\n",
    "    # plt.plot(model_history.history['val_loss'])\n",
    "    \n",
    "    # plt.title(f'{model_name} model loss')\n",
    "    # plt.ylabel('loss')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='lower right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(y_test, y_test_pred):\n",
    "    # Heatmap\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    # Plot the two-way Confusion Matrix\n",
    "    sb.heatmap(confusion_matrix(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"]), \n",
    "            annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.xaxis.set_ticklabels([\"Hate\",\"Non-Hate\"])\n",
    "    ax.yaxis.set_ticklabels([\"Hate\",\"Non-Hate\"])\n",
    "\n",
    "    # Count\n",
    "    df1 = pd.DataFrame({'Actual':y_test, 'Predict':y_test_pred})\n",
    "    # print(df1.describe())\n",
    "    print(f\"Count: {df1['Actual'].value_counts()}\")\n",
    "    print()\n",
    "    print(f\"Count: {df1['Predict'].value_counts()}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Non-Hate    0.578737\n",
      "Hate        0.421263\n",
      "Name: proportion, dtype: float64\n",
      "Train Set : (10384,) (10384,)\n",
      "Test Set  : (2596,) (2596,)\n",
      "Total  12980\n",
      "SE2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best gift ever '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, dataset_name = load_dataset(3,2) \n",
    "x_train, y_train, y_train_binary, x_test, y_test, y_test_binary = split_data(df)\n",
    "df_result = get_result_table()\n",
    "print(dataset_name)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gab \n",
    "'white people post ww stupid allowing bullshit happen right noses western civilization smart cunning superior rest envy'\n",
    "\n",
    "implicit\n",
    "'dividing country small groups hate kkk neonazis etc droves crazies flocking well done dnc'\n",
    "\n",
    "se \n",
    "'yeah bad bitch looking hoe kind average'\n",
    "\n",
    "balanced\n",
    "'reason poem woman '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 34671\n",
      "Converted 22504 words (12167 misses)\n",
      "word2vec_trained\n",
      "GabHateCorpus\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model,em_model_name = get_word2vec_model()\n",
    "custom_encoder, custom_embedding, embedding_name = pre_trained_em(x_train, pre_trained_model, em_model_name)\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 34666\n",
      "Converted 22627 words (12039 misses)\n",
      "word2vec_trained\n",
      "GabHateCorpus\n"
     ]
    }
   ],
   "source": [
    "# pre trained word embedding \n",
    "pre_trained_model,em_model_name = get_word2vec_model()\n",
    "custom_encoder, custom_embedding, embedding_name = pre_trained_em(x_train, pre_trained_model, em_model_name)\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 34819\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# learned word embedding\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m custom_encoder, custom_embedding, embedding_name \u001b[39m=\u001b[39m glove_em(x_train)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(embedding_name)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(dataset_name)\n",
      "Cell \u001b[1;32mIn[39], line 18\u001b[0m, in \u001b[0;36mglove_em\u001b[1;34m(x_train)\u001b[0m\n\u001b[0;32m     15\u001b[0m embeddings_dic \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m     16\u001b[0m glove_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDataset/trained/glove.42B.300d.txt\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m glove_file:\n\u001b[0;32m     19\u001b[0m     records \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit()\n\u001b[0;32m     20\u001b[0m     word \u001b[39m=\u001b[39m records[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learned word embedding\n",
    "custom_encoder, custom_embedding, embedding_name = glove_em(x_train)\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, h = cnn(custom_encoder,custom_embedding, embedding_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "model, h = rnn(custom_encoder,custom_embedding, embedding_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "model, h = lstm(custom_encoder,custom_embedding, embedding_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "model, h = gru(custom_encoder,custom_embedding, embedding_name,save=False, epoch=8, batch_size=256, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru\n",
      "Epoch 1/8\n",
      "107/107 [==============================] - 11s 47ms/step - loss: 0.6128 - accuracy: 0.6726 - precision: 0.6724 - recall: 0.6734 - val_loss: 0.5889 - val_accuracy: 0.6898 - val_precision: 0.7260 - val_recall: 0.6006\n",
      "Epoch 2/8\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 0.5746 - accuracy: 0.7017 - precision: 0.7014 - recall: 0.7050 - val_loss: 0.5724 - val_accuracy: 0.7070 - val_precision: 0.6928 - val_recall: 0.7341\n",
      "Epoch 3/8\n",
      "107/107 [==============================] - 2s 20ms/step - loss: 0.5614 - accuracy: 0.7118 - precision: 0.7067 - recall: 0.7265 - val_loss: 0.5664 - val_accuracy: 0.7077 - val_precision: 0.6850 - val_recall: 0.7593\n",
      "Epoch 4/8\n",
      "107/107 [==============================] - 2s 20ms/step - loss: 0.5491 - accuracy: 0.7169 - precision: 0.7087 - recall: 0.7387 - val_loss: 0.5596 - val_accuracy: 0.7130 - val_precision: 0.7108 - val_recall: 0.7095\n",
      "Epoch 5/8\n",
      "107/107 [==============================] - 2s 20ms/step - loss: 0.5381 - accuracy: 0.7284 - precision: 0.7228 - recall: 0.7430 - val_loss: 0.5582 - val_accuracy: 0.7137 - val_precision: 0.6938 - val_recall: 0.7558\n",
      "Epoch 6/8\n",
      "107/107 [==============================] - 2s 21ms/step - loss: 0.5256 - accuracy: 0.7358 - precision: 0.7281 - recall: 0.7546 - val_loss: 0.5569 - val_accuracy: 0.7167 - val_precision: 0.6938 - val_recall: 0.7665\n",
      "Epoch 7/8\n",
      "107/107 [==============================] - 2s 21ms/step - loss: 0.5159 - accuracy: 0.7427 - precision: 0.7379 - recall: 0.7545 - val_loss: 0.5628 - val_accuracy: 0.7220 - val_precision: 0.6978 - val_recall: 0.7742\n",
      "Epoch 8/8\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 0.5001 - accuracy: 0.7502 - precision: 0.7440 - recall: 0.7645 - val_loss: 0.5591 - val_accuracy: 0.7230 - val_precision: 0.7066 - val_recall: 0.7540\n",
      "acc 0.6897515058517456\n",
      "Score:  0.5590667724609375\n",
      "Accuracy:  0.7229819297790527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>hate f1</th>\n",
       "      <th>non-hate f1</th>\n",
       "      <th>hate support</th>\n",
       "      <th>non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced_word2vec_trained</td>\n",
       "      <td>0.722982</td>\n",
       "      <td>0.72398</td>\n",
       "      <td>0.723258</td>\n",
       "      <td>0.722819</td>\n",
       "      <td>0.729543</td>\n",
       "      <td>0.716094</td>\n",
       "      <td>3370.0</td>\n",
       "      <td>3431.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  precision    recall  f1-score  \\\n",
       "0  Balanced_word2vec_trained  0.722982    0.72398  0.723258  0.722819   \n",
       "\n",
       "    hate f1  non-hate f1  hate support  non-hate support  \n",
       "0  0.729543     0.716094        3370.0            3431.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, h = gru(custom_encoder,custom_embedding, embedding_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "y_test_pred = nn_predict(model)\n",
    "get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/Balanced_glove_lstm\n",
      "Score:  0.44131216406822205\n",
      "Accuracy:  0.810621440410614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Hate      0.370     0.865     0.519       639\n",
      "    Non-Hate      0.978     0.803     0.882      4784\n",
      "\n",
      "    accuracy                          0.811      5423\n",
      "   macro avg      0.674     0.834     0.700      5423\n",
      "weighted avg      0.906     0.811     0.839      5423\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>hate f1</th>\n",
       "      <th>non-hate f1</th>\n",
       "      <th>hate support</th>\n",
       "      <th>non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0.810621</td>\n",
       "      <td>0.674129</td>\n",
       "      <td>0.834359</td>\n",
       "      <td>0.700324</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.88213</td>\n",
       "      <td>639.0</td>\n",
       "      <td>4784.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  precision    recall  f1-score   hate f1  non-hate f1  \\\n",
       "0  test  0.810621   0.674129  0.834359  0.700324  0.518519      0.88213   \n",
       "\n",
       "   hate support  non-hate support  \n",
       "0         639.0            4784.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = load_model_nn(\"Balanced_glove_lstm\")\n",
    "y_test_pred = nn_predict(m)\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "get_result_single(y_test, y_test_pred)\n",
    "# plot_heatmap(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name):\n",
    "    model, h = cnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "    y_test_pred = nn_predict(model, x_test, y_test_binary)\n",
    "    get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"_cnn\", df_result)\n",
    "\n",
    "    model, h = rnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "    y_test_pred = nn_predict(model, x_test, y_test_binary)\n",
    "    get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"_rnn\", df_result)\n",
    "\n",
    "    model, h = lstm(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "    y_test_pred = nn_predict(model, x_test, y_test_binary)\n",
    "    get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"_lstm\", df_result)\n",
    "\n",
    "    model, h = gru(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "    y_test_pred = nn_predict(model, x_test, y_test_binary)\n",
    "    get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"_gru\", df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 33332\n",
      "total vector 3000000\n",
      "Converted 21403 words (11929 misses)\n",
      "word2vec_trained\n",
      "Balanced\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_start_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(embedding_name)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(dataset_name)\n\u001b[1;32m----> 7\u001b[0m model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_start_train' is not defined"
     ]
    }
   ],
   "source": [
    "# word2vec word embedding \n",
    "pre_trained_model, model_name = get_word2vec_model()\n",
    "custom_encoder, custom_embedding, embedding_name, missWord = pre_trained_em(x_train, pre_trained_model, model_name)\n",
    "print(embedding_name)\n",
    "print(dataset_name)\n",
    "\n",
    "#model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 33332\n",
      "total vector 999994\n",
      "Converted 22650 words (10682 misses)\n",
      "fasttext_trained\n",
      "Balanced\n"
     ]
    }
   ],
   "source": [
    "# fasttext word embedding \n",
    "pre_trained_model, model_name = get_fasttext_model()\n",
    "custom_encoder, custom_embedding, embedding_name, missWord = pre_trained_em(x_train, pre_trained_model, model_name)\n",
    "print(embedding_name)\n",
    "print(dataset_name)\n",
    "\n",
    "#model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 19393\n",
      "Total words  1917494\n",
      "Converted 15043 words (4350 misses)\n",
      "glove\n",
      "SE2019\n"
     ]
    }
   ],
   "source": [
    "# glove word embedding\n",
    "custom_encoder, custom_embedding, embedding_name, missWord = glove_em(x_train)\n",
    "print(embedding_name)\n",
    "print(dataset_name)\n",
    "\n",
    "#model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 33332\n",
      "no_train\n",
      "Balanced\n"
     ]
    }
   ],
   "source": [
    "# learned word embedding\n",
    "custom_encoder, custom_embedding, embedding_name = noTrained_em(x_train)\n",
    "print(embedding_name)\n",
    "print(dataset_name)\n",
    "\n",
    "#model_start_train(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "Epoch 1/8\n",
      "107/107 [==============================] - 2s 14ms/step - loss: 0.6676 - accuracy: 0.6228 - precision: 0.6119 - recall: 0.6736 - val_loss: 0.6365 - val_accuracy: 0.6586 - val_precision: 0.6692 - val_recall: 0.6217\n",
      "Epoch 2/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.6160 - accuracy: 0.6762 - precision: 0.6812 - recall: 0.6651 - val_loss: 0.6041 - val_accuracy: 0.6898 - val_precision: 0.6727 - val_recall: 0.7343\n",
      "Epoch 3/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5881 - accuracy: 0.6958 - precision: 0.6999 - recall: 0.6877 - val_loss: 0.5888 - val_accuracy: 0.6911 - val_precision: 0.7271 - val_recall: 0.6079\n",
      "Epoch 4/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7114 - precision: 0.7204 - recall: 0.6928 - val_loss: 0.5773 - val_accuracy: 0.7045 - val_precision: 0.7114 - val_recall: 0.6841\n",
      "Epoch 5/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5545 - accuracy: 0.7214 - precision: 0.7285 - recall: 0.7076 - val_loss: 0.5717 - val_accuracy: 0.7052 - val_precision: 0.7146 - val_recall: 0.6794\n",
      "Epoch 6/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5436 - accuracy: 0.7297 - precision: 0.7387 - recall: 0.7124 - val_loss: 0.5705 - val_accuracy: 0.7124 - val_precision: 0.6917 - val_recall: 0.7624\n",
      "Epoch 7/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5326 - accuracy: 0.7381 - precision: 0.7440 - recall: 0.7275 - val_loss: 0.5631 - val_accuracy: 0.7138 - val_precision: 0.7126 - val_recall: 0.7128\n",
      "Epoch 8/8\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.5222 - accuracy: 0.7459 - precision: 0.7527 - recall: 0.7340 - val_loss: 0.5599 - val_accuracy: 0.7142 - val_precision: 0.7250 - val_recall: 0.6865\n",
      "training time 9.815820693969727\n",
      "acc 0.6585724949836731\n",
      "Score:  0.5599043965339661\n",
      "Accuracy:  0.7142016291618347\n"
     ]
    }
   ],
   "source": [
    "model, h = cnn(x_train, y_train_binary, x_test,y_test_binary,custom_encoder, custom_embedding, embedding_name, dataset_name,save=False, epoch=8, batch_size=256, lr=0.001)\n",
    "y_test_pred = nn_predict(model, x_test, y_test_binary)\n",
    "get_result_single(y_test, y_test_pred, dataset_name+\"_\"+embedding_name+\"_cnn\", df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>hate f1</th>\n",
       "      <th>non-hate f1</th>\n",
       "      <th>hate support</th>\n",
       "      <th>non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced_glove_cnn</td>\n",
       "      <td>0.723032</td>\n",
       "      <td>0.724296</td>\n",
       "      <td>0.723176</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.731985</td>\n",
       "      <td>0.713459</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Balanced_glove_cnn</td>\n",
       "      <td>0.720677</td>\n",
       "      <td>0.721007</td>\n",
       "      <td>0.720594</td>\n",
       "      <td>0.720520</td>\n",
       "      <td>0.713898</td>\n",
       "      <td>0.727142</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balanced_word2vec_trained_cnn</td>\n",
       "      <td>0.729065</td>\n",
       "      <td>0.729507</td>\n",
       "      <td>0.728973</td>\n",
       "      <td>0.728879</td>\n",
       "      <td>0.721777</td>\n",
       "      <td>0.735982</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balanced_no_train_cnn</td>\n",
       "      <td>0.673878</td>\n",
       "      <td>0.673894</td>\n",
       "      <td>0.673847</td>\n",
       "      <td>0.673842</td>\n",
       "      <td>0.670434</td>\n",
       "      <td>0.677250</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Balanced_no_train_cnn</td>\n",
       "      <td>0.657837</td>\n",
       "      <td>0.657987</td>\n",
       "      <td>0.657889</td>\n",
       "      <td>0.657798</td>\n",
       "      <td>0.661424</td>\n",
       "      <td>0.654172</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Balanced_no_train_cnn</td>\n",
       "      <td>0.645769</td>\n",
       "      <td>0.646015</td>\n",
       "      <td>0.645675</td>\n",
       "      <td>0.645526</td>\n",
       "      <td>0.636240</td>\n",
       "      <td>0.654811</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Balanced_no_train_cnn</td>\n",
       "      <td>0.646358</td>\n",
       "      <td>0.647428</td>\n",
       "      <td>0.646516</td>\n",
       "      <td>0.645863</td>\n",
       "      <td>0.659101</td>\n",
       "      <td>0.632625</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.713171</td>\n",
       "      <td>0.714054</td>\n",
       "      <td>0.713038</td>\n",
       "      <td>0.712789</td>\n",
       "      <td>0.702306</td>\n",
       "      <td>0.723271</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.718617</td>\n",
       "      <td>0.718721</td>\n",
       "      <td>0.718655</td>\n",
       "      <td>0.718603</td>\n",
       "      <td>0.720550</td>\n",
       "      <td>0.716657</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.700809</td>\n",
       "      <td>0.709040</td>\n",
       "      <td>0.700409</td>\n",
       "      <td>0.697563</td>\n",
       "      <td>0.666229</td>\n",
       "      <td>0.728897</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.703753</td>\n",
       "      <td>0.706727</td>\n",
       "      <td>0.703985</td>\n",
       "      <td>0.702833</td>\n",
       "      <td>0.719364</td>\n",
       "      <td>0.686302</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.696247</td>\n",
       "      <td>0.699581</td>\n",
       "      <td>0.696497</td>\n",
       "      <td>0.695143</td>\n",
       "      <td>0.713493</td>\n",
       "      <td>0.676793</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Balanced_fasttext_trained_cnn</td>\n",
       "      <td>0.714202</td>\n",
       "      <td>0.714785</td>\n",
       "      <td>0.714092</td>\n",
       "      <td>0.713936</td>\n",
       "      <td>0.705222</td>\n",
       "      <td>0.722651</td>\n",
       "      <td>3384.0</td>\n",
       "      <td>3411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy  precision    recall  f1-score  \\\n",
       "0              Balanced_glove_cnn  0.723032   0.724296  0.723176  0.722722   \n",
       "1              Balanced_glove_cnn  0.720677   0.721007  0.720594  0.720520   \n",
       "2   Balanced_word2vec_trained_cnn  0.729065   0.729507  0.728973  0.728879   \n",
       "3           Balanced_no_train_cnn  0.673878   0.673894  0.673847  0.673842   \n",
       "4           Balanced_no_train_cnn  0.657837   0.657987  0.657889  0.657798   \n",
       "5           Balanced_no_train_cnn  0.645769   0.646015  0.645675  0.645526   \n",
       "6           Balanced_no_train_cnn  0.646358   0.647428  0.646516  0.645863   \n",
       "7   Balanced_fasttext_trained_cnn  0.713171   0.714054  0.713038  0.712789   \n",
       "8   Balanced_fasttext_trained_cnn  0.718617   0.718721  0.718655  0.718603   \n",
       "9   Balanced_fasttext_trained_cnn  0.700809   0.709040  0.700409  0.697563   \n",
       "10  Balanced_fasttext_trained_cnn  0.703753   0.706727  0.703985  0.702833   \n",
       "11  Balanced_fasttext_trained_cnn  0.696247   0.699581  0.696497  0.695143   \n",
       "12  Balanced_fasttext_trained_cnn  0.714202   0.714785  0.714092  0.713936   \n",
       "\n",
       "     hate f1  non-hate f1  hate support  non-hate support  \n",
       "0   0.731985     0.713459        3384.0            3411.0  \n",
       "1   0.713898     0.727142        3384.0            3411.0  \n",
       "2   0.721777     0.735982        3384.0            3411.0  \n",
       "3   0.670434     0.677250        3384.0            3411.0  \n",
       "4   0.661424     0.654172        3384.0            3411.0  \n",
       "5   0.636240     0.654811        3384.0            3411.0  \n",
       "6   0.659101     0.632625        3384.0            3411.0  \n",
       "7   0.702306     0.723271        3384.0            3411.0  \n",
       "8   0.720550     0.716657        3384.0            3411.0  \n",
       "9   0.666229     0.728897        3384.0            3411.0  \n",
       "10  0.719364     0.686302        3384.0            3411.0  \n",
       "11  0.713493     0.676793        3384.0            3411.0  \n",
       "12  0.705222     0.722651        3384.0            3411.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Hate       0.55      0.44      0.49       639\n",
      "    Non-Hate       0.93      0.95      0.94      4784\n",
      "\n",
      "    accuracy                           0.89      5423\n",
      "   macro avg       0.74      0.70      0.71      5423\n",
      "weighted avg       0.88      0.89      0.89      5423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: Actual\n",
      "Non-Hate    4784\n",
      "Hate         639\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count: Predict\n",
      "Non-Hate    4909\n",
      "Hate         514\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/Balanced_word2vec_trained_cnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4755_row0_col0, #T_e4755_row0_col1, #T_e4755_row0_col2, #T_e4755_row0_col3, #T_e4755_row0_col4, #T_e4755_row0_col5, #T_e4755_row0_col6, #T_e4755_row0_col7, #T_e4755_row0_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4755\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4755_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e4755_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e4755_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_e4755_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_e4755_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_e4755_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_e4755_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_e4755_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_e4755_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4755_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e4755_row0_col0\" class=\"data row0 col0\" >Balanced_word2vec_trained_cnn</td>\n",
       "      <td id=\"T_e4755_row0_col1\" class=\"data row0 col1\" >0.708425</td>\n",
       "      <td id=\"T_e4755_row0_col2\" class=\"data row0 col2\" >0.709118</td>\n",
       "      <td id=\"T_e4755_row0_col3\" class=\"data row0 col3\" >0.708131</td>\n",
       "      <td id=\"T_e4755_row0_col4\" class=\"data row0 col4\" >0.707979</td>\n",
       "      <td id=\"T_e4755_row0_col5\" class=\"data row0 col5\" >0.696557</td>\n",
       "      <td id=\"T_e4755_row0_col6\" class=\"data row0 col6\" >0.719400</td>\n",
       "      <td id=\"T_e4755_row0_col7\" class=\"data row0 col7\" >3370.000000</td>\n",
       "      <td id=\"T_e4755_row0_col8\" class=\"data row0 col8\" >3431.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d80c07b220>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset_name\n",
    "em = embedding_name\n",
    "get_result_multiple(x_test, y_test, [ds+\"_\"+em+\"_cnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_fasttext_trained_cnn\n",
      "models/GabHateCorpus_fasttext_trained_rnn\n",
      "models/GabHateCorpus_fasttext_trained_lstm\n",
      "models/GabHateCorpus_fasttext_trained_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c02ba_row0_col3, #T_c02ba_row0_col4, #T_c02ba_row0_col5, #T_c02ba_row0_col7, #T_c02ba_row0_col8, #T_c02ba_row1_col0, #T_c02ba_row1_col7, #T_c02ba_row1_col8, #T_c02ba_row2_col1, #T_c02ba_row2_col6, #T_c02ba_row2_col7, #T_c02ba_row2_col8, #T_c02ba_row3_col2, #T_c02ba_row3_col7, #T_c02ba_row3_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c02ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c02ba_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c02ba_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_c02ba_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_c02ba_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_c02ba_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_c02ba_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_c02ba_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_c02ba_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_c02ba_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c02ba_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_fasttext_trained_cnn</td>\n",
       "      <td id=\"T_c02ba_row0_col1\" class=\"data row0 col1\" >0.895814</td>\n",
       "      <td id=\"T_c02ba_row0_col2\" class=\"data row0 col2\" >0.753715</td>\n",
       "      <td id=\"T_c02ba_row0_col3\" class=\"data row0 col3\" >0.681969</td>\n",
       "      <td id=\"T_c02ba_row0_col4\" class=\"data row0 col4\" >0.709260</td>\n",
       "      <td id=\"T_c02ba_row0_col5\" class=\"data row0 col5\" >0.476367</td>\n",
       "      <td id=\"T_c02ba_row0_col6\" class=\"data row0 col6\" >0.942152</td>\n",
       "      <td id=\"T_c02ba_row0_col7\" class=\"data row0 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row0_col8\" class=\"data row0 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c02ba_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_fasttext_trained_rnn</td>\n",
       "      <td id=\"T_c02ba_row1_col1\" class=\"data row1 col1\" >0.888069</td>\n",
       "      <td id=\"T_c02ba_row1_col2\" class=\"data row1 col2\" >0.763584</td>\n",
       "      <td id=\"T_c02ba_row1_col3\" class=\"data row1 col3\" >0.554869</td>\n",
       "      <td id=\"T_c02ba_row1_col4\" class=\"data row1 col4\" >0.570044</td>\n",
       "      <td id=\"T_c02ba_row1_col5\" class=\"data row1 col5\" >0.200264</td>\n",
       "      <td id=\"T_c02ba_row1_col6\" class=\"data row1 col6\" >0.939824</td>\n",
       "      <td id=\"T_c02ba_row1_col7\" class=\"data row1 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row1_col8\" class=\"data row1 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c02ba_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_fasttext_trained_lstm</td>\n",
       "      <td id=\"T_c02ba_row2_col1\" class=\"data row2 col1\" >0.902821</td>\n",
       "      <td id=\"T_c02ba_row2_col2\" class=\"data row2 col2\" >0.822903</td>\n",
       "      <td id=\"T_c02ba_row2_col3\" class=\"data row2 col3\" >0.630348</td>\n",
       "      <td id=\"T_c02ba_row2_col4\" class=\"data row2 col4\" >0.673112</td>\n",
       "      <td id=\"T_c02ba_row2_col5\" class=\"data row2 col5\" >0.399088</td>\n",
       "      <td id=\"T_c02ba_row2_col6\" class=\"data row2 col6\" >0.947136</td>\n",
       "      <td id=\"T_c02ba_row2_col7\" class=\"data row2 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row2_col8\" class=\"data row2 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c02ba_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_fasttext_trained_gru</td>\n",
       "      <td id=\"T_c02ba_row3_col1\" class=\"data row3 col1\" >0.900240</td>\n",
       "      <td id=\"T_c02ba_row3_col2\" class=\"data row3 col2\" >0.844451</td>\n",
       "      <td id=\"T_c02ba_row3_col3\" class=\"data row3 col3\" >0.601767</td>\n",
       "      <td id=\"T_c02ba_row3_col4\" class=\"data row3 col4\" >0.639506</td>\n",
       "      <td id=\"T_c02ba_row3_col5\" class=\"data row3 col5\" >0.332922</td>\n",
       "      <td id=\"T_c02ba_row3_col6\" class=\"data row3 col6\" >0.946089</td>\n",
       "      <td id=\"T_c02ba_row3_col7\" class=\"data row3 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row3_col8\" class=\"data row3 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1434ea1c070>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'fasttext_trained'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\",ds+\"_\"+em+\"_rnn\",ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_word2vec_cnn\n",
      "models/SE2019_word2vec3_cnn\n",
      "models/SE2019_no_train_cnn\n",
      "models/SE2019_no_train3_cnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1774_row0_col0, #T_b1774_row0_col1, #T_b1774_row0_col2, #T_b1774_row0_col6, #T_b1774_row0_col7, #T_b1774_row0_col8, #T_b1774_row1_col1, #T_b1774_row1_col3, #T_b1774_row1_col4, #T_b1774_row1_col7, #T_b1774_row1_col8, #T_b1774_row2_col7, #T_b1774_row2_col8, #T_b1774_row3_col5, #T_b1774_row3_col7, #T_b1774_row3_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1774\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1774_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b1774_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b1774_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_b1774_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_b1774_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_b1774_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_b1774_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_b1774_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_b1774_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1774_row0_col0\" class=\"data row0 col0\" >SE2019_word2vec_cnn</td>\n",
       "      <td id=\"T_b1774_row0_col1\" class=\"data row0 col1\" >0.731895</td>\n",
       "      <td id=\"T_b1774_row0_col2\" class=\"data row0 col2\" >0.730780</td>\n",
       "      <td id=\"T_b1774_row0_col3\" class=\"data row0 col3\" >0.719644</td>\n",
       "      <td id=\"T_b1774_row0_col4\" class=\"data row0 col4\" >0.722074</td>\n",
       "      <td id=\"T_b1774_row0_col5\" class=\"data row0 col5\" >0.669829</td>\n",
       "      <td id=\"T_b1774_row0_col6\" class=\"data row0 col6\" >0.774319</td>\n",
       "      <td id=\"T_b1774_row0_col7\" class=\"data row0 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row0_col8\" class=\"data row0 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1774_row1_col0\" class=\"data row1 col0\" >SE2019_word2vec3_cnn</td>\n",
       "      <td id=\"T_b1774_row1_col1\" class=\"data row1 col1\" >0.731895</td>\n",
       "      <td id=\"T_b1774_row1_col2\" class=\"data row1 col2\" >0.730117</td>\n",
       "      <td id=\"T_b1774_row1_col3\" class=\"data row1 col3\" >0.720425</td>\n",
       "      <td id=\"T_b1774_row1_col4\" class=\"data row1 col4\" >0.722729</td>\n",
       "      <td id=\"T_b1774_row1_col5\" class=\"data row1 col5\" >0.672316</td>\n",
       "      <td id=\"T_b1774_row1_col6\" class=\"data row1 col6\" >0.773142</td>\n",
       "      <td id=\"T_b1774_row1_col7\" class=\"data row1 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row1_col8\" class=\"data row1 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1774_row2_col0\" class=\"data row2 col0\" >SE2019_no_train_cnn</td>\n",
       "      <td id=\"T_b1774_row2_col1\" class=\"data row2 col1\" >0.710324</td>\n",
       "      <td id=\"T_b1774_row2_col2\" class=\"data row2 col2\" >0.706902</td>\n",
       "      <td id=\"T_b1774_row2_col3\" class=\"data row2 col3\" >0.699098</td>\n",
       "      <td id=\"T_b1774_row2_col4\" class=\"data row2 col4\" >0.700933</td>\n",
       "      <td id=\"T_b1774_row2_col5\" class=\"data row2 col5\" >0.647940</td>\n",
       "      <td id=\"T_b1774_row2_col6\" class=\"data row2 col6\" >0.753927</td>\n",
       "      <td id=\"T_b1774_row2_col7\" class=\"data row2 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row2_col8\" class=\"data row2 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1774_row3_col0\" class=\"data row3 col0\" >SE2019_no_train3_cnn</td>\n",
       "      <td id=\"T_b1774_row3_col1\" class=\"data row3 col1\" >0.705701</td>\n",
       "      <td id=\"T_b1774_row3_col2\" class=\"data row3 col2\" >0.702347</td>\n",
       "      <td id=\"T_b1774_row3_col3\" class=\"data row3 col3\" >0.704561</td>\n",
       "      <td id=\"T_b1774_row3_col4\" class=\"data row3 col4\" >0.702902</td>\n",
       "      <td id=\"T_b1774_row3_col5\" class=\"data row3 col5\" >0.674061</td>\n",
       "      <td id=\"T_b1774_row3_col6\" class=\"data row3 col6\" >0.731742</td>\n",
       "      <td id=\"T_b1774_row3_col7\" class=\"data row3 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row3_col8\" class=\"data row3 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x183cf06c2e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"SE2019\"\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\",ds+\"_\"+em+\"3_cnn\",ds+\"_no_train_cnn\",ds+\"_no_train3_cnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 35s 44ms/step - loss: 0.3068 - accuracy: 0.8880 - precision: 0.6301 - recall: 0.2231 - val_loss: 0.2695 - val_accuracy: 0.8931 - val_precision: 0.6594 - val_recall: 0.2725\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.1754 - accuracy: 0.9336 - precision: 0.8073 - recall: 0.6066 - val_loss: 0.3079 - val_accuracy: 0.8879 - val_precision: 0.5798 - val_recall: 0.3263\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0583 - accuracy: 0.9812 - precision: 0.9525 - recall: 0.8920 - val_loss: 0.4039 - val_accuracy: 0.8831 - val_precision: 0.5392 - val_recall: 0.3503\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.0180 - accuracy: 0.9947 - precision: 0.9885 - recall: 0.9684 - val_loss: 0.4873 - val_accuracy: 0.8779 - val_precision: 0.5059 - val_recall: 0.3862\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.0082 - accuracy: 0.9976 - precision: 0.9943 - recall: 0.9864 - val_loss: 0.5623 - val_accuracy: 0.8802 - val_precision: 0.5204 - val_recall: 0.3443\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 31s 40ms/step - loss: 0.0050 - accuracy: 0.9986 - precision: 0.9963 - recall: 0.9924 - val_loss: 0.6261 - val_accuracy: 0.8772 - val_precision: 0.5024 - val_recall: 0.3084\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 35s 46ms/step - loss: 0.0041 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9950 - val_loss: 0.6674 - val_accuracy: 0.8791 - val_precision: 0.5146 - val_recall: 0.3174\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 33s 44ms/step - loss: 0.0033 - accuracy: 0.9992 - precision: 0.9973 - recall: 0.9960 - val_loss: 0.6752 - val_accuracy: 0.8721 - val_precision: 0.4780 - val_recall: 0.4222\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 30s 39ms/step - loss: 0.0033 - accuracy: 0.9991 - precision: 0.9967 - recall: 0.9960 - val_loss: 0.7314 - val_accuracy: 0.8768 - val_precision: 0.5000 - val_recall: 0.3234\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 35s 46ms/step - loss: 0.0032 - accuracy: 0.9993 - precision: 0.9973 - recall: 0.9967 - val_loss: 0.7651 - val_accuracy: 0.8798 - val_precision: 0.5185 - val_recall: 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_cnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8930678367614746\n",
      "rnn\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 115s 148ms/step - loss: 0.1489 - accuracy: 0.9422 - precision: 0.8159 - recall: 0.6863 - val_loss: 0.4125 - val_accuracy: 0.8698 - val_precision: 0.4570 - val_recall: 0.3024\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 121s 158ms/step - loss: 0.0597 - accuracy: 0.9793 - precision: 0.9230 - recall: 0.9083 - val_loss: 0.4803 - val_accuracy: 0.8551 - val_precision: 0.4013 - val_recall: 0.3593\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 119s 156ms/step - loss: 0.0302 - accuracy: 0.9889 - precision: 0.9576 - recall: 0.9525 - val_loss: 0.6529 - val_accuracy: 0.8654 - val_precision: 0.4317 - val_recall: 0.2934\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 117s 154ms/step - loss: 0.0173 - accuracy: 0.9945 - precision: 0.9813 - recall: 0.9744 - val_loss: 0.7736 - val_accuracy: 0.8595 - val_precision: 0.4041 - val_recall: 0.2964\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 115s 150ms/step - loss: 0.0107 - accuracy: 0.9967 - precision: 0.9870 - recall: 0.9864 - val_loss: 0.6590 - val_accuracy: 0.8448 - val_precision: 0.2995 - val_recall: 0.1946\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 109s 144ms/step - loss: 0.0118 - accuracy: 0.9961 - precision: 0.9870 - recall: 0.9814 - val_loss: 0.8400 - val_accuracy: 0.8422 - val_precision: 0.3601 - val_recall: 0.3623\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 103s 135ms/step - loss: 0.0109 - accuracy: 0.9966 - precision: 0.9887 - recall: 0.9841 - val_loss: 0.7830 - val_accuracy: 0.8459 - val_precision: 0.3779 - val_recall: 0.3892\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 94s 124ms/step - loss: 0.0120 - accuracy: 0.9961 - precision: 0.9850 - recall: 0.9834 - val_loss: 0.8460 - val_accuracy: 0.8322 - val_precision: 0.3315 - val_recall: 0.3563\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 112s 147ms/step - loss: 0.0079 - accuracy: 0.9972 - precision: 0.9890 - recall: 0.9880 - val_loss: 1.0179 - val_accuracy: 0.8348 - val_precision: 0.3304 - val_recall: 0.3323\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 102s 133ms/step - loss: 0.0064 - accuracy: 0.9979 - precision: 0.9930 - recall: 0.9897 - val_loss: 0.9482 - val_accuracy: 0.8326 - val_precision: 0.3137 - val_recall: 0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_rnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_rnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.869837760925293\n",
      "lstm\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 358s 464ms/step - loss: 0.0824 - accuracy: 0.9579 - precision: 0.8641 - recall: 0.7814 - val_loss: 0.5779 - val_accuracy: 0.8426 - val_precision: 0.3786 - val_recall: 0.4341\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 296s 388ms/step - loss: 0.0180 - accuracy: 0.9944 - precision: 0.9809 - recall: 0.9734 - val_loss: 0.7569 - val_accuracy: 0.8510 - val_precision: 0.3776 - val_recall: 0.3234\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 301s 394ms/step - loss: 0.0100 - accuracy: 0.9971 - precision: 0.9897 - recall: 0.9867 - val_loss: 0.7764 - val_accuracy: 0.8459 - val_precision: 0.3679 - val_recall: 0.3503\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 307s 402ms/step - loss: 0.0070 - accuracy: 0.9979 - precision: 0.9927 - recall: 0.9900 - val_loss: 0.9544 - val_accuracy: 0.8462 - val_precision: 0.3754 - val_recall: 0.3743\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 311s 408ms/step - loss: 0.0056 - accuracy: 0.9981 - precision: 0.9933 - recall: 0.9914 - val_loss: 0.8721 - val_accuracy: 0.8319 - val_precision: 0.3342 - val_recall: 0.3683\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 305s 400ms/step - loss: 0.0062 - accuracy: 0.9982 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.9005 - val_accuracy: 0.8566 - val_precision: 0.3799 - val_recall: 0.2605\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 316s 415ms/step - loss: 0.0033 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9947 - val_loss: 1.0540 - val_accuracy: 0.8647 - val_precision: 0.4225 - val_recall: 0.2695\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 245s 322ms/step - loss: 0.0053 - accuracy: 0.9981 - precision: 0.9930 - recall: 0.9917 - val_loss: 0.9419 - val_accuracy: 0.8485 - val_precision: 0.3695 - val_recall: 0.3263\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 159s 208ms/step - loss: 0.0037 - accuracy: 0.9985 - precision: 0.9953 - recall: 0.9924 - val_loss: 0.9320 - val_accuracy: 0.8555 - val_precision: 0.3811 - val_recall: 0.2784\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 159s 208ms/step - loss: 0.0035 - accuracy: 0.9989 - precision: 0.9967 - recall: 0.9947 - val_loss: 1.0141 - val_accuracy: 0.8426 - val_precision: 0.3514 - val_recall: 0.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8425516486167908\n",
      "bilstm\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 306s 392ms/step - loss: 0.0464 - accuracy: 0.9696 - precision: 0.9083 - recall: 0.8382 - val_loss: 0.7997 - val_accuracy: 0.8448 - val_precision: 0.3724 - val_recall: 0.3802\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 310s 407ms/step - loss: 0.0054 - accuracy: 0.9984 - precision: 0.9957 - recall: 0.9910 - val_loss: 0.9759 - val_accuracy: 0.8414 - val_precision: 0.3605 - val_recall: 0.3713\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 314s 411ms/step - loss: 0.0057 - accuracy: 0.9983 - precision: 0.9937 - recall: 0.9924 - val_loss: 0.8995 - val_accuracy: 0.8392 - val_precision: 0.3500 - val_recall: 0.3563\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 309s 405ms/step - loss: 0.0032 - accuracy: 0.9988 - precision: 0.9963 - recall: 0.9940 - val_loss: 1.0786 - val_accuracy: 0.8367 - val_precision: 0.3507 - val_recall: 0.3832\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 316s 414ms/step - loss: 0.0029 - accuracy: 0.9991 - precision: 0.9973 - recall: 0.9957 - val_loss: 0.9066 - val_accuracy: 0.8426 - val_precision: 0.3690 - val_recall: 0.3922\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 325s 426ms/step - loss: 0.0029 - accuracy: 0.9989 - precision: 0.9963 - recall: 0.9944 - val_loss: 1.1307 - val_accuracy: 0.8389 - val_precision: 0.3648 - val_recall: 0.4162\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 326s 428ms/step - loss: 0.0024 - accuracy: 0.9989 - precision: 0.9967 - recall: 0.9940 - val_loss: 1.0283 - val_accuracy: 0.8285 - val_precision: 0.3235 - val_recall: 0.3593\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 314s 411ms/step - loss: 0.0020 - accuracy: 0.9993 - precision: 0.9983 - recall: 0.9957 - val_loss: 1.1044 - val_accuracy: 0.8407 - val_precision: 0.3497 - val_recall: 0.3413\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 307s 402ms/step - loss: 0.0018 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9960 - val_loss: 1.1312 - val_accuracy: 0.8352 - val_precision: 0.3408 - val_recall: 0.3623\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 303s 397ms/step - loss: 0.0022 - accuracy: 0.9991 - precision: 0.9970 - recall: 0.9960 - val_loss: 1.0695 - val_accuracy: 0.8027 - val_precision: 0.2994 - val_recall: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_bilstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_bilstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.844763994216919\n",
      "gru\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 216s 278ms/step - loss: 0.0371 - accuracy: 0.9689 - precision: 0.8759 - recall: 0.8717 - val_loss: 0.8563 - val_accuracy: 0.8378 - val_precision: 0.3209 - val_recall: 0.2844\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 199s 261ms/step - loss: 0.0039 - accuracy: 0.9990 - precision: 0.9983 - recall: 0.9937 - val_loss: 1.0127 - val_accuracy: 0.8355 - val_precision: 0.3427 - val_recall: 0.3653\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 201s 264ms/step - loss: 0.0038 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9947 - val_loss: 0.9929 - val_accuracy: 0.8348 - val_precision: 0.3443 - val_recall: 0.3772\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 204s 268ms/step - loss: 0.0040 - accuracy: 0.9988 - precision: 0.9963 - recall: 0.9937 - val_loss: 1.0385 - val_accuracy: 0.8274 - val_precision: 0.3255 - val_recall: 0.3743\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 205s 269ms/step - loss: 0.0024 - accuracy: 0.9991 - precision: 0.9960 - recall: 0.9963 - val_loss: 1.2110 - val_accuracy: 0.8378 - val_precision: 0.3520 - val_recall: 0.3772\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 211s 276ms/step - loss: 0.0022 - accuracy: 0.9992 - precision: 0.9980 - recall: 0.9957 - val_loss: 1.1862 - val_accuracy: 0.8385 - val_precision: 0.3514 - val_recall: 0.3683\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 207s 272ms/step - loss: 0.0018 - accuracy: 0.9993 - precision: 0.9970 - recall: 0.9970 - val_loss: 1.2740 - val_accuracy: 0.8274 - val_precision: 0.3299 - val_recall: 0.3892\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 198s 259ms/step - loss: 0.0015 - accuracy: 0.9994 - precision: 0.9987 - recall: 0.9963 - val_loss: 1.4557 - val_accuracy: 0.8355 - val_precision: 0.3519 - val_recall: 0.3982\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 212s 277ms/step - loss: 0.0045 - accuracy: 0.9984 - precision: 0.9940 - recall: 0.9927 - val_loss: 1.0820 - val_accuracy: 0.8348 - val_precision: 0.3476 - val_recall: 0.3892\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 200s 262ms/step - loss: 0.0020 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9960 - val_loss: 1.1602 - val_accuracy: 0.8359 - val_precision: 0.3419 - val_recall: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_gru\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_gru\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8377581238746643\n"
     ]
    }
   ],
   "source": [
    "h = cnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = rnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = lstm(custom_encoder,custom_embedding,embedding_name)\n",
    "h = bilstm(custom_encoder,custom_embedding,embedding_name)\n",
    "h = gru(custom_encoder,custom_embedding,embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/Implicit_hate_corpus_fasttext_cnn\n",
      "models/Implicit_hate_corpus_fasttext_rnn\n",
      "models/Implicit_hate_corpus_fasttext_lstm\n",
      "models/Implicit_hate_corpus_fasttext_bilstm\n",
      "models/Implicit_hate_corpus_fasttext_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e754e_row0_col5, #T_e754e_row0_col7, #T_e754e_row0_col8, #T_e754e_row1_col0, #T_e754e_row1_col7, #T_e754e_row1_col8, #T_e754e_row2_col7, #T_e754e_row2_col8, #T_e754e_row3_col1, #T_e754e_row3_col3, #T_e754e_row3_col4, #T_e754e_row3_col7, #T_e754e_row3_col8, #T_e754e_row4_col2, #T_e754e_row4_col6, #T_e754e_row4_col7, #T_e754e_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e754e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e754e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e754e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e754e_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_e754e_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_e754e_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_e754e_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_e754e_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_e754e_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_e754e_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e754e_row0_col0\" class=\"data row0 col0\" >Implicit_hate_corpus_fasttext_cnn</td>\n",
       "      <td id=\"T_e754e_row0_col1\" class=\"data row0 col1\" >0.691962</td>\n",
       "      <td id=\"T_e754e_row0_col2\" class=\"data row0 col2\" >0.672204</td>\n",
       "      <td id=\"T_e754e_row0_col3\" class=\"data row0 col3\" >0.673499</td>\n",
       "      <td id=\"T_e754e_row0_col4\" class=\"data row0 col4\" >0.672811</td>\n",
       "      <td id=\"T_e754e_row0_col5\" class=\"data row0 col5\" >0.593654</td>\n",
       "      <td id=\"T_e754e_row0_col6\" class=\"data row0 col6\" >0.751968</td>\n",
       "      <td id=\"T_e754e_row0_col7\" class=\"data row0 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row0_col8\" class=\"data row0 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e754e_row1_col0\" class=\"data row1 col0\" >Implicit_hate_corpus_fasttext_rnn</td>\n",
       "      <td id=\"T_e754e_row1_col1\" class=\"data row1 col1\" >0.699876</td>\n",
       "      <td id=\"T_e754e_row1_col2\" class=\"data row1 col2\" >0.682861</td>\n",
       "      <td id=\"T_e754e_row1_col3\" class=\"data row1 col3\" >0.647670</td>\n",
       "      <td id=\"T_e754e_row1_col4\" class=\"data row1 col4\" >0.652007</td>\n",
       "      <td id=\"T_e754e_row1_col5\" class=\"data row1 col5\" >0.522940</td>\n",
       "      <td id=\"T_e754e_row1_col6\" class=\"data row1 col6\" >0.781073</td>\n",
       "      <td id=\"T_e754e_row1_col7\" class=\"data row1 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row1_col8\" class=\"data row1 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e754e_row2_col0\" class=\"data row2 col0\" >Implicit_hate_corpus_fasttext_lstm</td>\n",
       "      <td id=\"T_e754e_row2_col1\" class=\"data row2 col1\" >0.714618</td>\n",
       "      <td id=\"T_e754e_row2_col2\" class=\"data row2 col2\" >0.698594</td>\n",
       "      <td id=\"T_e754e_row2_col3\" class=\"data row2 col3\" >0.669451</td>\n",
       "      <td id=\"T_e754e_row2_col4\" class=\"data row2 col4\" >0.675276</td>\n",
       "      <td id=\"T_e754e_row2_col5\" class=\"data row2 col5\" >0.562247</td>\n",
       "      <td id=\"T_e754e_row2_col6\" class=\"data row2 col6\" >0.788304</td>\n",
       "      <td id=\"T_e754e_row2_col7\" class=\"data row2 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row2_col8\" class=\"data row2 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e754e_row3_col0\" class=\"data row3 col0\" >Implicit_hate_corpus_fasttext_bilstm</td>\n",
       "      <td id=\"T_e754e_row3_col1\" class=\"data row3 col1\" >0.717722</td>\n",
       "      <td id=\"T_e754e_row3_col2\" class=\"data row3 col2\" >0.700199</td>\n",
       "      <td id=\"T_e754e_row3_col3\" class=\"data row3 col3\" >0.677956</td>\n",
       "      <td id=\"T_e754e_row3_col4\" class=\"data row3 col4\" >0.683571</td>\n",
       "      <td id=\"T_e754e_row3_col5\" class=\"data row3 col5\" >0.579616</td>\n",
       "      <td id=\"T_e754e_row3_col6\" class=\"data row3 col6\" >0.787525</td>\n",
       "      <td id=\"T_e754e_row3_col7\" class=\"data row3 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row3_col8\" class=\"data row3 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e754e_row4_col0\" class=\"data row4 col0\" >Implicit_hate_corpus_fasttext_gru</td>\n",
       "      <td id=\"T_e754e_row4_col1\" class=\"data row4 col1\" >0.714618</td>\n",
       "      <td id=\"T_e754e_row4_col2\" class=\"data row4 col2\" >0.703246</td>\n",
       "      <td id=\"T_e754e_row4_col3\" class=\"data row4 col3\" >0.662193</td>\n",
       "      <td id=\"T_e754e_row4_col4\" class=\"data row4 col4\" >0.667807</td>\n",
       "      <td id=\"T_e754e_row4_col5\" class=\"data row4 col5\" >0.543106</td>\n",
       "      <td id=\"T_e754e_row4_col6\" class=\"data row4 col6\" >0.792508</td>\n",
       "      <td id=\"T_e754e_row4_col7\" class=\"data row4 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row4_col8\" class=\"data row4 col8\" >4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19db4958210>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"Implicit_hate_corpus\"\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_no_train_cnn\n",
      "models/GabHateCorpus_no_train_rnn\n",
      "models/GabHateCorpus_no_train_lstm\n",
      "models/GabHateCorpus_no_train_bilstm\n",
      "models/GabHateCorpus_no_train_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_994a8_row0_col1, #T_994a8_row0_col2, #T_994a8_row0_col4, #T_994a8_row0_col5, #T_994a8_row0_col6, #T_994a8_row0_col7, #T_994a8_row0_col8, #T_994a8_row1_col0, #T_994a8_row1_col7, #T_994a8_row1_col8, #T_994a8_row2_col7, #T_994a8_row2_col8, #T_994a8_row3_col3, #T_994a8_row3_col7, #T_994a8_row3_col8, #T_994a8_row4_col7, #T_994a8_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_994a8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_994a8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_994a8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_994a8_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_994a8_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_994a8_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_994a8_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_994a8_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_994a8_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_994a8_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_994a8_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_no_train_cnn</td>\n",
       "      <td id=\"T_994a8_row0_col1\" class=\"data row0 col1\" >0.879794</td>\n",
       "      <td id=\"T_994a8_row0_col2\" class=\"data row0 col2\" >0.714788</td>\n",
       "      <td id=\"T_994a8_row0_col3\" class=\"data row0 col3\" >0.645798</td>\n",
       "      <td id=\"T_994a8_row0_col4\" class=\"data row0 col4\" >0.670194</td>\n",
       "      <td id=\"T_994a8_row0_col5\" class=\"data row0 col5\" >0.407273</td>\n",
       "      <td id=\"T_994a8_row0_col6\" class=\"data row0 col6\" >0.933114</td>\n",
       "      <td id=\"T_994a8_row0_col7\" class=\"data row0 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row0_col8\" class=\"data row0 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_994a8_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_no_train_rnn</td>\n",
       "      <td id=\"T_994a8_row1_col1\" class=\"data row1 col1\" >0.832596</td>\n",
       "      <td id=\"T_994a8_row1_col2\" class=\"data row1 col2\" >0.608088</td>\n",
       "      <td id=\"T_994a8_row1_col3\" class=\"data row1 col3\" >0.604730</td>\n",
       "      <td id=\"T_994a8_row1_col4\" class=\"data row1 col4\" >0.606354</td>\n",
       "      <td id=\"T_994a8_row1_col5\" class=\"data row1 col5\" >0.307927</td>\n",
       "      <td id=\"T_994a8_row1_col6\" class=\"data row1 col6\" >0.904782</td>\n",
       "      <td id=\"T_994a8_row1_col7\" class=\"data row1 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row1_col8\" class=\"data row1 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_994a8_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_no_train_lstm</td>\n",
       "      <td id=\"T_994a8_row2_col1\" class=\"data row2 col1\" >0.842552</td>\n",
       "      <td id=\"T_994a8_row2_col2\" class=\"data row2 col2\" >0.629033</td>\n",
       "      <td id=\"T_994a8_row2_col3\" class=\"data row2 col3\" >0.621988</td>\n",
       "      <td id=\"T_994a8_row2_col4\" class=\"data row2 col4\" >0.625322</td>\n",
       "      <td id=\"T_994a8_row2_col5\" class=\"data row2 col5\" >0.340031</td>\n",
       "      <td id=\"T_994a8_row2_col6\" class=\"data row2 col6\" >0.910613</td>\n",
       "      <td id=\"T_994a8_row2_col7\" class=\"data row2 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row2_col8\" class=\"data row2 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_994a8_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_no_train_bilstm</td>\n",
       "      <td id=\"T_994a8_row3_col1\" class=\"data row3 col1\" >0.802729</td>\n",
       "      <td id=\"T_994a8_row3_col2\" class=\"data row3 col2\" >0.608090</td>\n",
       "      <td id=\"T_994a8_row3_col3\" class=\"data row3 col3\" >0.650749</td>\n",
       "      <td id=\"T_994a8_row3_col4\" class=\"data row3 col4\" >0.621349</td>\n",
       "      <td id=\"T_994a8_row3_col5\" class=\"data row3 col5\" >0.359281</td>\n",
       "      <td id=\"T_994a8_row3_col6\" class=\"data row3 col6\" >0.883417</td>\n",
       "      <td id=\"T_994a8_row3_col7\" class=\"data row3 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row3_col8\" class=\"data row3 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_994a8_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_no_train_gru</td>\n",
       "      <td id=\"T_994a8_row4_col1\" class=\"data row4 col1\" >0.835914</td>\n",
       "      <td id=\"T_994a8_row4_col2\" class=\"data row4 col2\" >0.625620</td>\n",
       "      <td id=\"T_994a8_row4_col3\" class=\"data row4 col3\" >0.631070</td>\n",
       "      <td id=\"T_994a8_row4_col4\" class=\"data row4 col4\" >0.628232</td>\n",
       "      <td id=\"T_994a8_row4_col5\" class=\"data row4 col5\" >0.350365</td>\n",
       "      <td id=\"T_994a8_row4_col6\" class=\"data row4 col6\" >0.906098</td>\n",
       "      <td id=\"T_994a8_row4_col7\" class=\"data row4 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row4_col8\" class=\"data row4 col8\" >2378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fae94e13d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'no_train'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_word2vec_cnn\n",
      "models/GabHateCorpus_word2vec_rnn\n",
      "models/GabHateCorpus_word2vec_lstm\n",
      "models/GabHateCorpus_word2vec_bilstm\n",
      "models/GabHateCorpus_word2vec_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_043a0_row0_col3, #T_043a0_row0_col4, #T_043a0_row0_col5, #T_043a0_row0_col7, #T_043a0_row0_col8, #T_043a0_row1_col0, #T_043a0_row1_col7, #T_043a0_row1_col8, #T_043a0_row2_col7, #T_043a0_row2_col8, #T_043a0_row3_col7, #T_043a0_row3_col8, #T_043a0_row4_col1, #T_043a0_row4_col2, #T_043a0_row4_col6, #T_043a0_row4_col7, #T_043a0_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_043a0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_043a0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_043a0_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_043a0_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_043a0_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_043a0_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_043a0_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_043a0_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_043a0_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_043a0_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_043a0_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_word2vec_cnn</td>\n",
       "      <td id=\"T_043a0_row0_col1\" class=\"data row0 col1\" >0.887906</td>\n",
       "      <td id=\"T_043a0_row0_col2\" class=\"data row0 col2\" >0.746150</td>\n",
       "      <td id=\"T_043a0_row0_col3\" class=\"data row0 col3\" >0.642703</td>\n",
       "      <td id=\"T_043a0_row0_col4\" class=\"data row0 col4\" >0.674457</td>\n",
       "      <td id=\"T_043a0_row0_col5\" class=\"data row0 col5\" >0.410853</td>\n",
       "      <td id=\"T_043a0_row0_col6\" class=\"data row0 col6\" >0.938060</td>\n",
       "      <td id=\"T_043a0_row0_col7\" class=\"data row0 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row0_col8\" class=\"data row0 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_043a0_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_word2vec_rnn</td>\n",
       "      <td id=\"T_043a0_row1_col1\" class=\"data row1 col1\" >0.873894</td>\n",
       "      <td id=\"T_043a0_row1_col2\" class=\"data row1 col2\" >0.694916</td>\n",
       "      <td id=\"T_043a0_row1_col3\" class=\"data row1 col3\" >0.633426</td>\n",
       "      <td id=\"T_043a0_row1_col4\" class=\"data row1 col4\" >0.655119</td>\n",
       "      <td id=\"T_043a0_row1_col5\" class=\"data row1 col5\" >0.380435</td>\n",
       "      <td id=\"T_043a0_row1_col6\" class=\"data row1 col6\" >0.929803</td>\n",
       "      <td id=\"T_043a0_row1_col7\" class=\"data row1 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row1_col8\" class=\"data row1 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_043a0_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_word2vec_lstm</td>\n",
       "      <td id=\"T_043a0_row2_col1\" class=\"data row2 col1\" >0.888274</td>\n",
       "      <td id=\"T_043a0_row2_col2\" class=\"data row2 col2\" >0.775411</td>\n",
       "      <td id=\"T_043a0_row2_col3\" class=\"data row2 col3\" >0.591443</td>\n",
       "      <td id=\"T_043a0_row2_col4\" class=\"data row2 col4\" >0.621357</td>\n",
       "      <td id=\"T_043a0_row2_col5\" class=\"data row2 col5\" >0.303448</td>\n",
       "      <td id=\"T_043a0_row2_col6\" class=\"data row2 col6\" >0.939266</td>\n",
       "      <td id=\"T_043a0_row2_col7\" class=\"data row2 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row2_col8\" class=\"data row2 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_043a0_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_word2vec_bilstm</td>\n",
       "      <td id=\"T_043a0_row3_col1\" class=\"data row3 col1\" >0.884956</td>\n",
       "      <td id=\"T_043a0_row3_col2\" class=\"data row3 col2\" >0.734727</td>\n",
       "      <td id=\"T_043a0_row3_col3\" class=\"data row3 col3\" >0.633300</td>\n",
       "      <td id=\"T_043a0_row3_col4\" class=\"data row3 col4\" >0.663554</td>\n",
       "      <td id=\"T_043a0_row3_col5\" class=\"data row3 col5\" >0.390625</td>\n",
       "      <td id=\"T_043a0_row3_col6\" class=\"data row3 col6\" >0.936482</td>\n",
       "      <td id=\"T_043a0_row3_col7\" class=\"data row3 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row3_col8\" class=\"data row3 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_043a0_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_word2vec_gru</td>\n",
       "      <td id=\"T_043a0_row4_col1\" class=\"data row4 col1\" >0.893437</td>\n",
       "      <td id=\"T_043a0_row4_col2\" class=\"data row4 col2\" >0.807469</td>\n",
       "      <td id=\"T_043a0_row4_col3\" class=\"data row4 col3\" >0.605968</td>\n",
       "      <td id=\"T_043a0_row4_col4\" class=\"data row4 col4\" >0.641856</td>\n",
       "      <td id=\"T_043a0_row4_col5\" class=\"data row4 col5\" >0.341686</td>\n",
       "      <td id=\"T_043a0_row4_col6\" class=\"data row4 col6\" >0.942026</td>\n",
       "      <td id=\"T_043a0_row4_col7\" class=\"data row4 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row4_col8\" class=\"data row4 col8\" >2378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb282f6510>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5372_row0_col6, #T_f5372_row0_col8, #T_f5372_row1_col0, #T_f5372_row1_col6, #T_f5372_row1_col8, #T_f5372_row2_col1, #T_f5372_row2_col2, #T_f5372_row2_col6, #T_f5372_row2_col7, #T_f5372_row2_col8, #T_f5372_row3_col6, #T_f5372_row3_col8, #T_f5372_row4_col3, #T_f5372_row4_col4, #T_f5372_row4_col5, #T_f5372_row4_col6, #T_f5372_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5372\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5372_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f5372_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f5372_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_f5372_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_f5372_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_f5372_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_f5372_level0_col6\" class=\"col_heading level0 col6\" >hate support</th>\n",
       "      <th id=\"T_f5372_level0_col7\" class=\"col_heading level0 col7\" >non-hate f1</th>\n",
       "      <th id=\"T_f5372_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5372_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_fasttext_cnn</td>\n",
       "      <td id=\"T_f5372_row0_col1\" class=\"data row0 col1\" >0.883944</td>\n",
       "      <td id=\"T_f5372_row0_col2\" class=\"data row0 col2\" >0.724345</td>\n",
       "      <td id=\"T_f5372_row0_col3\" class=\"data row0 col3\" >0.603634</td>\n",
       "      <td id=\"T_f5372_row0_col4\" class=\"data row0 col4\" >0.632063</td>\n",
       "      <td id=\"T_f5372_row0_col5\" class=\"data row0 col5\" >0.327635</td>\n",
       "      <td id=\"T_f5372_row0_col6\" class=\"data row0 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row0_col7\" class=\"data row0 col7\" >0.936491</td>\n",
       "      <td id=\"T_f5372_row0_col8\" class=\"data row0 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5372_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_fasttext_rnn</td>\n",
       "      <td id=\"T_f5372_row1_col1\" class=\"data row1 col1\" >0.879149</td>\n",
       "      <td id=\"T_f5372_row1_col2\" class=\"data row1 col2\" >0.689995</td>\n",
       "      <td id=\"T_f5372_row1_col3\" class=\"data row1 col3\" >0.503949</td>\n",
       "      <td id=\"T_f5372_row1_col4\" class=\"data row1 col4\" >0.476797</td>\n",
       "      <td id=\"T_f5372_row1_col5\" class=\"data row1 col5\" >0.017982</td>\n",
       "      <td id=\"T_f5372_row1_col6\" class=\"data row1 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row1_col7\" class=\"data row1 col7\" >0.935613</td>\n",
       "      <td id=\"T_f5372_row1_col8\" class=\"data row1 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5372_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_fasttext_lstm</td>\n",
       "      <td id=\"T_f5372_row2_col1\" class=\"data row2 col1\" >0.891320</td>\n",
       "      <td id=\"T_f5372_row2_col2\" class=\"data row2 col2\" >0.795910</td>\n",
       "      <td id=\"T_f5372_row2_col3\" class=\"data row2 col3\" >0.584577</td>\n",
       "      <td id=\"T_f5372_row2_col4\" class=\"data row2 col4\" >0.613565</td>\n",
       "      <td id=\"T_f5372_row2_col5\" class=\"data row2 col5\" >0.285945</td>\n",
       "      <td id=\"T_f5372_row2_col6\" class=\"data row2 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row2_col7\" class=\"data row2 col7\" >0.941184</td>\n",
       "      <td id=\"T_f5372_row2_col8\" class=\"data row2 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5372_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_fasttext_bilstm</td>\n",
       "      <td id=\"T_f5372_row3_col1\" class=\"data row3 col1\" >0.890214</td>\n",
       "      <td id=\"T_f5372_row3_col2\" class=\"data row3 col2\" >0.755402</td>\n",
       "      <td id=\"T_f5372_row3_col3\" class=\"data row3 col3\" >0.620362</td>\n",
       "      <td id=\"T_f5372_row3_col4\" class=\"data row3 col4\" >0.653948</td>\n",
       "      <td id=\"T_f5372_row3_col5\" class=\"data row3 col5\" >0.368011</td>\n",
       "      <td id=\"T_f5372_row3_col6\" class=\"data row3 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row3_col7\" class=\"data row3 col7\" >0.939886</td>\n",
       "      <td id=\"T_f5372_row3_col8\" class=\"data row3 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5372_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_fasttext_gru</td>\n",
       "      <td id=\"T_f5372_row4_col1\" class=\"data row4 col1\" >0.889107</td>\n",
       "      <td id=\"T_f5372_row4_col2\" class=\"data row4 col2\" >0.740086</td>\n",
       "      <td id=\"T_f5372_row4_col3\" class=\"data row4 col3\" >0.664044</td>\n",
       "      <td id=\"T_f5372_row4_col4\" class=\"data row4 col4\" >0.691493</td>\n",
       "      <td id=\"T_f5372_row4_col5\" class=\"data row4 col5\" >0.444581</td>\n",
       "      <td id=\"T_f5372_row4_col6\" class=\"data row4 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row4_col7\" class=\"data row4 col7\" >0.938405</td>\n",
       "      <td id=\"T_f5372_row4_col8\" class=\"data row4 col8\" >7151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22adb39c2d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26f23_row1_col0, #T_26f23_row2_col1, #T_26f23_row2_col2, #T_26f23_row2_col3, #T_26f23_row2_col4 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26f23\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_26f23_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_26f23_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_26f23_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_26f23_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_26f23_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_26f23_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_glove_cnn</td>\n",
       "      <td id=\"T_26f23_row0_col1\" class=\"data row0 col1\" >0.887755</td>\n",
       "      <td id=\"T_26f23_row0_col2\" class=\"data row0 col2\" >0.864472</td>\n",
       "      <td id=\"T_26f23_row0_col3\" class=\"data row0 col3\" >0.887755</td>\n",
       "      <td id=\"T_26f23_row0_col4\" class=\"data row0 col4\" >0.864063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_26f23_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_glove_rnn</td>\n",
       "      <td id=\"T_26f23_row1_col1\" class=\"data row1 col1\" >0.885050</td>\n",
       "      <td id=\"T_26f23_row1_col2\" class=\"data row1 col2\" >0.858332</td>\n",
       "      <td id=\"T_26f23_row1_col3\" class=\"data row1 col3\" >0.885050</td>\n",
       "      <td id=\"T_26f23_row1_col4\" class=\"data row1 col4\" >0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_26f23_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_glove_lstm</td>\n",
       "      <td id=\"T_26f23_row2_col1\" class=\"data row2 col1\" >0.892304</td>\n",
       "      <td id=\"T_26f23_row2_col2\" class=\"data row2 col2\" >0.880023</td>\n",
       "      <td id=\"T_26f23_row2_col3\" class=\"data row2 col3\" >0.892304</td>\n",
       "      <td id=\"T_26f23_row2_col4\" class=\"data row2 col4\" >0.884057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_26f23_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_glove_bilstm</td>\n",
       "      <td id=\"T_26f23_row3_col1\" class=\"data row3 col1\" >0.880747</td>\n",
       "      <td id=\"T_26f23_row3_col2\" class=\"data row3 col2\" >0.872886</td>\n",
       "      <td id=\"T_26f23_row3_col3\" class=\"data row3 col3\" >0.880747</td>\n",
       "      <td id=\"T_26f23_row3_col4\" class=\"data row3 col4\" >0.876315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_26f23_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_glove_gru</td>\n",
       "      <td id=\"T_26f23_row4_col1\" class=\"data row4 col1\" >0.882837</td>\n",
       "      <td id=\"T_26f23_row4_col2\" class=\"data row4 col2\" >0.876953</td>\n",
       "      <td id=\"T_26f23_row4_col3\" class=\"data row4 col3\" >0.882837</td>\n",
       "      <td id=\"T_26f23_row4_col4\" class=\"data row4 col4\" >0.879606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23b9d55ce10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'GabHateCorpus'\n",
    "em = 'glove'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_word2vec_cnn\n",
      "models/SE2019_word2vec_rnn\n",
      "models/SE2019_word2vec_lstm\n",
      "models/SE2019_word2vec_bilstm\n",
      "models/SE2019_word2vec_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aeaa9_row0_col5, #T_aeaa9_row0_col7, #T_aeaa9_row0_col8, #T_aeaa9_row1_col0, #T_aeaa9_row1_col7, #T_aeaa9_row1_col8, #T_aeaa9_row2_col2, #T_aeaa9_row2_col6, #T_aeaa9_row2_col7, #T_aeaa9_row2_col8, #T_aeaa9_row3_col7, #T_aeaa9_row3_col8, #T_aeaa9_row4_col1, #T_aeaa9_row4_col3, #T_aeaa9_row4_col4, #T_aeaa9_row4_col7, #T_aeaa9_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aeaa9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aeaa9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_aeaa9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_aeaa9_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_aeaa9_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_aeaa9_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_aeaa9_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_aeaa9_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_aeaa9_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_aeaa9_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aeaa9_row0_col0\" class=\"data row0 col0\" >SE2019_word2vec_cnn</td>\n",
       "      <td id=\"T_aeaa9_row0_col1\" class=\"data row0 col1\" >0.700488</td>\n",
       "      <td id=\"T_aeaa9_row0_col2\" class=\"data row0 col2\" >0.696548</td>\n",
       "      <td id=\"T_aeaa9_row0_col3\" class=\"data row0 col3\" >0.700337</td>\n",
       "      <td id=\"T_aeaa9_row0_col4\" class=\"data row0 col4\" >0.697045</td>\n",
       "      <td id=\"T_aeaa9_row0_col5\" class=\"data row0 col5\" >0.664750</td>\n",
       "      <td id=\"T_aeaa9_row0_col6\" class=\"data row0 col6\" >0.729341</td>\n",
       "      <td id=\"T_aeaa9_row0_col7\" class=\"data row0 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row0_col8\" class=\"data row0 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aeaa9_row1_col0\" class=\"data row1 col0\" >SE2019_word2vec_rnn</td>\n",
       "      <td id=\"T_aeaa9_row1_col1\" class=\"data row1 col1\" >0.669407</td>\n",
       "      <td id=\"T_aeaa9_row1_col2\" class=\"data row1 col2\" >0.660556</td>\n",
       "      <td id=\"T_aeaa9_row1_col3\" class=\"data row1 col3\" >0.655255</td>\n",
       "      <td id=\"T_aeaa9_row1_col4\" class=\"data row1 col4\" >0.656664</td>\n",
       "      <td id=\"T_aeaa9_row1_col5\" class=\"data row1 col5\" >0.590519</td>\n",
       "      <td id=\"T_aeaa9_row1_col6\" class=\"data row1 col6\" >0.722809</td>\n",
       "      <td id=\"T_aeaa9_row1_col7\" class=\"data row1 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row1_col8\" class=\"data row1 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aeaa9_row2_col0\" class=\"data row2 col0\" >SE2019_word2vec_lstm</td>\n",
       "      <td id=\"T_aeaa9_row2_col1\" class=\"data row2 col1\" >0.713332</td>\n",
       "      <td id=\"T_aeaa9_row2_col2\" class=\"data row2 col2\" >0.711090</td>\n",
       "      <td id=\"T_aeaa9_row2_col3\" class=\"data row2 col3\" >0.693266</td>\n",
       "      <td id=\"T_aeaa9_row2_col4\" class=\"data row2 col4\" >0.696179</td>\n",
       "      <td id=\"T_aeaa9_row2_col5\" class=\"data row2 col5\" >0.623989</td>\n",
       "      <td id=\"T_aeaa9_row2_col6\" class=\"data row2 col6\" >0.768369</td>\n",
       "      <td id=\"T_aeaa9_row2_col7\" class=\"data row2 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row2_col8\" class=\"data row2 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aeaa9_row3_col0\" class=\"data row3 col0\" >SE2019_word2vec_bilstm</td>\n",
       "      <td id=\"T_aeaa9_row3_col1\" class=\"data row3 col1\" >0.713075</td>\n",
       "      <td id=\"T_aeaa9_row3_col2\" class=\"data row3 col2\" >0.708568</td>\n",
       "      <td id=\"T_aeaa9_row3_col3\" class=\"data row3 col3\" >0.695976</td>\n",
       "      <td id=\"T_aeaa9_row3_col4\" class=\"data row3 col4\" >0.698712</td>\n",
       "      <td id=\"T_aeaa9_row3_col5\" class=\"data row3 col5\" >0.632928</td>\n",
       "      <td id=\"T_aeaa9_row3_col6\" class=\"data row3 col6\" >0.764495</td>\n",
       "      <td id=\"T_aeaa9_row3_col7\" class=\"data row3 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row3_col8\" class=\"data row3 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aeaa9_row4_col0\" class=\"data row4 col0\" >SE2019_word2vec_gru</td>\n",
       "      <td id=\"T_aeaa9_row4_col1\" class=\"data row4 col1\" >0.717185</td>\n",
       "      <td id=\"T_aeaa9_row4_col2\" class=\"data row4 col2\" >0.710524</td>\n",
       "      <td id=\"T_aeaa9_row4_col3\" class=\"data row4 col3\" >0.706840</td>\n",
       "      <td id=\"T_aeaa9_row4_col4\" class=\"data row4 col4\" >0.708230</td>\n",
       "      <td id=\"T_aeaa9_row4_col5\" class=\"data row4 col5\" >0.657116</td>\n",
       "      <td id=\"T_aeaa9_row4_col6\" class=\"data row4 col6\" >0.759344</td>\n",
       "      <td id=\"T_aeaa9_row4_col7\" class=\"data row4 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row4_col8\" class=\"data row4 col8\" >2240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1faff4f8510>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_fasttext_cnn\n",
      "models/SE2019_fasttext_rnn\n",
      "models/SE2019_fasttext_lstm\n",
      "models/SE2019_fasttext_bilstm\n",
      "models/SE2019_fasttext_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd23c_row0_col7, #T_bd23c_row0_col8, #T_bd23c_row1_col0, #T_bd23c_row1_col7, #T_bd23c_row1_col8, #T_bd23c_row2_col6, #T_bd23c_row2_col7, #T_bd23c_row2_col8, #T_bd23c_row3_col1, #T_bd23c_row3_col2, #T_bd23c_row3_col3, #T_bd23c_row3_col4, #T_bd23c_row3_col5, #T_bd23c_row3_col7, #T_bd23c_row3_col8, #T_bd23c_row4_col7, #T_bd23c_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd23c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd23c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bd23c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_bd23c_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_bd23c_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_bd23c_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_bd23c_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_bd23c_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_bd23c_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_bd23c_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd23c_row0_col0\" class=\"data row0 col0\" >SE2019_fasttext_cnn</td>\n",
       "      <td id=\"T_bd23c_row0_col1\" class=\"data row0 col1\" >0.701259</td>\n",
       "      <td id=\"T_bd23c_row0_col2\" class=\"data row0 col2\" >0.696076</td>\n",
       "      <td id=\"T_bd23c_row0_col3\" class=\"data row0 col3\" >0.699025</td>\n",
       "      <td id=\"T_bd23c_row0_col4\" class=\"data row0 col4\" >0.696878</td>\n",
       "      <td id=\"T_bd23c_row0_col5\" class=\"data row0 col5\" >0.660438</td>\n",
       "      <td id=\"T_bd23c_row0_col6\" class=\"data row0 col6\" >0.733318</td>\n",
       "      <td id=\"T_bd23c_row0_col7\" class=\"data row0 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row0_col8\" class=\"data row0 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd23c_row1_col0\" class=\"data row1 col0\" >SE2019_fasttext_rnn</td>\n",
       "      <td id=\"T_bd23c_row1_col1\" class=\"data row1 col1\" >0.682764</td>\n",
       "      <td id=\"T_bd23c_row1_col2\" class=\"data row1 col2\" >0.679793</td>\n",
       "      <td id=\"T_bd23c_row1_col3\" class=\"data row1 col3\" >0.658064</td>\n",
       "      <td id=\"T_bd23c_row1_col4\" class=\"data row1 col4\" >0.659184</td>\n",
       "      <td id=\"T_bd23c_row1_col5\" class=\"data row1 col5\" >0.569536</td>\n",
       "      <td id=\"T_bd23c_row1_col6\" class=\"data row1 col6\" >0.748831</td>\n",
       "      <td id=\"T_bd23c_row1_col7\" class=\"data row1 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row1_col8\" class=\"data row1 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd23c_row2_col0\" class=\"data row2 col0\" >SE2019_fasttext_lstm</td>\n",
       "      <td id=\"T_bd23c_row2_col1\" class=\"data row2 col1\" >0.704598</td>\n",
       "      <td id=\"T_bd23c_row2_col2\" class=\"data row2 col2\" >0.697699</td>\n",
       "      <td id=\"T_bd23c_row2_col3\" class=\"data row2 col3\" >0.691701</td>\n",
       "      <td id=\"T_bd23c_row2_col4\" class=\"data row2 col4\" >0.693555</td>\n",
       "      <td id=\"T_bd23c_row2_col5\" class=\"data row2 col5\" >0.635384</td>\n",
       "      <td id=\"T_bd23c_row2_col6\" class=\"data row2 col6\" >0.751727</td>\n",
       "      <td id=\"T_bd23c_row2_col7\" class=\"data row2 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row2_col8\" class=\"data row2 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd23c_row3_col0\" class=\"data row3 col0\" >SE2019_fasttext_bilstm</td>\n",
       "      <td id=\"T_bd23c_row3_col1\" class=\"data row3 col1\" >0.711790</td>\n",
       "      <td id=\"T_bd23c_row3_col2\" class=\"data row3 col2\" >0.705390</td>\n",
       "      <td id=\"T_bd23c_row3_col3\" class=\"data row3 col3\" >0.706433</td>\n",
       "      <td id=\"T_bd23c_row3_col4\" class=\"data row3 col4\" >0.705855</td>\n",
       "      <td id=\"T_bd23c_row3_col5\" class=\"data row3 col5\" >0.664072</td>\n",
       "      <td id=\"T_bd23c_row3_col6\" class=\"data row3 col6\" >0.747638</td>\n",
       "      <td id=\"T_bd23c_row3_col7\" class=\"data row3 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row3_col8\" class=\"data row3 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd23c_row4_col0\" class=\"data row4 col0\" >SE2019_fasttext_gru</td>\n",
       "      <td id=\"T_bd23c_row4_col1\" class=\"data row4 col1\" >0.708965</td>\n",
       "      <td id=\"T_bd23c_row4_col2\" class=\"data row4 col2\" >0.702250</td>\n",
       "      <td id=\"T_bd23c_row4_col3\" class=\"data row4 col3\" >0.702471</td>\n",
       "      <td id=\"T_bd23c_row4_col4\" class=\"data row4 col4\" >0.702358</td>\n",
       "      <td id=\"T_bd23c_row4_col5\" class=\"data row4 col5\" >0.658014</td>\n",
       "      <td id=\"T_bd23c_row4_col6\" class=\"data row4 col6\" >0.746702</td>\n",
       "      <td id=\"T_bd23c_row4_col7\" class=\"data row4 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row4_col8\" class=\"data row4 col8\" >2240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19dc079f490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3f5ec_row1_col0, #T_3f5ec_row4_col1, #T_3f5ec_row4_col2, #T_3f5ec_row4_col3, #T_3f5ec_row4_col4 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3f5ec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f5ec_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3f5ec_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3f5ec_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_3f5ec_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3f5ec_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3f5ec_row0_col0\" class=\"data row0 col0\" >SE2019_glove_cnn</td>\n",
       "      <td id=\"T_3f5ec_row0_col1\" class=\"data row0 col1\" >0.709989</td>\n",
       "      <td id=\"T_3f5ec_row0_col2\" class=\"data row0 col2\" >0.707252</td>\n",
       "      <td id=\"T_3f5ec_row0_col3\" class=\"data row0 col3\" >0.709989</td>\n",
       "      <td id=\"T_3f5ec_row0_col4\" class=\"data row0 col4\" >0.707052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3f5ec_row1_col0\" class=\"data row1 col0\" >SE2019_glove_rnn</td>\n",
       "      <td id=\"T_3f5ec_row1_col1\" class=\"data row1 col1\" >0.661344</td>\n",
       "      <td id=\"T_3f5ec_row1_col2\" class=\"data row1 col2\" >0.661685</td>\n",
       "      <td id=\"T_3f5ec_row1_col3\" class=\"data row1 col3\" >0.661344</td>\n",
       "      <td id=\"T_3f5ec_row1_col4\" class=\"data row1 col4\" >0.661509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3f5ec_row2_col0\" class=\"data row2 col0\" >SE2019_glove_lstm</td>\n",
       "      <td id=\"T_3f5ec_row2_col1\" class=\"data row2 col1\" >0.732269</td>\n",
       "      <td id=\"T_3f5ec_row2_col2\" class=\"data row2 col2\" >0.746559</td>\n",
       "      <td id=\"T_3f5ec_row2_col3\" class=\"data row2 col3\" >0.732269</td>\n",
       "      <td id=\"T_3f5ec_row2_col4\" class=\"data row2 col4\" >0.734036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3f5ec_row3_col0\" class=\"data row3 col0\" >SE2019_glove_bilstm</td>\n",
       "      <td id=\"T_3f5ec_row3_col1\" class=\"data row3 col1\" >0.726328</td>\n",
       "      <td id=\"T_3f5ec_row3_col2\" class=\"data row3 col2\" >0.730623</td>\n",
       "      <td id=\"T_3f5ec_row3_col3\" class=\"data row3 col3\" >0.726328</td>\n",
       "      <td id=\"T_3f5ec_row3_col4\" class=\"data row3 col4\" >0.727574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3f5ec_row4_col0\" class=\"data row4 col0\" >SE2019_glove_gru</td>\n",
       "      <td id=\"T_3f5ec_row4_col1\" class=\"data row4 col1\" >0.756034</td>\n",
       "      <td id=\"T_3f5ec_row4_col2\" class=\"data row4 col2\" >0.754855</td>\n",
       "      <td id=\"T_3f5ec_row4_col3\" class=\"data row4 col3\" >0.756034</td>\n",
       "      <td id=\"T_3f5ec_row4_col4\" class=\"data row4 col4\" >0.755169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23b5dc99bd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'glove'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_52f0a_row3_col1, #T_52f0a_row3_col2, #T_52f0a_row3_col3, #T_52f0a_row3_col4, #T_52f0a_row5_col0 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_52f0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_52f0a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_52f0a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_52f0a_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_52f0a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_52f0a_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_52f0a_row0_col0\" class=\"data row0 col0\" >dtc</td>\n",
       "      <td id=\"T_52f0a_row0_col1\" class=\"data row0 col1\" >0.749350</td>\n",
       "      <td id=\"T_52f0a_row0_col2\" class=\"data row0 col2\" >0.747932</td>\n",
       "      <td id=\"T_52f0a_row0_col3\" class=\"data row0 col3\" >0.749350</td>\n",
       "      <td id=\"T_52f0a_row0_col4\" class=\"data row0 col4\" >0.748249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_52f0a_row1_col0\" class=\"data row1 col0\" >dtc-tfid</td>\n",
       "      <td id=\"T_52f0a_row1_col1\" class=\"data row1 col1\" >0.743780</td>\n",
       "      <td id=\"T_52f0a_row1_col2\" class=\"data row1 col2\" >0.743531</td>\n",
       "      <td id=\"T_52f0a_row1_col3\" class=\"data row1 col3\" >0.743780</td>\n",
       "      <td id=\"T_52f0a_row1_col4\" class=\"data row1 col4\" >0.743649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_52f0a_row2_col0\" class=\"data row2 col0\" >dtc-w2v</td>\n",
       "      <td id=\"T_52f0a_row2_col1\" class=\"data row2 col1\" >0.586706</td>\n",
       "      <td id=\"T_52f0a_row2_col2\" class=\"data row2 col2\" >0.589898</td>\n",
       "      <td id=\"T_52f0a_row2_col3\" class=\"data row2 col3\" >0.586706</td>\n",
       "      <td id=\"T_52f0a_row2_col4\" class=\"data row2 col4\" >0.588024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_52f0a_row3_col0\" class=\"data row3 col0\" >svm</td>\n",
       "      <td id=\"T_52f0a_row3_col1\" class=\"data row3 col1\" >0.768659</td>\n",
       "      <td id=\"T_52f0a_row3_col2\" class=\"data row3 col2\" >0.767394</td>\n",
       "      <td id=\"T_52f0a_row3_col3\" class=\"data row3 col3\" >0.768659</td>\n",
       "      <td id=\"T_52f0a_row3_col4\" class=\"data row3 col4\" >0.766195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_52f0a_row4_col0\" class=\"data row4 col0\" >svm-tfid</td>\n",
       "      <td id=\"T_52f0a_row4_col1\" class=\"data row4 col1\" >0.746008</td>\n",
       "      <td id=\"T_52f0a_row4_col2\" class=\"data row4 col2\" >0.760112</td>\n",
       "      <td id=\"T_52f0a_row4_col3\" class=\"data row4 col3\" >0.746008</td>\n",
       "      <td id=\"T_52f0a_row4_col4\" class=\"data row4 col4\" >0.731861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_52f0a_row5_col0\" class=\"data row5 col0\" >svm-w2v</td>\n",
       "      <td id=\"T_52f0a_row5_col1\" class=\"data row5 col1\" >0.590048</td>\n",
       "      <td id=\"T_52f0a_row5_col2\" class=\"data row5 col2\" >0.611645</td>\n",
       "      <td id=\"T_52f0a_row5_col3\" class=\"data row5 col3\" >0.590048</td>\n",
       "      <td id=\"T_52f0a_row5_col4\" class=\"data row5 col4\" >0.461541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_52f0a_row6_col0\" class=\"data row6 col0\" >lr</td>\n",
       "      <td id=\"T_52f0a_row6_col1\" class=\"data row6 col1\" >0.684738</td>\n",
       "      <td id=\"T_52f0a_row6_col2\" class=\"data row6 col2\" >0.690064</td>\n",
       "      <td id=\"T_52f0a_row6_col3\" class=\"data row6 col3\" >0.684738</td>\n",
       "      <td id=\"T_52f0a_row6_col4\" class=\"data row6 col4\" >0.686326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_52f0a_row7_col0\" class=\"data row7 col0\" >lr-tfid</td>\n",
       "      <td id=\"T_52f0a_row7_col1\" class=\"data row7 col1\" >0.694393</td>\n",
       "      <td id=\"T_52f0a_row7_col2\" class=\"data row7 col2\" >0.697312</td>\n",
       "      <td id=\"T_52f0a_row7_col3\" class=\"data row7 col3\" >0.694393</td>\n",
       "      <td id=\"T_52f0a_row7_col4\" class=\"data row7 col4\" >0.695449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_52f0a_row8_col0\" class=\"data row8 col0\" >lr-w2v</td>\n",
       "      <td id=\"T_52f0a_row8_col1\" class=\"data row8 col1\" >0.708504</td>\n",
       "      <td id=\"T_52f0a_row8_col2\" class=\"data row8 col2\" >0.705758</td>\n",
       "      <td id=\"T_52f0a_row8_col3\" class=\"data row8 col3\" >0.708504</td>\n",
       "      <td id=\"T_52f0a_row8_col4\" class=\"data row8 col4\" >0.705809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f954ed6450>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
