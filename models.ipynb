{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum text\n",
    "# sb.set()\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    counter = 0\n",
    "    for i in text:\n",
    "        counter += len(i.split())\n",
    "    return counter\n",
    "\n",
    "def count_token(text):\n",
    "    s = set()\n",
    "    for i in text:\n",
    "        tokenize = i.split()\n",
    "        for j in tokenize:\n",
    "            s.add(j)    \n",
    "    return len(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GabHateCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Non-Hate    0.876664\n",
       "Hate        0.123336\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"GabHateCorpus\"\n",
    "filepath = \"Dataset/GabHateCorpus/\"\n",
    "df = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE2019 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Non-Hate    0.578542\n",
       "Hate        0.421458\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"SE2019\"\n",
    "filepath = \"Dataset/SE2019/\"\n",
    "df = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit_hate_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Non-Hate    0.618726\n",
       "Hate        0.381274\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Implicit_hate_corpus\"\n",
    "filepath = \"Dataset/Implicit_hate_corpus/\"\n",
    "df = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Non-Hate    0.5\n",
       "Hate        0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Balanced\"\n",
    "filepath = f\"Dataset/{dataset_name}/\"\n",
    "df = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Hate        0.5\n",
       "Non-Hate    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"Balanced\"\n",
    "filepath = f\"Dataset/{dataset_name}/\"\n",
    "df = pd.read_csv(filepath+\"data_needed.csv\")\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34002 entries, 0 to 34001\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   34002 non-null  object\n",
      " 1   text    34002 non-null  object\n",
      " 2   hate    34002 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 797.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Non-Hate</td>\n",
       "      <td>feminsts sjws gets owned cringe compilation co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate</td>\n",
       "      <td>hey fellow whites sit let lecture terrible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Hate</td>\n",
       "      <td>evolved potential currency asset soon become r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate</td>\n",
       "      <td>mil milstalin milhitler milmao milpolpot miln ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate</td>\n",
       "      <td>liberalism mental disorder much dangerous thou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text  hate\n",
       "0  Non-Hate  feminsts sjws gets owned cringe compilation co...     0\n",
       "1      Hate         hey fellow whites sit let lecture terrible     1\n",
       "2  Non-Hate  evolved potential currency asset soon become r...     0\n",
       "3      Hate  mil milstalin milhitler milmao milpolpot miln ...     1\n",
       "4      Hate  liberalism mental disorder much dangerous thou...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, text, hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 12974\n"
     ]
    }
   ],
   "source": [
    "filepath = \"Dataset/SE2019/\"\n",
    "df_need = pd.read_csv(filepath+\"data_needed.csv\")\n",
    "df_processed = pd.read_csv(filepath+\"data_processed.csv\")\n",
    "print(len(df_need), len(df_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_need = np.array(df_need[\"text\"])\n",
    "text_processed = np.array(df_processed[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "need:  281058\n",
      "pro:  156009\n",
      "token\n",
      "need:  53046\n",
      "pro:  22855\n"
     ]
    }
   ],
   "source": [
    "print(\"word\")\n",
    "print(\"need: \", count_words(text_need))\n",
    "print(\"pro: \", count_words(text_processed))\n",
    "\n",
    "print(\"token\")\n",
    "print(\"need: \", count_token(text_need))\n",
    "print(\"pro: \", count_token(text_processed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set : (21690,) (21690,)\n",
      "Test Set  : (5423,) (5423,)\n",
      "Total  27113\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.20\n",
    "x = np.array(df[\"text\"])\n",
    "y = np.array(df[\"class\"])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = test_size, random_state=42) #random state ensure same sample\n",
    "print(\"Train Set :\", x_train.shape, y_train.shape) \n",
    "print(\"Test Set  :\", x_test.shape, y_test.shape) \n",
    "print(\"Total \", len(df))\n",
    "# y in digit form\n",
    "y_train_binary = np.array(list(map(lambda x:1 if x==\"Hate\" else 0, y_train)))\n",
    "y_test_binary = np.array(list(map(lambda x:1 if x==\"Hate\" else 0, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2\n",
    "\n",
    "gab \n",
    "'white people post ww stupid allowing bullshit happen right noses western civilization smart cunning superior rest envy'\n",
    "\n",
    "implicit\n",
    "'dividing country small groups hate kkk neonazis etc droves crazies flocking well done dnc'\n",
    "\n",
    "se\n",
    "\n",
    "\n",
    "balanced\n",
    "'reason poem woman '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reason poem woman '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering - Word embeding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "- CountVectorizer, Tfidftransformer & Tfidfvectorizer are Frequency based Word Embedding technique\n",
    "- Tfidftransformer acts on sparse matrix and Tfidfvectorizer acts on raw text data\n",
    "- Tfidfvectorizer = countVectorizater + Tfidftransformer\n",
    "\n",
    "- https://www.analyticsvidhya.com/blog/2018/07/hands-on-sentiment-analysis-dataset-python/\n",
    "- vectorizer = word embedding process of converting text data to numerical vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/#:~:text=Word2Vec%20is%20a%20popular%20algorithm,a%20large%20corpus%20of%20text\n",
    "- Word2vec is not a single algorithm but a combination of two techniques – CBOW(Continuous bag of words) and Skip-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2vVectorizer():\n",
    "    def __init__(self) -> None:\n",
    "        self.w2v_model = None\n",
    "    \n",
    "    def w2v_vectorizer(self,sentence):\n",
    "        # vectorize the text data\n",
    "        words = sentence.split()\n",
    "        words_vec = [self.w2v_model.wv[word] for word in words if word in self.w2v_model.wv]\n",
    "        if len(words_vec) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vec = np.array(words_vec)\n",
    "        return words_vec.mean(axis=0)\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        # train the model when fit the pipeline\n",
    "        sentences = [sentence.split() for sentence in x]\n",
    "        self.w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        # when use fit or transform on the pipeline \n",
    "        return np.array([self.w2v_vectorizer(sentence) for sentence in x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_model(model, model_name):\n",
    "    filename = f\"models/{model_name}.pickle\"\n",
    "    pickle.dump(model, open(filename,\"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert given text to a vector base\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "               ('clf', DecisionTreeClassifier()),\n",
    "              ])\n",
    "model_name = \"dtc-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model,model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- supervisied learning algorithm\n",
    "- Unlike neural networks, SVMs can work with very small datasets and are not prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "model_name = \"svm\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "              ])\n",
    "model_name = \"svm-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "               ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "              ])\n",
    "model_name = \"svm-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr-tfid\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('vect', w2vVectorizer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5,max_iter=6300)),\n",
    "        ])\n",
    "model_name = \"lr-w2v\"\n",
    "model.fit(x_train, y_train)\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict data\n",
    "print(\"Test Data Accuracy  :\\t\", model.score(x_test, y_test))\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow gpu \n",
    "- https://www.tensorflow.org/install/pip#windows-native\n",
    "- https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=oWo9SNcyxlI\n",
    "- good read for = https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-022-01665-y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding\n",
    "from keras.layers import Conv1D, LSTM, SpatialDropout1D, Bidirectional, GRU, SimpleRNN, TextVectorization\n",
    "\n",
    "from keras.metrics import BinaryAccuracy,Precision,Recall\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models import FastText, Word2Vec, KeyedVectors\n",
    "\n",
    "METRICS = [\n",
    "    BinaryAccuracy(name=\"accuracy\"),\n",
    "    Precision(name=\"precision\"),\n",
    "    Recall(name=\"recall\")\n",
    "]\n",
    "\n",
    "def nn_predict(model):\n",
    "    score = model.evaluate(x_test, y_test_binary, verbose=0)\n",
    "    print(\"Score: \", score[0])\n",
    "    print(\"Accuracy: \", score[1])\n",
    "\n",
    "    y_test_pred_percent = model.predict(x_test, verbose=0)\n",
    "    y_test_pred = np.where(y_test_pred_percent > 0.5, \"Hate\", \"Non-Hate\") \n",
    "    y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "    return y_test_pred\n",
    "\n",
    "def save_model_nn(model, model_name, embedding_name, dataset_name):\n",
    "    filename = f\"models/{dataset_name}_{embedding_name}_{model_name}\"\n",
    "    model.save(filename)\n",
    "    return filename\n",
    "\n",
    "def load_model_nn(model_name):\n",
    "    filename = f\"models/{model_name}\"\n",
    "    print(filename)\n",
    "    return load_model(filename) \n",
    "\n",
    "def compile_fit_save(model, model_name, embedding_name, dataset_name, save):    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(x_train, y_train_binary, epochs=10,\n",
    "                        validation_data=(x_test,y_test_binary),\n",
    "                        batch_size = 64)\n",
    "\n",
    "    if save: \n",
    "        save_model_nn(model, model_name, embedding_name, dataset_name)\n",
    "    else:\n",
    "        \n",
    "    print(f\"acc {history.history['val_accuracy'][0]}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n",
      "Keras Version: 2.10.0\n",
      "GPU is available\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeding layer convert text to numeric form which is used as the first layer for the deep learning model\n",
    "- https://speakai.co/the-best-pretrained-word-embeddings/#:~:text=The%20most%20popular%20pretrained%20word,GloVe%2C%20Word2Vec%2C%20and%20FastText."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_em(x_train):\n",
    "    embedding_name = \"glove\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    # load glove to dictionay\n",
    "    embeddings_dic = dict()\n",
    "    glove_file = open(\"Dataset/trained/glove.42B.300d.txt\", encoding=\"utf8\")\n",
    "\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dic[word] = vector_dimensions\n",
    "    glove_file.close()\n",
    "    print(\"Total words \", len(embeddings_dic))\n",
    "\n",
    "    # create vocab length is the size of token in dictionary\n",
    "    # Size of the vocabulary\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = 300 #each glove word is 100 long\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    # create embedding matrix having 100 col\n",
    "    # for all vocab word we give it a vector value from glove\n",
    "    # for those not found in glove will be empty 0\n",
    "    # size of embedding_matriz = size of word_tokenizer.word_index.items()\n",
    "    # embedding_matrix is the weight \n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        embedding_vector = embeddings_dic.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    \n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/@93Kryptonian/word-embedding-using-fasttext-62beb0209db9\n",
    "- It treats each word as composed of n-grams. In word2vec each word is represented as a bag of words but in FastText each word is represented as a bag of character n-gram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_model():\n",
    "    return KeyedVectors.load_word2vec_format(\"./Dataset/trained/wiki-news-300d-1M-subword.vec\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_em(x_train):\n",
    "    embedding_name = \"fasttext\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size=100\n",
    "\n",
    "    sentences = [sentence.split() for sentence in x_train]\n",
    "    ft_model = FastText(sentences, vector_size=vector_size, window=5, min_count=2, workers=4, seed=42, sg=1, epochs=10) # skip gram or cbow=0\n",
    "    ft = ft_model.wv\n",
    "    ft_vocab = ft.index_to_key\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "        vocabulary = ft_vocab\n",
    "    )\n",
    "\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        embedding_vector = ft[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_em(x_train):\n",
    "    embedding_name = \"word2vec\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size=100\n",
    "\n",
    "    sentences = [sentence.split() for sentence in x_train]\n",
    "    w_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4, seed=42, sg=1, epochs=10)\n",
    "    w = w_model.wv\n",
    "    w_vocab = w.index_to_key\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "        vocabulary = w_vocab\n",
    "    )\n",
    "\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    for word, index in vocab_dict.items():\n",
    "        if word in w.key_to_index:\n",
    "            embedding_vector = w[word]\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[index] = embedding_vector\n",
    "                hits += 1\n",
    "            else:\n",
    "                print(word)\n",
    "                miss +=1\n",
    "        else:\n",
    "            print(word)\n",
    "            miss +=1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix), \n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_trained_em(x_train, model_em, embedding_name):\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = 300 \n",
    "\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "    keyVector_key = model_em.index_to_key\n",
    "    for word, index in vocab_dict.items():\n",
    "        if word in keyVector_key:\n",
    "            embedding_vector = np.array(model_em[word])\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[index] = embedding_vector\n",
    "                hits += 1\n",
    "        else:\n",
    "            miss +=1\n",
    "            \n",
    "    print(\"Converted %d words (%d misses)\" % (hits, miss))\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim, \n",
    "                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                trainable = False,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    \n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test without pre-trained\n",
    "- https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noTrained_em(x_train):\n",
    "    embedding_name = \"no_train\"\n",
    "    text_length = 50 #pad/truncate text to this long, such that each text after token will be this long\n",
    "    vector_size=100\n",
    "\n",
    "    custom_encoder = TextVectorization(\n",
    "        standardize = None,\n",
    "        output_sequence_length=text_length, \n",
    "    )\n",
    "    custom_encoder.adapt(x_train)\n",
    "    vocab = custom_encoder.get_vocabulary()\n",
    "    print(f\"total vocab {len(vocab)}\")\n",
    "    vocab_dict = dict(zip(vocab, range(len(vocab))))\n",
    "\n",
    "    vocab_length = len(vocab) + 1\n",
    "    embedding_dim = vector_size\n",
    "\n",
    "    custom_embedding = Embedding(vocab_length, embedding_dim,\n",
    "                input_length=text_length,\n",
    "                mask_zero=True)\n",
    "    return custom_encoder, custom_embedding, embedding_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snn(custom_encoder, custom_embedding, embedding_name):\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(x_train, y_train_binary, epochs=10,\n",
    "                        validation_data=(x_test,y_test_binary))\n",
    "\n",
    "    model_name = \"snn-\"+embedding_name\n",
    "    save_model_nn(model, model_name)\n",
    "    print(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_connected_layer(model):\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(custom_encoder, custom_embedding, embedding_name, save = False):\n",
    "    model_name = \"cnn\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "    add_connected_layer(model)\n",
    "\n",
    "    return compile_fit_save(model, model_name, embedding_name, dataset_name, save)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GOOD = https://medium.com/mlearning-ai/the-classification-of-text-messages-using-lstm-bi-lstm-and-gru-f79b207f90ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(custom_encoder, custom_embedding, embedding_name):\n",
    "    model_name = \"lstm\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return compile_fit_save(model,model_name, embedding_name, dataset_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm(custom_encoder, custom_embedding, embedding_name):\n",
    "    print(\"bilstm\")\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(x_train, y_train_binary, epochs=10,\n",
    "                        validation_data=(x_test,y_test_binary))\n",
    "\n",
    "    save_model_nn(model, \"bilstm\", embedding_name, dataset_name)\n",
    "    print(f\"acc {history.history['val_accuracy'][0]}\")\n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(custom_encoder, custom_embedding, embedding_name):\n",
    "    model_name = \"gru\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(GRU(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return compile_fit_save(model,model_name, embedding_name, dataset_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "- 'input_dim' = the vocab size that we will choose. In other words it is the number of unique words in the vocab.\n",
    "- 'output_dim' = the number of dimensions we wish to embed into. Each word will be represented by a vector of this much dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(custom_encoder, custom_embedding, embedding_name):\n",
    "    model_name = \"rnn\"\n",
    "    print(model_name)\n",
    "    model = Sequential()\n",
    "    model.add(custom_encoder)\n",
    "    model.add(custom_embedding)\n",
    "    model.add(SimpleRNN(128))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return compile_fit_save(model,model_name, embedding_name, dataset_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gpt word embedding and bert\n",
    "- based on transformer architecture\n",
    "- uses deep learning for word embedding \n",
    "- Yes, transformer-based word embeddings are a form of deep learning. The transformer model architecture, which is the foundation of transformer-based word embeddings, is a deep learning architecture widely used in natural language processing (NLP) tasks.\n",
    "- transformer-based word embeddings are a type of deep learning technique that utilizes the power of deep neural networks to learn contextually rich representations of words or tokens in natural language text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPT-2 belongs to a family of deep learning models called “Transformers”. Transformers are the building block of the current state-of-the-art NLP architecture\n",
    "- A typical transformers design contains two parts, encoder and decoders, both working as vectorized representation of word relationships.\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb\n",
    "- can do through fine tunning or word embedding \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuining "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://platform.openai.com/docs/api-reference/fine-tunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GabHateCorpus'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5423"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset for gpt\n",
    "df_gpt = pd.DataFrame(zip(x_train,y_train_binary), columns = ['prompt', 'completion'])\n",
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_train.jsonl\", orient='records', lines=True)\n",
    "len(df_gpt)\n",
    "\n",
    "df_gpt = pd.DataFrame(zip(x_test,y_test_binary), columns = ['prompt', 'completion'])\n",
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_test.jsonl\", orient='records', lines=True)\n",
    "len(df_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai tools fine_tunes.prepare_data -f Dataset/GabHateCorpus/gpt_data_train.jsonl\n",
      "openai tools fine_tunes.prepare_data -f Dataset/GabHateCorpus/gpt_data_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset for fine tune do in cmd\n",
    "print(f\"openai tools fine_tunes.prepare_data -f Dataset/{dataset_name}/gpt_data_train.jsonl\")\n",
    "print(f\"openai tools fine_tunes.prepare_data -f Dataset/{dataset_name}/gpt_data_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-Pki8sIaEj65AK6bjs3TY5aFQ uploaded\n",
      "file-gtNMuvqZMwNjEPfqqiVmBq5i uploaded\n"
     ]
    }
   ],
   "source": [
    "# upload file to openai and create fine tune model\n",
    "train_create_output = openai.File.create(\n",
    "  file=open(f\"Dataset/{dataset_name}/gpt_data_train_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_train_id = train_create_output.get('id')\n",
    "print(file_train_id, train_create_output.get('status'))\n",
    "\n",
    "test_create_output = openai.File.create(\n",
    "  file=open(f\"Dataset/{dataset_name}/gpt_data_test_prepared.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_test_id = test_create_output.get('id')\n",
    "print(file_test_id, test_create_output.get('status'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_create_output = openai.FineTune.create(training_file =file_train_id,\n",
    "                       validation_file=file_test_id,\n",
    "                       model = \"ada\",\n",
    "                       compute_classification_metrics = True,\n",
    "                       classification_positive_class = \" 0\"\n",
    "                       )\n",
    "fine_tune_id = fine_tune_create_output.get('id')\n",
    "print(fine_tune_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft-WNSM4A5PrnGNMJOBLcy9SFSY\n"
     ]
    }
   ],
   "source": [
    "print(fine_tune_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft-VwKO2vWcNtBJrPoZorUtFTVV succeeded ada:ft-personal-2023-06-26-14-43-42\n",
      "ft-LAcA6GtvgJ0lksqRT8jwtzSx succeeded ada:ft-personal-2023-06-26-17-27-28\n",
      "ft-XGDLqYtbnvM9gy4Mrm8AWGay cancelled None\n",
      "ft-g85PjO2OHcdlpGjn53IPW3Ed succeeded ada:ft-personal-2023-08-01-08-11-24\n",
      "ft-WNSM4A5PrnGNMJOBLcy9SFSY pending None\n"
     ]
    }
   ],
   "source": [
    "# fine tune list\n",
    "all_finetune = openai.FineTune.list()\n",
    "all_finetune_data = all_finetune.get('data')\n",
    "for i in range(len(all_finetune_data)):\n",
    "    print(all_finetune_data[i].get('id'), all_finetune_data[i].get('status'), all_finetune_data[i].get('fine_tuned_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ada:ft-personal-2023-08-01-08-11-24\",\n",
      "  \"object\": \"model\",\n",
      "  \"created\": 1690877485,\n",
      "  \"owned_by\": \"user-g61vq7zfiw7gw7twk60losib\",\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"id\": \"snapperm-4nfXiuUpIdcrwXWgqZt0Th1J\",\n",
      "      \"object\": \"model_permission\",\n",
      "      \"created\": 1690877485,\n",
      "      \"allow_create_engine\": true,\n",
      "      \"allow_sampling\": true,\n",
      "      \"allow_logprobs\": true,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": true,\n",
      "      \"allow_fine_tuning\": true,\n",
      "      \"organization\": \"org-57m2RCBaIU5pd9nsTDikjeLg\",\n",
      "      \"group\": null,\n",
      "      \"is_blocking\": false\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"ada:2020-05-03\",\n",
      "  \"parent\": \"ada:2020-05-03\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model list\n",
    "all_models = openai.Model.list()\n",
    "all_models_data = all_models.get('data')\n",
    "owned_by_list = ['openai','openai-dev', 'openai-internal']\n",
    "for i in range(len(all_models_data)):\n",
    "    if all_models_data[i].get('owned_by') not in owned_by_list:\n",
    "        print(all_models_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=ada:ft-personal-2023-06-26-17-27-28 at 0x2153fc084f0> JSON: {\n",
       "  \"id\": \"ada:ft-personal-2023-06-26-17-27-28\",\n",
       "  \"object\": \"model\",\n",
       "  \"deleted\": true\n",
       "}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Model.delete('ada:ft-personal-2023-06-26-17-27-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_output = openai.FineTune.retrieve(id=fine_tune_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pending\n"
     ]
    }
   ],
   "source": [
    "if retrieve_output.get(\"status\") == \"succeeded\":\n",
    "    model_id = retrieve_output.get('fine_tuned_model')\n",
    "    print(\"succeeded\", model_id)\n",
    "else:\n",
    "    print(retrieve_output.get(\"status\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x2913e94bdd0> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine-tune-event\",\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-WNSM4A5PrnGNMJOBLcy9SFSY\",\n",
       "      \"created_at\": 1691130661\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTune.list_events(id=fine_tune_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai api fine_tunes.results -i ft-g85PjO2OHcdlpGjn53IPW3Ed > result.csv\n"
     ]
    }
   ],
   "source": [
    "# get result of model\n",
    "print(f\"openai api fine_tunes.results -i {fine_tune_id} > result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>elapsed_tokens</th>\n",
       "      <th>elapsed_examples</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_sequence_accuracy</th>\n",
       "      <th>training_token_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_sequence_accuracy</th>\n",
       "      <th>validation_token_accuracy</th>\n",
       "      <th>classification/accuracy</th>\n",
       "      <th>classification/precision</th>\n",
       "      <th>classification/recall</th>\n",
       "      <th>classification/auroc</th>\n",
       "      <th>classification/auprc</th>\n",
       "      <th>classification/f1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>3138</td>\n",
       "      <td>1017808</td>\n",
       "      <td>25104</td>\n",
       "      <td>0.030316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814333</td>\n",
       "      <td>0.837239</td>\n",
       "      <td>0.844728</td>\n",
       "      <td>0.890362</td>\n",
       "      <td>0.914601</td>\n",
       "      <td>0.840967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  elapsed_tokens  elapsed_examples  training_loss   \n",
       "3137  3138         1017808             25104       0.030316  \\\n",
       "\n",
       "      training_sequence_accuracy  training_token_accuracy  validation_loss   \n",
       "3137                         1.0                      1.0              NaN  \\\n",
       "\n",
       "      validation_sequence_accuracy  validation_token_accuracy   \n",
       "3137                           NaN                        NaN  \\\n",
       "\n",
       "      classification/accuracy  classification/precision   \n",
       "3137                 0.814333                  0.837239  \\\n",
       "\n",
       "      classification/recall  classification/auroc  classification/auprc   \n",
       "3137               0.844728              0.890362              0.914601  \\\n",
       "\n",
       "      classification/f1.0  \n",
       "3137             0.840967  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result view\n",
    "results = pd.read_csv('result.csv')\n",
    "results[results['classification/accuracy'].notnull()].tail(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ada:ft-personal-2023-08-01-08-11-24'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_complete_create(prompt_text):\n",
    "    #model_id = \"ada:ft-personal-2023-06-26-17-27-28\" \n",
    "    result_gpt = openai.Completion.create(model=model_id, prompt=prompt_text, max_tokens=1, temperature=0)\n",
    "    return result_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7: The Anime Traditionalist, also 'tradwives' ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and the racist  anti 1a etc threats by antifa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course this jew is feigning that he  \" has...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@PoliticsGhost\\n\\n###\\n\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attn : all white people : here's your wake up ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion  predicted\n",
       "0  7: The Anime Traditionalist, also 'tradwives' ...           1         -1\n",
       "1  and the racist  anti 1a etc threats by antifa ...           0         -1\n",
       "2   of course this jew is feigning that he  \" has...           1         -1\n",
       "3                          @PoliticsGhost\\n\\n###\\n\\n           0         -1\n",
       "4  attn : all white people : here's your wake up ...           0         -1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = f\"Dataset/{dataset_name}/gpt_data_test_prepared.jsonl\"\n",
    "df_gpt = pd.read_json(filepath, lines= True)\n",
    "df_gpt['predicted'] = -1\n",
    "df_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and the racist  anti 1a etc threats by antifa who has done the violence . iam aganist any voilence  wth 1a all can say want they want\\n\\n###\\n\\n'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt['prompt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gpt_complete_create([\"7: The Anime Traditionalist, also 'tradwives' are usually trannies or secret mudsharks\\n\\n###\\n\\n\",\n",
    "                           'and the racist  anti 1a etc threats by antifa who has done the violence . iam aganist any voilence  wth 1a all can say want they want\\n\\n###\\n\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7: The Anime Traditionalist, also 'tradwives' ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and the racist  anti 1a etc threats by antifa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course this jew is feigning that he  \" has...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@PoliticsGhost\\n\\n###\\n\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attn : all white people : here's your wake up ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion  predicted\n",
       "0  7: The Anime Traditionalist, also 'tradwives' ...           1          1\n",
       "1  and the racist  anti 1a etc threats by antifa ...           0          0\n",
       "2   of course this jew is feigning that he  \" has...           1         -1\n",
       "3                          @PoliticsGhost\\n\\n###\\n\\n           0         -1\n",
       "4  attn : all white people : here's your wake up ...           0         -1"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices_gpt = res.get('choices')\n",
    "for i in range(len(choices_gpt)):\n",
    "    j = choices_gpt[i]['index']\n",
    "    df_gpt.loc[j, 'predicted'] = int(choices_gpt[i]['text'])\n",
    "df_gpt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_predict(start = 0, step = 10, max_s=10):\n",
    "    prompts_tosend = []\n",
    "    for i in range(start, start+step):\n",
    "        if i == max_s: break\n",
    "        p = df_gpt.loc[i]['prompt']\n",
    "        prompts_tosend.append(p)\n",
    "    \n",
    "    predict_result = gpt_complete_create(prompts_tosend)\n",
    "    choices_gpt = predict_result.get('choices')\n",
    "    \n",
    "    for i in range(len(choices_gpt)):\n",
    "        j = choices_gpt[i]['index']\n",
    "        df_gpt.loc[start+j, 'predicted'] = int(choices_gpt[i]['text'])\n",
    "\n",
    "    print(f\"predicted {start} to {start+len(prompts_tosend)-1}\")\n",
    "\n",
    "    # for i in range(start, start+step):\n",
    "    #     r = df_gpt.loc[i]\n",
    "    #     print(r['prompt'], \"\\n\", r['completion'], r['predicted'])\n",
    "\n",
    "    return prompts_tosend, predict_result\n",
    "\n",
    "def loop_gpt(start, end, step, max_s):\n",
    "    for i in range(start, end, step):\n",
    "        bb, cc = gpt_predict(i, step, max_s)\n",
    "        time.sleep(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_s = len(df_gpt)\n",
    "max_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 560 to 599\n",
      "predicted 600 to 639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loop_gpt(\u001b[39m560\u001b[39;49m, max_s, \u001b[39m40\u001b[39;49m, max_s)\n",
      "Cell \u001b[1;32mIn[214], line 4\u001b[0m, in \u001b[0;36mloop_gpt\u001b[1;34m(start, end, step, max_s)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start, end, step):\n\u001b[0;32m      3\u001b[0m     bb, cc \u001b[39m=\u001b[39m gpt_predict(i, step, max_s)\n\u001b[1;32m----> 4\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loop_gpt(560, max_s, 40, max_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_gpt.loc[df_gpt['predicted'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, completion, predicted]\n",
       "Index: []"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt.loc[df_gpt['predicted'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt.to_json(f\"Dataset/{dataset_name}/gpt_data_test_result1.jsonl\", orient='records', lines=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7: The Anime Traditionalist, also 'tradwives' ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and the racist  anti 1a etc threats by antifa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of course this jew is feigning that he  \" has...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@PoliticsGhost\\n\\n###\\n\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attn : all white people : here's your wake up ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>that is sick and racist\\n\\n###\\n\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>the most growing white people population in no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>Literally just saw a 10 year old girl wearing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>While our countries are fighting about paying ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>Your bitch a hoe I be fuckin her mouth if she ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  completion  predicted\n",
       "0     7: The Anime Traditionalist, also 'tradwives' ...           1          1\n",
       "1     and the racist  anti 1a etc threats by antifa ...           0          0\n",
       "2      of course this jew is feigning that he  \" has...           1          1\n",
       "3                             @PoliticsGhost\\n\\n###\\n\\n           0          0\n",
       "4     attn : all white people : here's your wake up ...           0          0\n",
       "...                                                 ...         ...        ...\n",
       "6802                 that is sick and racist\\n\\n###\\n\\n           0          0\n",
       "6803  the most growing white people population in no...           0          0\n",
       "6804  Literally just saw a 10 year old girl wearing ...           0          1\n",
       "6805  While our countries are fighting about paying ...           1          1\n",
       "6806  Your bitch a hoe I be fuckin her mouth if she ...           1          1\n",
       "\n",
       "[6807 rows x 3 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt = pd.read_json(f\"Dataset/{dataset_name}/gpt_data_test_result1.jsonl\", orient='records', lines=True)\n",
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_gpt['completion'].to_numpy()\n",
    "y_test_pred = df_gpt['predicted'].to_numpy()\n",
    "\n",
    "y_test = np.where(y_test == 1, \"Hate\", \"Non-Hate\") \n",
    "y_test_pred = np.where(y_test_pred == 1, \"Hate\", \"Non-Hate\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Hate      0.769     0.770     0.769      3420\n",
      "    Non-Hate      0.767     0.766     0.767      3387\n",
      "\n",
      "    accuracy                          0.768      6807\n",
      "   macro avg      0.768     0.768     0.768      6807\n",
      "weighted avg      0.768     0.768     0.768      6807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"], digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: Actual\n",
      "Hate        3420\n",
      "Non-Hate    3387\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count: Predict\n",
      "Hate        3423\n",
      "Non-Hate    3384\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(y_test, y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n",
    "- https://www.youtube.com/watch?v=hOCDJyZ6quA\n",
    "- tensorflow hub bert https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
    "- bert will convert sentence into embeding vector which will feed to neural network for training \n",
    "- consist of preprocess and embeding \n",
    "- (4)BERT-RNN: The corresponding representational word vectors were trained by BERT model for the input text, which were then classified by RNN neural network. (5)word2vec-RNN: This model is a traditional text classification model. 4.3.\n",
    "- BERT is a neural-network-based technique for language processing pre-training\n",
    "- it is not a classification algorithm \n",
    "- BERT generates <b>contextual embeddings</b>, the input to the model is a sentence rather than a single word.\n",
    "- BERT learns contextualized word representations, often referred to as contextual word embeddings or contextualized embeddings. Unlike traditional word embeddings, which assign a fixed vector representation to each word, BERT's word representations are sensitive to the context in which the word appears."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 50)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 100)           3200300   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, 50, 100)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               117248    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,317,677\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 3,200,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_predict(model):\n",
    "    score = model.evaluate(x_test, y_test_binary, verbose=0)\n",
    "    print(\"Score: \", score[0])\n",
    "    print(\"Accuracy: \", score[1])\n",
    "\n",
    "    y_test_pred_percent = model.predict(x_test, verbose=0)\n",
    "    y_test_pred = np.where(y_test_pred_percent > 0.5, \"Hate\", \"Non-Hate\") \n",
    "    y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history):\n",
    "    # Model performance charts\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.ylim(None, 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.ylim(0, None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(y_test, y_test_pred):\n",
    "    # Heatmap\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    # Plot the two-way Confusion Matrix\n",
    "    sb.heatmap(confusion_matrix(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"]), \n",
    "            annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.xaxis.set_ticklabels([\"Hate\",\"Non-Hate\"])\n",
    "    ax.yaxis.set_ticklabels([\"Hate\",\"Non-Hate\"])\n",
    "\n",
    "    # Count\n",
    "    df1 = pd.DataFrame({'Actual':y_test, 'Predict':y_test_pred})\n",
    "    # print(df1.describe())\n",
    "    print(f\"Count: {df1['Actual'].value_counts()}\")\n",
    "    print()\n",
    "    print(f\"Count: {df1['Predict'].value_counts()}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model_to_load:\n",
    "#     filename = f\"models/{i}.pickle\"\n",
    "#     old_model = pickle.load(open(filename,\"rb\"))\n",
    "\n",
    "def get_classification_report(i, cr):\n",
    "    return [i, cr['accuracy'], cr['macro avg']['precision'], \n",
    "            cr['macro avg']['recall'], cr['macro avg']['f1-score'],\n",
    "            cr['Hate']['f1-score'],cr['Non-Hate']['f1-score'], \n",
    "            cr['Hate']['support'],cr['Non-Hate']['support']]\n",
    "\n",
    "\n",
    "def get_result_nn(model_to_load):\n",
    "    c = ['Model', 'Accuracy', 'precision', 'recall', 'f1-score', 'hate f1', \"non-hate f1\", 'hate support', 'non-hate support']\n",
    "    result_table = pd.DataFrame(columns=c)\n",
    "    for i in model_to_load:\n",
    "        filename = f\"models/{i}\"\n",
    "        print(filename)\n",
    "        old_model = load_model(filename)\n",
    "\n",
    "        y_test_pred = old_model.predict(x_test, verbose=0)\n",
    "        y_test_pred = np.where(y_test_pred > 0.5, \"Hate\", \"Non-Hate\") \n",
    "        y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "        cr = classification_report(y_test, y_test_pred, labels=[\"Hate\",\"Non-Hate\"], output_dict=True)\n",
    "        result_table.loc[len(result_table)] = get_classification_report(i, cr)\n",
    "    return result_table.style.highlight_max(color = 'red', axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learned word embedding\n",
    "custom_encoder, custom_embedding, embedding_name = glove_em(x_train)\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, 50)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 50, 300)           10401600  \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 46, 128)           192128    \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,602,049\n",
      "Trainable params: 200,449\n",
      "Non-trainable params: 10,401,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn(custom_encoder,custom_embedding, embedding_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/Balanced_no_train_rnn\n",
      "Score:  1.653633952140808\n",
      "Accuracy:  0.6379944086074829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Hate      0.630     0.653     0.641      3370\n",
      "    Non-Hate      0.646     0.623     0.635      3431\n",
      "\n",
      "    accuracy                          0.638      6801\n",
      "   macro avg      0.638     0.638     0.638      6801\n",
      "weighted avg      0.638     0.638     0.638      6801\n",
      "\n",
      "Count: Actual\n",
      "Non-Hate    3431\n",
      "Hate        3370\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count: Predict\n",
      "Hate        3492\n",
      "Non-Hate    3309\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = load_model_nn(\"Balanced_no_train_rnn\")\n",
    "y_test_pred = nn_predict(m)\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "plot_heatmap(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white people post ww stupid allowing bullshit happen right noses western civilization smart cunning superior rest envy'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27201 6801 34817\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test), count_token(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 34671\n",
      "Converted 23820 words (10851 misses)\n",
      "fasttext_trained\n",
      "GabHateCorpus\n"
     ]
    }
   ],
   "source": [
    "# pre trained word embedding \n",
    "pre_trained_model = get_fasttext_model()\n",
    "custom_encoder, custom_embedding, embedding_name = pre_trained_em(x_train, pre_trained_model, \"fasttext_trained\")\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab 34671\n",
      "Total words  1917494\n",
      "Converted 27459 words (7212 misses)\n",
      "glove\n",
      "GabHateCorpus\n"
     ]
    }
   ],
   "source": [
    "# learned word embedding\n",
    "custom_encoder, custom_embedding, embedding_name = glove_em(x_train)\n",
    "print(embedding_name)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "Epoch 1/10\n",
      "339/339 [==============================] - 4s 9ms/step - loss: 0.3095 - accuracy: 0.8776 - precision: 0.5074 - recall: 0.2682 - val_loss: 0.2600 - val_accuracy: 0.8991 - val_precision: 0.6150 - val_recall: 0.3850\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.2411 - accuracy: 0.9021 - precision: 0.6741 - recall: 0.4159 - val_loss: 0.2741 - val_accuracy: 0.8848 - val_precision: 0.5100 - val_recall: 0.5587\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 3s 8ms/step - loss: 0.1929 - accuracy: 0.9200 - precision: 0.7378 - recall: 0.5556 - val_loss: 0.2638 - val_accuracy: 0.8995 - val_precision: 0.5967 - val_recall: 0.4538\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.1399 - accuracy: 0.9437 - precision: 0.8187 - recall: 0.7043 - val_loss: 0.2863 - val_accuracy: 0.8938 - val_precision: 0.5642 - val_recall: 0.4335\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0998 - accuracy: 0.9620 - precision: 0.8767 - recall: 0.8092 - val_loss: 0.4395 - val_accuracy: 0.9013 - val_precision: 0.6733 - val_recall: 0.3161\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0768 - accuracy: 0.9715 - precision: 0.9058 - recall: 0.8606 - val_loss: 0.3779 - val_accuracy: 0.8853 - val_precision: 0.5159 - val_recall: 0.4319\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0647 - accuracy: 0.9761 - precision: 0.9201 - recall: 0.8854 - val_loss: 0.4691 - val_accuracy: 0.8947 - val_precision: 0.5881 - val_recall: 0.3552\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0543 - accuracy: 0.9805 - precision: 0.9283 - recall: 0.9142 - val_loss: 0.4608 - val_accuracy: 0.8833 - val_precision: 0.5050 - val_recall: 0.4742\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0466 - accuracy: 0.9838 - precision: 0.9445 - recall: 0.9246 - val_loss: 0.4968 - val_accuracy: 0.8914 - val_precision: 0.5541 - val_recall: 0.4006\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 2s 7ms/step - loss: 0.0391 - accuracy: 0.9875 - precision: 0.9561 - recall: 0.9427 - val_loss: 0.5055 - val_accuracy: 0.8907 - val_precision: 0.5466 - val_recall: 0.4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_cnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8991333246231079\n",
      "rnn\n",
      "Epoch 1/10\n",
      "339/339 [==============================] - 26s 74ms/step - loss: 0.3273 - accuracy: 0.8784 - precision: 0.5150 - recall: 0.2359 - val_loss: 0.2699 - val_accuracy: 0.8938 - val_precision: 0.6245 - val_recall: 0.2473\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 25s 74ms/step - loss: 0.2791 - accuracy: 0.8900 - precision: 0.6189 - recall: 0.3079 - val_loss: 0.2769 - val_accuracy: 0.8801 - val_precision: 0.4909 - val_recall: 0.4632\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 25s 75ms/step - loss: 0.2620 - accuracy: 0.8959 - precision: 0.6544 - recall: 0.3494 - val_loss: 0.2766 - val_accuracy: 0.8894 - val_precision: 0.5859 - val_recall: 0.2081\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 25s 74ms/step - loss: 0.2605 - accuracy: 0.8970 - precision: 0.6669 - recall: 0.3486 - val_loss: 0.2750 - val_accuracy: 0.8930 - val_precision: 0.5817 - val_recall: 0.3286\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 25s 74ms/step - loss: 0.2360 - accuracy: 0.9077 - precision: 0.7079 - recall: 0.4418 - val_loss: 0.2737 - val_accuracy: 0.8934 - val_precision: 0.5753 - val_recall: 0.3646\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 30s 88ms/step - loss: 0.2143 - accuracy: 0.9124 - precision: 0.7193 - recall: 0.4887 - val_loss: 0.3064 - val_accuracy: 0.8921 - val_precision: 0.6184 - val_recall: 0.2207\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 31s 92ms/step - loss: 0.1934 - accuracy: 0.9241 - precision: 0.7681 - recall: 0.5608 - val_loss: 0.3072 - val_accuracy: 0.8735 - val_precision: 0.4581 - val_recall: 0.4022\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 33s 97ms/step - loss: 0.1678 - accuracy: 0.9346 - precision: 0.8036 - recall: 0.6292 - val_loss: 0.3306 - val_accuracy: 0.8825 - val_precision: 0.5019 - val_recall: 0.4100\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 32s 95ms/step - loss: 0.1445 - accuracy: 0.9438 - precision: 0.8232 - recall: 0.6991 - val_loss: 0.3449 - val_accuracy: 0.8667 - val_precision: 0.4364 - val_recall: 0.4507\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 31s 92ms/step - loss: 0.1200 - accuracy: 0.9555 - precision: 0.8646 - recall: 0.7627 - val_loss: 0.3976 - val_accuracy: 0.8772 - val_precision: 0.4746 - val_recall: 0.3944\n",
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_rnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_rnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8937857151031494\n",
      "lstm\n",
      "Epoch 1/10\n",
      "339/339 [==============================] - 10s 18ms/step - loss: 0.3108 - accuracy: 0.8824 - precision: 0.5458 - recall: 0.2763 - val_loss: 0.2606 - val_accuracy: 0.8960 - val_precision: 0.6126 - val_recall: 0.3192\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.2609 - accuracy: 0.8960 - precision: 0.6529 - recall: 0.3553 - val_loss: 0.2554 - val_accuracy: 0.9030 - val_precision: 0.6601 - val_recall: 0.3646\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 5s 13ms/step - loss: 0.2464 - accuracy: 0.9013 - precision: 0.6787 - recall: 0.3959 - val_loss: 0.2576 - val_accuracy: 0.9013 - val_precision: 0.6667 - val_recall: 0.3255\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.2348 - accuracy: 0.9066 - precision: 0.7094 - recall: 0.4251 - val_loss: 0.2473 - val_accuracy: 0.9039 - val_precision: 0.6788 - val_recall: 0.3505\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 5s 13ms/step - loss: 0.2244 - accuracy: 0.9107 - precision: 0.7335 - recall: 0.4466 - val_loss: 0.2487 - val_accuracy: 0.9034 - val_precision: 0.6542 - val_recall: 0.3818\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.2092 - accuracy: 0.9149 - precision: 0.7397 - recall: 0.4906 - val_loss: 0.2523 - val_accuracy: 0.9034 - val_precision: 0.6910 - val_recall: 0.3255\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.1920 - accuracy: 0.9236 - precision: 0.7807 - recall: 0.5383 - val_loss: 0.2560 - val_accuracy: 0.9025 - val_precision: 0.6440 - val_recall: 0.3850\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.1753 - accuracy: 0.9299 - precision: 0.7990 - recall: 0.5848 - val_loss: 0.2805 - val_accuracy: 0.8978 - val_precision: 0.5884 - val_recall: 0.4429\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.1514 - accuracy: 0.9388 - precision: 0.8202 - recall: 0.6525 - val_loss: 0.2972 - val_accuracy: 0.8905 - val_precision: 0.5401 - val_recall: 0.4742\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 5s 14ms/step - loss: 0.1310 - accuracy: 0.9480 - precision: 0.8513 - recall: 0.7068 - val_loss: 0.3162 - val_accuracy: 0.8932 - val_precision: 0.5607 - val_recall: 0.4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8959985375404358\n",
      "gru\n",
      "Epoch 1/10\n",
      "339/339 [==============================] - 9s 17ms/step - loss: 0.3124 - accuracy: 0.8877 - precision: 0.5869 - recall: 0.3020 - val_loss: 0.2588 - val_accuracy: 0.8989 - val_precision: 0.5966 - val_recall: 0.4397\n",
      "Epoch 2/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.2585 - accuracy: 0.8964 - precision: 0.6474 - recall: 0.3719 - val_loss: 0.2549 - val_accuracy: 0.9028 - val_precision: 0.7314 - val_recall: 0.2770\n",
      "Epoch 3/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.2458 - accuracy: 0.9031 - precision: 0.6869 - recall: 0.4104 - val_loss: 0.2459 - val_accuracy: 0.9025 - val_precision: 0.6455 - val_recall: 0.3818\n",
      "Epoch 4/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.2353 - accuracy: 0.9065 - precision: 0.7063 - recall: 0.4277 - val_loss: 0.2469 - val_accuracy: 0.9052 - val_precision: 0.6450 - val_recall: 0.4351\n",
      "Epoch 5/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.2201 - accuracy: 0.9133 - precision: 0.7340 - recall: 0.4784 - val_loss: 0.2567 - val_accuracy: 0.9013 - val_precision: 0.6092 - val_recall: 0.4538\n",
      "Epoch 6/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.2074 - accuracy: 0.9169 - precision: 0.7460 - recall: 0.5061 - val_loss: 0.2594 - val_accuracy: 0.9004 - val_precision: 0.6051 - val_recall: 0.4460\n",
      "Epoch 7/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.1873 - accuracy: 0.9246 - precision: 0.7687 - recall: 0.5652 - val_loss: 0.2708 - val_accuracy: 0.8975 - val_precision: 0.5896 - val_recall: 0.4272\n",
      "Epoch 8/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.1672 - accuracy: 0.9340 - precision: 0.8041 - recall: 0.6222 - val_loss: 0.2781 - val_accuracy: 0.8978 - val_precision: 0.6065 - val_recall: 0.3787\n",
      "Epoch 9/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.1454 - accuracy: 0.9439 - precision: 0.8321 - recall: 0.6891 - val_loss: 0.2892 - val_accuracy: 0.8936 - val_precision: 0.5618 - val_recall: 0.4413\n",
      "Epoch 10/10\n",
      "339/339 [==============================] - 4s 13ms/step - loss: 0.1213 - accuracy: 0.9539 - precision: 0.8683 - recall: 0.7434 - val_loss: 0.3482 - val_accuracy: 0.8748 - val_precision: 0.4716 - val_recall: 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_gru\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_glove_gru\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8989489078521729\n"
     ]
    }
   ],
   "source": [
    "h = cnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = rnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = lstm(custom_encoder,custom_embedding,embedding_name)\n",
    "h = gru(custom_encoder,custom_embedding,embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_glove_cnn\n",
      "models/GabHateCorpus_glove_rnn\n",
      "models/GabHateCorpus_glove_lstm\n",
      "models/GabHateCorpus_glove_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cd252_row0_col7, #T_cd252_row0_col8, #T_cd252_row1_col0, #T_cd252_row1_col7, #T_cd252_row1_col8, #T_cd252_row2_col1, #T_cd252_row2_col2, #T_cd252_row2_col4, #T_cd252_row2_col6, #T_cd252_row2_col7, #T_cd252_row2_col8, #T_cd252_row3_col3, #T_cd252_row3_col5, #T_cd252_row3_col7, #T_cd252_row3_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cd252\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cd252_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_cd252_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_cd252_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_cd252_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_cd252_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_cd252_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_cd252_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_cd252_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_cd252_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cd252_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cd252_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_glove_cnn</td>\n",
       "      <td id=\"T_cd252_row0_col1\" class=\"data row0 col1\" >0.890651</td>\n",
       "      <td id=\"T_cd252_row0_col2\" class=\"data row0 col2\" >0.735848</td>\n",
       "      <td id=\"T_cd252_row0_col3\" class=\"data row0 col3\" >0.687856</td>\n",
       "      <td id=\"T_cd252_row0_col4\" class=\"data row0 col4\" >0.707779</td>\n",
       "      <td id=\"T_cd252_row0_col5\" class=\"data row0 col5\" >0.476611</td>\n",
       "      <td id=\"T_cd252_row0_col6\" class=\"data row0 col6\" >0.938948</td>\n",
       "      <td id=\"T_cd252_row0_col7\" class=\"data row0 col7\" >639.000000</td>\n",
       "      <td id=\"T_cd252_row0_col8\" class=\"data row0 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd252_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cd252_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_glove_rnn</td>\n",
       "      <td id=\"T_cd252_row1_col1\" class=\"data row1 col1\" >0.877190</td>\n",
       "      <td id=\"T_cd252_row1_col2\" class=\"data row1 col2\" >0.697734</td>\n",
       "      <td id=\"T_cd252_row1_col3\" class=\"data row1 col3\" >0.668023</td>\n",
       "      <td id=\"T_cd252_row1_col4\" class=\"data row1 col4\" >0.680970</td>\n",
       "      <td id=\"T_cd252_row1_col5\" class=\"data row1 col5\" >0.430769</td>\n",
       "      <td id=\"T_cd252_row1_col6\" class=\"data row1 col6\" >0.931170</td>\n",
       "      <td id=\"T_cd252_row1_col7\" class=\"data row1 col7\" >639.000000</td>\n",
       "      <td id=\"T_cd252_row1_col8\" class=\"data row1 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd252_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cd252_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_glove_lstm</td>\n",
       "      <td id=\"T_cd252_row2_col1\" class=\"data row2 col1\" >0.893233</td>\n",
       "      <td id=\"T_cd252_row2_col2\" class=\"data row2 col2\" >0.743643</td>\n",
       "      <td id=\"T_cd252_row2_col3\" class=\"data row2 col3\" >0.694065</td>\n",
       "      <td id=\"T_cd252_row2_col4\" class=\"data row2 col4\" >0.714678</td>\n",
       "      <td id=\"T_cd252_row2_col5\" class=\"data row2 col5\" >0.488967</td>\n",
       "      <td id=\"T_cd252_row2_col6\" class=\"data row2 col6\" >0.940389</td>\n",
       "      <td id=\"T_cd252_row2_col7\" class=\"data row2 col7\" >639.000000</td>\n",
       "      <td id=\"T_cd252_row2_col8\" class=\"data row2 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cd252_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cd252_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_glove_gru</td>\n",
       "      <td id=\"T_cd252_row3_col1\" class=\"data row3 col1\" >0.874793</td>\n",
       "      <td id=\"T_cd252_row3_col2\" class=\"data row3 col2\" >0.703267</td>\n",
       "      <td id=\"T_cd252_row3_col3\" class=\"data row3 col3\" >0.720901</td>\n",
       "      <td id=\"T_cd252_row3_col4\" class=\"data row3 col4\" >0.711482</td>\n",
       "      <td id=\"T_cd252_row3_col5\" class=\"data row3 col5\" >0.494415</td>\n",
       "      <td id=\"T_cd252_row3_col6\" class=\"data row3 col6\" >0.928549</td>\n",
       "      <td id=\"T_cd252_row3_col7\" class=\"data row3 col7\" >639.000000</td>\n",
       "      <td id=\"T_cd252_row3_col8\" class=\"data row3 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2918a13eb30>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'glove'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\",ds+\"_\"+em+\"_rnn\",ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_fasttext_trained_cnn\n",
      "models/GabHateCorpus_fasttext_trained_rnn\n",
      "models/GabHateCorpus_fasttext_trained_lstm\n",
      "models/GabHateCorpus_fasttext_trained_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c02ba_row0_col3, #T_c02ba_row0_col4, #T_c02ba_row0_col5, #T_c02ba_row0_col7, #T_c02ba_row0_col8, #T_c02ba_row1_col0, #T_c02ba_row1_col7, #T_c02ba_row1_col8, #T_c02ba_row2_col1, #T_c02ba_row2_col6, #T_c02ba_row2_col7, #T_c02ba_row2_col8, #T_c02ba_row3_col2, #T_c02ba_row3_col7, #T_c02ba_row3_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c02ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c02ba_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c02ba_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_c02ba_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_c02ba_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_c02ba_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_c02ba_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_c02ba_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_c02ba_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_c02ba_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c02ba_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_fasttext_trained_cnn</td>\n",
       "      <td id=\"T_c02ba_row0_col1\" class=\"data row0 col1\" >0.895814</td>\n",
       "      <td id=\"T_c02ba_row0_col2\" class=\"data row0 col2\" >0.753715</td>\n",
       "      <td id=\"T_c02ba_row0_col3\" class=\"data row0 col3\" >0.681969</td>\n",
       "      <td id=\"T_c02ba_row0_col4\" class=\"data row0 col4\" >0.709260</td>\n",
       "      <td id=\"T_c02ba_row0_col5\" class=\"data row0 col5\" >0.476367</td>\n",
       "      <td id=\"T_c02ba_row0_col6\" class=\"data row0 col6\" >0.942152</td>\n",
       "      <td id=\"T_c02ba_row0_col7\" class=\"data row0 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row0_col8\" class=\"data row0 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c02ba_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_fasttext_trained_rnn</td>\n",
       "      <td id=\"T_c02ba_row1_col1\" class=\"data row1 col1\" >0.888069</td>\n",
       "      <td id=\"T_c02ba_row1_col2\" class=\"data row1 col2\" >0.763584</td>\n",
       "      <td id=\"T_c02ba_row1_col3\" class=\"data row1 col3\" >0.554869</td>\n",
       "      <td id=\"T_c02ba_row1_col4\" class=\"data row1 col4\" >0.570044</td>\n",
       "      <td id=\"T_c02ba_row1_col5\" class=\"data row1 col5\" >0.200264</td>\n",
       "      <td id=\"T_c02ba_row1_col6\" class=\"data row1 col6\" >0.939824</td>\n",
       "      <td id=\"T_c02ba_row1_col7\" class=\"data row1 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row1_col8\" class=\"data row1 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c02ba_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_fasttext_trained_lstm</td>\n",
       "      <td id=\"T_c02ba_row2_col1\" class=\"data row2 col1\" >0.902821</td>\n",
       "      <td id=\"T_c02ba_row2_col2\" class=\"data row2 col2\" >0.822903</td>\n",
       "      <td id=\"T_c02ba_row2_col3\" class=\"data row2 col3\" >0.630348</td>\n",
       "      <td id=\"T_c02ba_row2_col4\" class=\"data row2 col4\" >0.673112</td>\n",
       "      <td id=\"T_c02ba_row2_col5\" class=\"data row2 col5\" >0.399088</td>\n",
       "      <td id=\"T_c02ba_row2_col6\" class=\"data row2 col6\" >0.947136</td>\n",
       "      <td id=\"T_c02ba_row2_col7\" class=\"data row2 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row2_col8\" class=\"data row2 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c02ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c02ba_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_fasttext_trained_gru</td>\n",
       "      <td id=\"T_c02ba_row3_col1\" class=\"data row3 col1\" >0.900240</td>\n",
       "      <td id=\"T_c02ba_row3_col2\" class=\"data row3 col2\" >0.844451</td>\n",
       "      <td id=\"T_c02ba_row3_col3\" class=\"data row3 col3\" >0.601767</td>\n",
       "      <td id=\"T_c02ba_row3_col4\" class=\"data row3 col4\" >0.639506</td>\n",
       "      <td id=\"T_c02ba_row3_col5\" class=\"data row3 col5\" >0.332922</td>\n",
       "      <td id=\"T_c02ba_row3_col6\" class=\"data row3 col6\" >0.946089</td>\n",
       "      <td id=\"T_c02ba_row3_col7\" class=\"data row3 col7\" >639.000000</td>\n",
       "      <td id=\"T_c02ba_row3_col8\" class=\"data row3 col8\" >4784.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1434ea1c070>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'fasttext_trained'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\",ds+\"_\"+em+\"_rnn\",ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_word2vec_cnn\n",
      "models/SE2019_word2vec3_cnn\n",
      "models/SE2019_no_train_cnn\n",
      "models/SE2019_no_train3_cnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b1774_row0_col0, #T_b1774_row0_col1, #T_b1774_row0_col2, #T_b1774_row0_col6, #T_b1774_row0_col7, #T_b1774_row0_col8, #T_b1774_row1_col1, #T_b1774_row1_col3, #T_b1774_row1_col4, #T_b1774_row1_col7, #T_b1774_row1_col8, #T_b1774_row2_col7, #T_b1774_row2_col8, #T_b1774_row3_col5, #T_b1774_row3_col7, #T_b1774_row3_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b1774\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b1774_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b1774_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_b1774_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_b1774_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_b1774_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_b1774_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_b1774_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_b1774_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_b1774_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b1774_row0_col0\" class=\"data row0 col0\" >SE2019_word2vec_cnn</td>\n",
       "      <td id=\"T_b1774_row0_col1\" class=\"data row0 col1\" >0.731895</td>\n",
       "      <td id=\"T_b1774_row0_col2\" class=\"data row0 col2\" >0.730780</td>\n",
       "      <td id=\"T_b1774_row0_col3\" class=\"data row0 col3\" >0.719644</td>\n",
       "      <td id=\"T_b1774_row0_col4\" class=\"data row0 col4\" >0.722074</td>\n",
       "      <td id=\"T_b1774_row0_col5\" class=\"data row0 col5\" >0.669829</td>\n",
       "      <td id=\"T_b1774_row0_col6\" class=\"data row0 col6\" >0.774319</td>\n",
       "      <td id=\"T_b1774_row0_col7\" class=\"data row0 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row0_col8\" class=\"data row0 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b1774_row1_col0\" class=\"data row1 col0\" >SE2019_word2vec3_cnn</td>\n",
       "      <td id=\"T_b1774_row1_col1\" class=\"data row1 col1\" >0.731895</td>\n",
       "      <td id=\"T_b1774_row1_col2\" class=\"data row1 col2\" >0.730117</td>\n",
       "      <td id=\"T_b1774_row1_col3\" class=\"data row1 col3\" >0.720425</td>\n",
       "      <td id=\"T_b1774_row1_col4\" class=\"data row1 col4\" >0.722729</td>\n",
       "      <td id=\"T_b1774_row1_col5\" class=\"data row1 col5\" >0.672316</td>\n",
       "      <td id=\"T_b1774_row1_col6\" class=\"data row1 col6\" >0.773142</td>\n",
       "      <td id=\"T_b1774_row1_col7\" class=\"data row1 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row1_col8\" class=\"data row1 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b1774_row2_col0\" class=\"data row2 col0\" >SE2019_no_train_cnn</td>\n",
       "      <td id=\"T_b1774_row2_col1\" class=\"data row2 col1\" >0.710324</td>\n",
       "      <td id=\"T_b1774_row2_col2\" class=\"data row2 col2\" >0.706902</td>\n",
       "      <td id=\"T_b1774_row2_col3\" class=\"data row2 col3\" >0.699098</td>\n",
       "      <td id=\"T_b1774_row2_col4\" class=\"data row2 col4\" >0.700933</td>\n",
       "      <td id=\"T_b1774_row2_col5\" class=\"data row2 col5\" >0.647940</td>\n",
       "      <td id=\"T_b1774_row2_col6\" class=\"data row2 col6\" >0.753927</td>\n",
       "      <td id=\"T_b1774_row2_col7\" class=\"data row2 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row2_col8\" class=\"data row2 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b1774_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b1774_row3_col0\" class=\"data row3 col0\" >SE2019_no_train3_cnn</td>\n",
       "      <td id=\"T_b1774_row3_col1\" class=\"data row3 col1\" >0.705701</td>\n",
       "      <td id=\"T_b1774_row3_col2\" class=\"data row3 col2\" >0.702347</td>\n",
       "      <td id=\"T_b1774_row3_col3\" class=\"data row3 col3\" >0.704561</td>\n",
       "      <td id=\"T_b1774_row3_col4\" class=\"data row3 col4\" >0.702902</td>\n",
       "      <td id=\"T_b1774_row3_col5\" class=\"data row3 col5\" >0.674061</td>\n",
       "      <td id=\"T_b1774_row3_col6\" class=\"data row3 col6\" >0.731742</td>\n",
       "      <td id=\"T_b1774_row3_col7\" class=\"data row3 col7\" >568.000000</td>\n",
       "      <td id=\"T_b1774_row3_col8\" class=\"data row3 col8\" >730.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x183cf06c2e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"SE2019\"\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\",ds+\"_\"+em+\"3_cnn\",ds+\"_no_train_cnn\",ds+\"_no_train3_cnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 35s 44ms/step - loss: 0.3068 - accuracy: 0.8880 - precision: 0.6301 - recall: 0.2231 - val_loss: 0.2695 - val_accuracy: 0.8931 - val_precision: 0.6594 - val_recall: 0.2725\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.1754 - accuracy: 0.9336 - precision: 0.8073 - recall: 0.6066 - val_loss: 0.3079 - val_accuracy: 0.8879 - val_precision: 0.5798 - val_recall: 0.3263\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 33s 43ms/step - loss: 0.0583 - accuracy: 0.9812 - precision: 0.9525 - recall: 0.8920 - val_loss: 0.4039 - val_accuracy: 0.8831 - val_precision: 0.5392 - val_recall: 0.3503\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.0180 - accuracy: 0.9947 - precision: 0.9885 - recall: 0.9684 - val_loss: 0.4873 - val_accuracy: 0.8779 - val_precision: 0.5059 - val_recall: 0.3862\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 31s 41ms/step - loss: 0.0082 - accuracy: 0.9976 - precision: 0.9943 - recall: 0.9864 - val_loss: 0.5623 - val_accuracy: 0.8802 - val_precision: 0.5204 - val_recall: 0.3443\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 31s 40ms/step - loss: 0.0050 - accuracy: 0.9986 - precision: 0.9963 - recall: 0.9924 - val_loss: 0.6261 - val_accuracy: 0.8772 - val_precision: 0.5024 - val_recall: 0.3084\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 35s 46ms/step - loss: 0.0041 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9950 - val_loss: 0.6674 - val_accuracy: 0.8791 - val_precision: 0.5146 - val_recall: 0.3174\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 33s 44ms/step - loss: 0.0033 - accuracy: 0.9992 - precision: 0.9973 - recall: 0.9960 - val_loss: 0.6752 - val_accuracy: 0.8721 - val_precision: 0.4780 - val_recall: 0.4222\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 30s 39ms/step - loss: 0.0033 - accuracy: 0.9991 - precision: 0.9967 - recall: 0.9960 - val_loss: 0.7314 - val_accuracy: 0.8768 - val_precision: 0.5000 - val_recall: 0.3234\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 35s 46ms/step - loss: 0.0032 - accuracy: 0.9993 - precision: 0.9973 - recall: 0.9967 - val_loss: 0.7651 - val_accuracy: 0.8798 - val_precision: 0.5185 - val_recall: 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_cnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_cnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8930678367614746\n",
      "rnn\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 115s 148ms/step - loss: 0.1489 - accuracy: 0.9422 - precision: 0.8159 - recall: 0.6863 - val_loss: 0.4125 - val_accuracy: 0.8698 - val_precision: 0.4570 - val_recall: 0.3024\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 121s 158ms/step - loss: 0.0597 - accuracy: 0.9793 - precision: 0.9230 - recall: 0.9083 - val_loss: 0.4803 - val_accuracy: 0.8551 - val_precision: 0.4013 - val_recall: 0.3593\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 119s 156ms/step - loss: 0.0302 - accuracy: 0.9889 - precision: 0.9576 - recall: 0.9525 - val_loss: 0.6529 - val_accuracy: 0.8654 - val_precision: 0.4317 - val_recall: 0.2934\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 117s 154ms/step - loss: 0.0173 - accuracy: 0.9945 - precision: 0.9813 - recall: 0.9744 - val_loss: 0.7736 - val_accuracy: 0.8595 - val_precision: 0.4041 - val_recall: 0.2964\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 115s 150ms/step - loss: 0.0107 - accuracy: 0.9967 - precision: 0.9870 - recall: 0.9864 - val_loss: 0.6590 - val_accuracy: 0.8448 - val_precision: 0.2995 - val_recall: 0.1946\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 109s 144ms/step - loss: 0.0118 - accuracy: 0.9961 - precision: 0.9870 - recall: 0.9814 - val_loss: 0.8400 - val_accuracy: 0.8422 - val_precision: 0.3601 - val_recall: 0.3623\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 103s 135ms/step - loss: 0.0109 - accuracy: 0.9966 - precision: 0.9887 - recall: 0.9841 - val_loss: 0.7830 - val_accuracy: 0.8459 - val_precision: 0.3779 - val_recall: 0.3892\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 94s 124ms/step - loss: 0.0120 - accuracy: 0.9961 - precision: 0.9850 - recall: 0.9834 - val_loss: 0.8460 - val_accuracy: 0.8322 - val_precision: 0.3315 - val_recall: 0.3563\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 112s 147ms/step - loss: 0.0079 - accuracy: 0.9972 - precision: 0.9890 - recall: 0.9880 - val_loss: 1.0179 - val_accuracy: 0.8348 - val_precision: 0.3304 - val_recall: 0.3323\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 102s 133ms/step - loss: 0.0064 - accuracy: 0.9979 - precision: 0.9930 - recall: 0.9897 - val_loss: 0.9482 - val_accuracy: 0.8326 - val_precision: 0.3137 - val_recall: 0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_rnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_rnn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.869837760925293\n",
      "lstm\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 358s 464ms/step - loss: 0.0824 - accuracy: 0.9579 - precision: 0.8641 - recall: 0.7814 - val_loss: 0.5779 - val_accuracy: 0.8426 - val_precision: 0.3786 - val_recall: 0.4341\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 296s 388ms/step - loss: 0.0180 - accuracy: 0.9944 - precision: 0.9809 - recall: 0.9734 - val_loss: 0.7569 - val_accuracy: 0.8510 - val_precision: 0.3776 - val_recall: 0.3234\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 301s 394ms/step - loss: 0.0100 - accuracy: 0.9971 - precision: 0.9897 - recall: 0.9867 - val_loss: 0.7764 - val_accuracy: 0.8459 - val_precision: 0.3679 - val_recall: 0.3503\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 307s 402ms/step - loss: 0.0070 - accuracy: 0.9979 - precision: 0.9927 - recall: 0.9900 - val_loss: 0.9544 - val_accuracy: 0.8462 - val_precision: 0.3754 - val_recall: 0.3743\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 311s 408ms/step - loss: 0.0056 - accuracy: 0.9981 - precision: 0.9933 - recall: 0.9914 - val_loss: 0.8721 - val_accuracy: 0.8319 - val_precision: 0.3342 - val_recall: 0.3683\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 305s 400ms/step - loss: 0.0062 - accuracy: 0.9982 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.9005 - val_accuracy: 0.8566 - val_precision: 0.3799 - val_recall: 0.2605\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 316s 415ms/step - loss: 0.0033 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9947 - val_loss: 1.0540 - val_accuracy: 0.8647 - val_precision: 0.4225 - val_recall: 0.2695\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 245s 322ms/step - loss: 0.0053 - accuracy: 0.9981 - precision: 0.9930 - recall: 0.9917 - val_loss: 0.9419 - val_accuracy: 0.8485 - val_precision: 0.3695 - val_recall: 0.3263\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 159s 208ms/step - loss: 0.0037 - accuracy: 0.9985 - precision: 0.9953 - recall: 0.9924 - val_loss: 0.9320 - val_accuracy: 0.8555 - val_precision: 0.3811 - val_recall: 0.2784\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 159s 208ms/step - loss: 0.0035 - accuracy: 0.9989 - precision: 0.9967 - recall: 0.9947 - val_loss: 1.0141 - val_accuracy: 0.8426 - val_precision: 0.3514 - val_recall: 0.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_lstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8425516486167908\n",
      "bilstm\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 306s 392ms/step - loss: 0.0464 - accuracy: 0.9696 - precision: 0.9083 - recall: 0.8382 - val_loss: 0.7997 - val_accuracy: 0.8448 - val_precision: 0.3724 - val_recall: 0.3802\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 310s 407ms/step - loss: 0.0054 - accuracy: 0.9984 - precision: 0.9957 - recall: 0.9910 - val_loss: 0.9759 - val_accuracy: 0.8414 - val_precision: 0.3605 - val_recall: 0.3713\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 314s 411ms/step - loss: 0.0057 - accuracy: 0.9983 - precision: 0.9937 - recall: 0.9924 - val_loss: 0.8995 - val_accuracy: 0.8392 - val_precision: 0.3500 - val_recall: 0.3563\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 309s 405ms/step - loss: 0.0032 - accuracy: 0.9988 - precision: 0.9963 - recall: 0.9940 - val_loss: 1.0786 - val_accuracy: 0.8367 - val_precision: 0.3507 - val_recall: 0.3832\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 316s 414ms/step - loss: 0.0029 - accuracy: 0.9991 - precision: 0.9973 - recall: 0.9957 - val_loss: 0.9066 - val_accuracy: 0.8426 - val_precision: 0.3690 - val_recall: 0.3922\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 325s 426ms/step - loss: 0.0029 - accuracy: 0.9989 - precision: 0.9963 - recall: 0.9944 - val_loss: 1.1307 - val_accuracy: 0.8389 - val_precision: 0.3648 - val_recall: 0.4162\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 326s 428ms/step - loss: 0.0024 - accuracy: 0.9989 - precision: 0.9967 - recall: 0.9940 - val_loss: 1.0283 - val_accuracy: 0.8285 - val_precision: 0.3235 - val_recall: 0.3593\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 314s 411ms/step - loss: 0.0020 - accuracy: 0.9993 - precision: 0.9983 - recall: 0.9957 - val_loss: 1.1044 - val_accuracy: 0.8407 - val_precision: 0.3497 - val_recall: 0.3413\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 307s 402ms/step - loss: 0.0018 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9960 - val_loss: 1.1312 - val_accuracy: 0.8352 - val_precision: 0.3408 - val_recall: 0.3623\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 303s 397ms/step - loss: 0.0022 - accuracy: 0.9991 - precision: 0.9970 - recall: 0.9960 - val_loss: 1.0695 - val_accuracy: 0.8027 - val_precision: 0.2994 - val_recall: 0.4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_bilstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_bilstm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.844763994216919\n",
      "gru\n",
      "Epoch 1/10\n",
      "763/763 [==============================] - 216s 278ms/step - loss: 0.0371 - accuracy: 0.9689 - precision: 0.8759 - recall: 0.8717 - val_loss: 0.8563 - val_accuracy: 0.8378 - val_precision: 0.3209 - val_recall: 0.2844\n",
      "Epoch 2/10\n",
      "763/763 [==============================] - 199s 261ms/step - loss: 0.0039 - accuracy: 0.9990 - precision: 0.9983 - recall: 0.9937 - val_loss: 1.0127 - val_accuracy: 0.8355 - val_precision: 0.3427 - val_recall: 0.3653\n",
      "Epoch 3/10\n",
      "763/763 [==============================] - 201s 264ms/step - loss: 0.0038 - accuracy: 0.9990 - precision: 0.9970 - recall: 0.9947 - val_loss: 0.9929 - val_accuracy: 0.8348 - val_precision: 0.3443 - val_recall: 0.3772\n",
      "Epoch 4/10\n",
      "763/763 [==============================] - 204s 268ms/step - loss: 0.0040 - accuracy: 0.9988 - precision: 0.9963 - recall: 0.9937 - val_loss: 1.0385 - val_accuracy: 0.8274 - val_precision: 0.3255 - val_recall: 0.3743\n",
      "Epoch 5/10\n",
      "763/763 [==============================] - 205s 269ms/step - loss: 0.0024 - accuracy: 0.9991 - precision: 0.9960 - recall: 0.9963 - val_loss: 1.2110 - val_accuracy: 0.8378 - val_precision: 0.3520 - val_recall: 0.3772\n",
      "Epoch 6/10\n",
      "763/763 [==============================] - 211s 276ms/step - loss: 0.0022 - accuracy: 0.9992 - precision: 0.9980 - recall: 0.9957 - val_loss: 1.1862 - val_accuracy: 0.8385 - val_precision: 0.3514 - val_recall: 0.3683\n",
      "Epoch 7/10\n",
      "763/763 [==============================] - 207s 272ms/step - loss: 0.0018 - accuracy: 0.9993 - precision: 0.9970 - recall: 0.9970 - val_loss: 1.2740 - val_accuracy: 0.8274 - val_precision: 0.3299 - val_recall: 0.3892\n",
      "Epoch 8/10\n",
      "763/763 [==============================] - 198s 259ms/step - loss: 0.0015 - accuracy: 0.9994 - precision: 0.9987 - recall: 0.9963 - val_loss: 1.4557 - val_accuracy: 0.8355 - val_precision: 0.3519 - val_recall: 0.3982\n",
      "Epoch 9/10\n",
      "763/763 [==============================] - 212s 277ms/step - loss: 0.0045 - accuracy: 0.9984 - precision: 0.9940 - recall: 0.9927 - val_loss: 1.0820 - val_accuracy: 0.8348 - val_precision: 0.3476 - val_recall: 0.3892\n",
      "Epoch 10/10\n",
      "763/763 [==============================] - 200s 262ms/step - loss: 0.0020 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9960 - val_loss: 1.1602 - val_accuracy: 0.8359 - val_precision: 0.3419 - val_recall: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_6_layer_call_fn, gru_cell_6_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_gru\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/GabHateCorpus_no_train_gru\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8377581238746643\n"
     ]
    }
   ],
   "source": [
    "h = cnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = rnn(custom_encoder,custom_embedding,embedding_name)\n",
    "h = lstm(custom_encoder,custom_embedding,embedding_name)\n",
    "h = bilstm(custom_encoder,custom_embedding,embedding_name)\n",
    "h = gru(custom_encoder,custom_embedding,embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/Implicit_hate_corpus_fasttext_cnn\n",
      "models/Implicit_hate_corpus_fasttext_rnn\n",
      "models/Implicit_hate_corpus_fasttext_lstm\n",
      "models/Implicit_hate_corpus_fasttext_bilstm\n",
      "models/Implicit_hate_corpus_fasttext_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e754e_row0_col5, #T_e754e_row0_col7, #T_e754e_row0_col8, #T_e754e_row1_col0, #T_e754e_row1_col7, #T_e754e_row1_col8, #T_e754e_row2_col7, #T_e754e_row2_col8, #T_e754e_row3_col1, #T_e754e_row3_col3, #T_e754e_row3_col4, #T_e754e_row3_col7, #T_e754e_row3_col8, #T_e754e_row4_col2, #T_e754e_row4_col6, #T_e754e_row4_col7, #T_e754e_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e754e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e754e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e754e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e754e_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_e754e_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_e754e_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_e754e_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_e754e_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_e754e_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_e754e_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e754e_row0_col0\" class=\"data row0 col0\" >Implicit_hate_corpus_fasttext_cnn</td>\n",
       "      <td id=\"T_e754e_row0_col1\" class=\"data row0 col1\" >0.691962</td>\n",
       "      <td id=\"T_e754e_row0_col2\" class=\"data row0 col2\" >0.672204</td>\n",
       "      <td id=\"T_e754e_row0_col3\" class=\"data row0 col3\" >0.673499</td>\n",
       "      <td id=\"T_e754e_row0_col4\" class=\"data row0 col4\" >0.672811</td>\n",
       "      <td id=\"T_e754e_row0_col5\" class=\"data row0 col5\" >0.593654</td>\n",
       "      <td id=\"T_e754e_row0_col6\" class=\"data row0 col6\" >0.751968</td>\n",
       "      <td id=\"T_e754e_row0_col7\" class=\"data row0 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row0_col8\" class=\"data row0 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e754e_row1_col0\" class=\"data row1 col0\" >Implicit_hate_corpus_fasttext_rnn</td>\n",
       "      <td id=\"T_e754e_row1_col1\" class=\"data row1 col1\" >0.699876</td>\n",
       "      <td id=\"T_e754e_row1_col2\" class=\"data row1 col2\" >0.682861</td>\n",
       "      <td id=\"T_e754e_row1_col3\" class=\"data row1 col3\" >0.647670</td>\n",
       "      <td id=\"T_e754e_row1_col4\" class=\"data row1 col4\" >0.652007</td>\n",
       "      <td id=\"T_e754e_row1_col5\" class=\"data row1 col5\" >0.522940</td>\n",
       "      <td id=\"T_e754e_row1_col6\" class=\"data row1 col6\" >0.781073</td>\n",
       "      <td id=\"T_e754e_row1_col7\" class=\"data row1 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row1_col8\" class=\"data row1 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e754e_row2_col0\" class=\"data row2 col0\" >Implicit_hate_corpus_fasttext_lstm</td>\n",
       "      <td id=\"T_e754e_row2_col1\" class=\"data row2 col1\" >0.714618</td>\n",
       "      <td id=\"T_e754e_row2_col2\" class=\"data row2 col2\" >0.698594</td>\n",
       "      <td id=\"T_e754e_row2_col3\" class=\"data row2 col3\" >0.669451</td>\n",
       "      <td id=\"T_e754e_row2_col4\" class=\"data row2 col4\" >0.675276</td>\n",
       "      <td id=\"T_e754e_row2_col5\" class=\"data row2 col5\" >0.562247</td>\n",
       "      <td id=\"T_e754e_row2_col6\" class=\"data row2 col6\" >0.788304</td>\n",
       "      <td id=\"T_e754e_row2_col7\" class=\"data row2 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row2_col8\" class=\"data row2 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e754e_row3_col0\" class=\"data row3 col0\" >Implicit_hate_corpus_fasttext_bilstm</td>\n",
       "      <td id=\"T_e754e_row3_col1\" class=\"data row3 col1\" >0.717722</td>\n",
       "      <td id=\"T_e754e_row3_col2\" class=\"data row3 col2\" >0.700199</td>\n",
       "      <td id=\"T_e754e_row3_col3\" class=\"data row3 col3\" >0.677956</td>\n",
       "      <td id=\"T_e754e_row3_col4\" class=\"data row3 col4\" >0.683571</td>\n",
       "      <td id=\"T_e754e_row3_col5\" class=\"data row3 col5\" >0.579616</td>\n",
       "      <td id=\"T_e754e_row3_col6\" class=\"data row3 col6\" >0.787525</td>\n",
       "      <td id=\"T_e754e_row3_col7\" class=\"data row3 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row3_col8\" class=\"data row3 col8\" >4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e754e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e754e_row4_col0\" class=\"data row4 col0\" >Implicit_hate_corpus_fasttext_gru</td>\n",
       "      <td id=\"T_e754e_row4_col1\" class=\"data row4 col1\" >0.714618</td>\n",
       "      <td id=\"T_e754e_row4_col2\" class=\"data row4 col2\" >0.703246</td>\n",
       "      <td id=\"T_e754e_row4_col3\" class=\"data row4 col3\" >0.662193</td>\n",
       "      <td id=\"T_e754e_row4_col4\" class=\"data row4 col4\" >0.667807</td>\n",
       "      <td id=\"T_e754e_row4_col5\" class=\"data row4 col5\" >0.543106</td>\n",
       "      <td id=\"T_e754e_row4_col6\" class=\"data row4 col6\" >0.792508</td>\n",
       "      <td id=\"T_e754e_row4_col7\" class=\"data row4 col7\" >2419</td>\n",
       "      <td id=\"T_e754e_row4_col8\" class=\"data row4 col8\" >4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19db4958210>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"Implicit_hate_corpus\"\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_no_train_cnn\n",
      "models/GabHateCorpus_no_train_rnn\n",
      "models/GabHateCorpus_no_train_lstm\n",
      "models/GabHateCorpus_no_train_bilstm\n",
      "models/GabHateCorpus_no_train_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_994a8_row0_col1, #T_994a8_row0_col2, #T_994a8_row0_col4, #T_994a8_row0_col5, #T_994a8_row0_col6, #T_994a8_row0_col7, #T_994a8_row0_col8, #T_994a8_row1_col0, #T_994a8_row1_col7, #T_994a8_row1_col8, #T_994a8_row2_col7, #T_994a8_row2_col8, #T_994a8_row3_col3, #T_994a8_row3_col7, #T_994a8_row3_col8, #T_994a8_row4_col7, #T_994a8_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_994a8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_994a8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_994a8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_994a8_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_994a8_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_994a8_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_994a8_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_994a8_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_994a8_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_994a8_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_994a8_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_no_train_cnn</td>\n",
       "      <td id=\"T_994a8_row0_col1\" class=\"data row0 col1\" >0.879794</td>\n",
       "      <td id=\"T_994a8_row0_col2\" class=\"data row0 col2\" >0.714788</td>\n",
       "      <td id=\"T_994a8_row0_col3\" class=\"data row0 col3\" >0.645798</td>\n",
       "      <td id=\"T_994a8_row0_col4\" class=\"data row0 col4\" >0.670194</td>\n",
       "      <td id=\"T_994a8_row0_col5\" class=\"data row0 col5\" >0.407273</td>\n",
       "      <td id=\"T_994a8_row0_col6\" class=\"data row0 col6\" >0.933114</td>\n",
       "      <td id=\"T_994a8_row0_col7\" class=\"data row0 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row0_col8\" class=\"data row0 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_994a8_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_no_train_rnn</td>\n",
       "      <td id=\"T_994a8_row1_col1\" class=\"data row1 col1\" >0.832596</td>\n",
       "      <td id=\"T_994a8_row1_col2\" class=\"data row1 col2\" >0.608088</td>\n",
       "      <td id=\"T_994a8_row1_col3\" class=\"data row1 col3\" >0.604730</td>\n",
       "      <td id=\"T_994a8_row1_col4\" class=\"data row1 col4\" >0.606354</td>\n",
       "      <td id=\"T_994a8_row1_col5\" class=\"data row1 col5\" >0.307927</td>\n",
       "      <td id=\"T_994a8_row1_col6\" class=\"data row1 col6\" >0.904782</td>\n",
       "      <td id=\"T_994a8_row1_col7\" class=\"data row1 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row1_col8\" class=\"data row1 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_994a8_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_no_train_lstm</td>\n",
       "      <td id=\"T_994a8_row2_col1\" class=\"data row2 col1\" >0.842552</td>\n",
       "      <td id=\"T_994a8_row2_col2\" class=\"data row2 col2\" >0.629033</td>\n",
       "      <td id=\"T_994a8_row2_col3\" class=\"data row2 col3\" >0.621988</td>\n",
       "      <td id=\"T_994a8_row2_col4\" class=\"data row2 col4\" >0.625322</td>\n",
       "      <td id=\"T_994a8_row2_col5\" class=\"data row2 col5\" >0.340031</td>\n",
       "      <td id=\"T_994a8_row2_col6\" class=\"data row2 col6\" >0.910613</td>\n",
       "      <td id=\"T_994a8_row2_col7\" class=\"data row2 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row2_col8\" class=\"data row2 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_994a8_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_no_train_bilstm</td>\n",
       "      <td id=\"T_994a8_row3_col1\" class=\"data row3 col1\" >0.802729</td>\n",
       "      <td id=\"T_994a8_row3_col2\" class=\"data row3 col2\" >0.608090</td>\n",
       "      <td id=\"T_994a8_row3_col3\" class=\"data row3 col3\" >0.650749</td>\n",
       "      <td id=\"T_994a8_row3_col4\" class=\"data row3 col4\" >0.621349</td>\n",
       "      <td id=\"T_994a8_row3_col5\" class=\"data row3 col5\" >0.359281</td>\n",
       "      <td id=\"T_994a8_row3_col6\" class=\"data row3 col6\" >0.883417</td>\n",
       "      <td id=\"T_994a8_row3_col7\" class=\"data row3 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row3_col8\" class=\"data row3 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_994a8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_994a8_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_no_train_gru</td>\n",
       "      <td id=\"T_994a8_row4_col1\" class=\"data row4 col1\" >0.835914</td>\n",
       "      <td id=\"T_994a8_row4_col2\" class=\"data row4 col2\" >0.625620</td>\n",
       "      <td id=\"T_994a8_row4_col3\" class=\"data row4 col3\" >0.631070</td>\n",
       "      <td id=\"T_994a8_row4_col4\" class=\"data row4 col4\" >0.628232</td>\n",
       "      <td id=\"T_994a8_row4_col5\" class=\"data row4 col5\" >0.350365</td>\n",
       "      <td id=\"T_994a8_row4_col6\" class=\"data row4 col6\" >0.906098</td>\n",
       "      <td id=\"T_994a8_row4_col7\" class=\"data row4 col7\" >334</td>\n",
       "      <td id=\"T_994a8_row4_col8\" class=\"data row4 col8\" >2378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fae94e13d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'no_train'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/GabHateCorpus_word2vec_cnn\n",
      "models/GabHateCorpus_word2vec_rnn\n",
      "models/GabHateCorpus_word2vec_lstm\n",
      "models/GabHateCorpus_word2vec_bilstm\n",
      "models/GabHateCorpus_word2vec_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_043a0_row0_col3, #T_043a0_row0_col4, #T_043a0_row0_col5, #T_043a0_row0_col7, #T_043a0_row0_col8, #T_043a0_row1_col0, #T_043a0_row1_col7, #T_043a0_row1_col8, #T_043a0_row2_col7, #T_043a0_row2_col8, #T_043a0_row3_col7, #T_043a0_row3_col8, #T_043a0_row4_col1, #T_043a0_row4_col2, #T_043a0_row4_col6, #T_043a0_row4_col7, #T_043a0_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_043a0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_043a0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_043a0_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_043a0_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_043a0_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_043a0_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_043a0_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_043a0_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_043a0_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_043a0_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_043a0_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_word2vec_cnn</td>\n",
       "      <td id=\"T_043a0_row0_col1\" class=\"data row0 col1\" >0.887906</td>\n",
       "      <td id=\"T_043a0_row0_col2\" class=\"data row0 col2\" >0.746150</td>\n",
       "      <td id=\"T_043a0_row0_col3\" class=\"data row0 col3\" >0.642703</td>\n",
       "      <td id=\"T_043a0_row0_col4\" class=\"data row0 col4\" >0.674457</td>\n",
       "      <td id=\"T_043a0_row0_col5\" class=\"data row0 col5\" >0.410853</td>\n",
       "      <td id=\"T_043a0_row0_col6\" class=\"data row0 col6\" >0.938060</td>\n",
       "      <td id=\"T_043a0_row0_col7\" class=\"data row0 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row0_col8\" class=\"data row0 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_043a0_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_word2vec_rnn</td>\n",
       "      <td id=\"T_043a0_row1_col1\" class=\"data row1 col1\" >0.873894</td>\n",
       "      <td id=\"T_043a0_row1_col2\" class=\"data row1 col2\" >0.694916</td>\n",
       "      <td id=\"T_043a0_row1_col3\" class=\"data row1 col3\" >0.633426</td>\n",
       "      <td id=\"T_043a0_row1_col4\" class=\"data row1 col4\" >0.655119</td>\n",
       "      <td id=\"T_043a0_row1_col5\" class=\"data row1 col5\" >0.380435</td>\n",
       "      <td id=\"T_043a0_row1_col6\" class=\"data row1 col6\" >0.929803</td>\n",
       "      <td id=\"T_043a0_row1_col7\" class=\"data row1 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row1_col8\" class=\"data row1 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_043a0_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_word2vec_lstm</td>\n",
       "      <td id=\"T_043a0_row2_col1\" class=\"data row2 col1\" >0.888274</td>\n",
       "      <td id=\"T_043a0_row2_col2\" class=\"data row2 col2\" >0.775411</td>\n",
       "      <td id=\"T_043a0_row2_col3\" class=\"data row2 col3\" >0.591443</td>\n",
       "      <td id=\"T_043a0_row2_col4\" class=\"data row2 col4\" >0.621357</td>\n",
       "      <td id=\"T_043a0_row2_col5\" class=\"data row2 col5\" >0.303448</td>\n",
       "      <td id=\"T_043a0_row2_col6\" class=\"data row2 col6\" >0.939266</td>\n",
       "      <td id=\"T_043a0_row2_col7\" class=\"data row2 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row2_col8\" class=\"data row2 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_043a0_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_word2vec_bilstm</td>\n",
       "      <td id=\"T_043a0_row3_col1\" class=\"data row3 col1\" >0.884956</td>\n",
       "      <td id=\"T_043a0_row3_col2\" class=\"data row3 col2\" >0.734727</td>\n",
       "      <td id=\"T_043a0_row3_col3\" class=\"data row3 col3\" >0.633300</td>\n",
       "      <td id=\"T_043a0_row3_col4\" class=\"data row3 col4\" >0.663554</td>\n",
       "      <td id=\"T_043a0_row3_col5\" class=\"data row3 col5\" >0.390625</td>\n",
       "      <td id=\"T_043a0_row3_col6\" class=\"data row3 col6\" >0.936482</td>\n",
       "      <td id=\"T_043a0_row3_col7\" class=\"data row3 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row3_col8\" class=\"data row3 col8\" >2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_043a0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_043a0_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_word2vec_gru</td>\n",
       "      <td id=\"T_043a0_row4_col1\" class=\"data row4 col1\" >0.893437</td>\n",
       "      <td id=\"T_043a0_row4_col2\" class=\"data row4 col2\" >0.807469</td>\n",
       "      <td id=\"T_043a0_row4_col3\" class=\"data row4 col3\" >0.605968</td>\n",
       "      <td id=\"T_043a0_row4_col4\" class=\"data row4 col4\" >0.641856</td>\n",
       "      <td id=\"T_043a0_row4_col5\" class=\"data row4 col5\" >0.341686</td>\n",
       "      <td id=\"T_043a0_row4_col6\" class=\"data row4 col6\" >0.942026</td>\n",
       "      <td id=\"T_043a0_row4_col7\" class=\"data row4 col7\" >334</td>\n",
       "      <td id=\"T_043a0_row4_col8\" class=\"data row4 col8\" >2378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fb282f6510>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5372_row0_col6, #T_f5372_row0_col8, #T_f5372_row1_col0, #T_f5372_row1_col6, #T_f5372_row1_col8, #T_f5372_row2_col1, #T_f5372_row2_col2, #T_f5372_row2_col6, #T_f5372_row2_col7, #T_f5372_row2_col8, #T_f5372_row3_col6, #T_f5372_row3_col8, #T_f5372_row4_col3, #T_f5372_row4_col4, #T_f5372_row4_col5, #T_f5372_row4_col6, #T_f5372_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5372\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5372_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f5372_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f5372_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_f5372_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_f5372_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_f5372_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_f5372_level0_col6\" class=\"col_heading level0 col6\" >hate support</th>\n",
       "      <th id=\"T_f5372_level0_col7\" class=\"col_heading level0 col7\" >non-hate f1</th>\n",
       "      <th id=\"T_f5372_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5372_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_fasttext_cnn</td>\n",
       "      <td id=\"T_f5372_row0_col1\" class=\"data row0 col1\" >0.883944</td>\n",
       "      <td id=\"T_f5372_row0_col2\" class=\"data row0 col2\" >0.724345</td>\n",
       "      <td id=\"T_f5372_row0_col3\" class=\"data row0 col3\" >0.603634</td>\n",
       "      <td id=\"T_f5372_row0_col4\" class=\"data row0 col4\" >0.632063</td>\n",
       "      <td id=\"T_f5372_row0_col5\" class=\"data row0 col5\" >0.327635</td>\n",
       "      <td id=\"T_f5372_row0_col6\" class=\"data row0 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row0_col7\" class=\"data row0 col7\" >0.936491</td>\n",
       "      <td id=\"T_f5372_row0_col8\" class=\"data row0 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5372_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_fasttext_rnn</td>\n",
       "      <td id=\"T_f5372_row1_col1\" class=\"data row1 col1\" >0.879149</td>\n",
       "      <td id=\"T_f5372_row1_col2\" class=\"data row1 col2\" >0.689995</td>\n",
       "      <td id=\"T_f5372_row1_col3\" class=\"data row1 col3\" >0.503949</td>\n",
       "      <td id=\"T_f5372_row1_col4\" class=\"data row1 col4\" >0.476797</td>\n",
       "      <td id=\"T_f5372_row1_col5\" class=\"data row1 col5\" >0.017982</td>\n",
       "      <td id=\"T_f5372_row1_col6\" class=\"data row1 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row1_col7\" class=\"data row1 col7\" >0.935613</td>\n",
       "      <td id=\"T_f5372_row1_col8\" class=\"data row1 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5372_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_fasttext_lstm</td>\n",
       "      <td id=\"T_f5372_row2_col1\" class=\"data row2 col1\" >0.891320</td>\n",
       "      <td id=\"T_f5372_row2_col2\" class=\"data row2 col2\" >0.795910</td>\n",
       "      <td id=\"T_f5372_row2_col3\" class=\"data row2 col3\" >0.584577</td>\n",
       "      <td id=\"T_f5372_row2_col4\" class=\"data row2 col4\" >0.613565</td>\n",
       "      <td id=\"T_f5372_row2_col5\" class=\"data row2 col5\" >0.285945</td>\n",
       "      <td id=\"T_f5372_row2_col6\" class=\"data row2 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row2_col7\" class=\"data row2 col7\" >0.941184</td>\n",
       "      <td id=\"T_f5372_row2_col8\" class=\"data row2 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5372_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_fasttext_bilstm</td>\n",
       "      <td id=\"T_f5372_row3_col1\" class=\"data row3 col1\" >0.890214</td>\n",
       "      <td id=\"T_f5372_row3_col2\" class=\"data row3 col2\" >0.755402</td>\n",
       "      <td id=\"T_f5372_row3_col3\" class=\"data row3 col3\" >0.620362</td>\n",
       "      <td id=\"T_f5372_row3_col4\" class=\"data row3 col4\" >0.653948</td>\n",
       "      <td id=\"T_f5372_row3_col5\" class=\"data row3 col5\" >0.368011</td>\n",
       "      <td id=\"T_f5372_row3_col6\" class=\"data row3 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row3_col7\" class=\"data row3 col7\" >0.939886</td>\n",
       "      <td id=\"T_f5372_row3_col8\" class=\"data row3 col8\" >7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5372_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5372_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_fasttext_gru</td>\n",
       "      <td id=\"T_f5372_row4_col1\" class=\"data row4 col1\" >0.889107</td>\n",
       "      <td id=\"T_f5372_row4_col2\" class=\"data row4 col2\" >0.740086</td>\n",
       "      <td id=\"T_f5372_row4_col3\" class=\"data row4 col3\" >0.664044</td>\n",
       "      <td id=\"T_f5372_row4_col4\" class=\"data row4 col4\" >0.691493</td>\n",
       "      <td id=\"T_f5372_row4_col5\" class=\"data row4 col5\" >0.444581</td>\n",
       "      <td id=\"T_f5372_row4_col6\" class=\"data row4 col6\" >983</td>\n",
       "      <td id=\"T_f5372_row4_col7\" class=\"data row4 col7\" >0.938405</td>\n",
       "      <td id=\"T_f5372_row4_col8\" class=\"data row4 col8\" >7151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22adb39c2d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds =\"GabHateCorpus\"\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26f23_row1_col0, #T_26f23_row2_col1, #T_26f23_row2_col2, #T_26f23_row2_col3, #T_26f23_row2_col4 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26f23\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_26f23_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_26f23_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_26f23_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_26f23_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_26f23_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_26f23_row0_col0\" class=\"data row0 col0\" >GabHateCorpus_glove_cnn</td>\n",
       "      <td id=\"T_26f23_row0_col1\" class=\"data row0 col1\" >0.887755</td>\n",
       "      <td id=\"T_26f23_row0_col2\" class=\"data row0 col2\" >0.864472</td>\n",
       "      <td id=\"T_26f23_row0_col3\" class=\"data row0 col3\" >0.887755</td>\n",
       "      <td id=\"T_26f23_row0_col4\" class=\"data row0 col4\" >0.864063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_26f23_row1_col0\" class=\"data row1 col0\" >GabHateCorpus_glove_rnn</td>\n",
       "      <td id=\"T_26f23_row1_col1\" class=\"data row1 col1\" >0.885050</td>\n",
       "      <td id=\"T_26f23_row1_col2\" class=\"data row1 col2\" >0.858332</td>\n",
       "      <td id=\"T_26f23_row1_col3\" class=\"data row1 col3\" >0.885050</td>\n",
       "      <td id=\"T_26f23_row1_col4\" class=\"data row1 col4\" >0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_26f23_row2_col0\" class=\"data row2 col0\" >GabHateCorpus_glove_lstm</td>\n",
       "      <td id=\"T_26f23_row2_col1\" class=\"data row2 col1\" >0.892304</td>\n",
       "      <td id=\"T_26f23_row2_col2\" class=\"data row2 col2\" >0.880023</td>\n",
       "      <td id=\"T_26f23_row2_col3\" class=\"data row2 col3\" >0.892304</td>\n",
       "      <td id=\"T_26f23_row2_col4\" class=\"data row2 col4\" >0.884057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_26f23_row3_col0\" class=\"data row3 col0\" >GabHateCorpus_glove_bilstm</td>\n",
       "      <td id=\"T_26f23_row3_col1\" class=\"data row3 col1\" >0.880747</td>\n",
       "      <td id=\"T_26f23_row3_col2\" class=\"data row3 col2\" >0.872886</td>\n",
       "      <td id=\"T_26f23_row3_col3\" class=\"data row3 col3\" >0.880747</td>\n",
       "      <td id=\"T_26f23_row3_col4\" class=\"data row3 col4\" >0.876315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26f23_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_26f23_row4_col0\" class=\"data row4 col0\" >GabHateCorpus_glove_gru</td>\n",
       "      <td id=\"T_26f23_row4_col1\" class=\"data row4 col1\" >0.882837</td>\n",
       "      <td id=\"T_26f23_row4_col2\" class=\"data row4 col2\" >0.876953</td>\n",
       "      <td id=\"T_26f23_row4_col3\" class=\"data row4 col3\" >0.882837</td>\n",
       "      <td id=\"T_26f23_row4_col4\" class=\"data row4 col4\" >0.879606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23b9d55ce10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'GabHateCorpus'\n",
    "em = 'glove'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_word2vec_cnn\n",
      "models/SE2019_word2vec_rnn\n",
      "models/SE2019_word2vec_lstm\n",
      "models/SE2019_word2vec_bilstm\n",
      "models/SE2019_word2vec_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aeaa9_row0_col5, #T_aeaa9_row0_col7, #T_aeaa9_row0_col8, #T_aeaa9_row1_col0, #T_aeaa9_row1_col7, #T_aeaa9_row1_col8, #T_aeaa9_row2_col2, #T_aeaa9_row2_col6, #T_aeaa9_row2_col7, #T_aeaa9_row2_col8, #T_aeaa9_row3_col7, #T_aeaa9_row3_col8, #T_aeaa9_row4_col1, #T_aeaa9_row4_col3, #T_aeaa9_row4_col4, #T_aeaa9_row4_col7, #T_aeaa9_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aeaa9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aeaa9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_aeaa9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_aeaa9_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_aeaa9_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_aeaa9_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_aeaa9_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_aeaa9_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_aeaa9_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_aeaa9_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aeaa9_row0_col0\" class=\"data row0 col0\" >SE2019_word2vec_cnn</td>\n",
       "      <td id=\"T_aeaa9_row0_col1\" class=\"data row0 col1\" >0.700488</td>\n",
       "      <td id=\"T_aeaa9_row0_col2\" class=\"data row0 col2\" >0.696548</td>\n",
       "      <td id=\"T_aeaa9_row0_col3\" class=\"data row0 col3\" >0.700337</td>\n",
       "      <td id=\"T_aeaa9_row0_col4\" class=\"data row0 col4\" >0.697045</td>\n",
       "      <td id=\"T_aeaa9_row0_col5\" class=\"data row0 col5\" >0.664750</td>\n",
       "      <td id=\"T_aeaa9_row0_col6\" class=\"data row0 col6\" >0.729341</td>\n",
       "      <td id=\"T_aeaa9_row0_col7\" class=\"data row0 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row0_col8\" class=\"data row0 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aeaa9_row1_col0\" class=\"data row1 col0\" >SE2019_word2vec_rnn</td>\n",
       "      <td id=\"T_aeaa9_row1_col1\" class=\"data row1 col1\" >0.669407</td>\n",
       "      <td id=\"T_aeaa9_row1_col2\" class=\"data row1 col2\" >0.660556</td>\n",
       "      <td id=\"T_aeaa9_row1_col3\" class=\"data row1 col3\" >0.655255</td>\n",
       "      <td id=\"T_aeaa9_row1_col4\" class=\"data row1 col4\" >0.656664</td>\n",
       "      <td id=\"T_aeaa9_row1_col5\" class=\"data row1 col5\" >0.590519</td>\n",
       "      <td id=\"T_aeaa9_row1_col6\" class=\"data row1 col6\" >0.722809</td>\n",
       "      <td id=\"T_aeaa9_row1_col7\" class=\"data row1 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row1_col8\" class=\"data row1 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aeaa9_row2_col0\" class=\"data row2 col0\" >SE2019_word2vec_lstm</td>\n",
       "      <td id=\"T_aeaa9_row2_col1\" class=\"data row2 col1\" >0.713332</td>\n",
       "      <td id=\"T_aeaa9_row2_col2\" class=\"data row2 col2\" >0.711090</td>\n",
       "      <td id=\"T_aeaa9_row2_col3\" class=\"data row2 col3\" >0.693266</td>\n",
       "      <td id=\"T_aeaa9_row2_col4\" class=\"data row2 col4\" >0.696179</td>\n",
       "      <td id=\"T_aeaa9_row2_col5\" class=\"data row2 col5\" >0.623989</td>\n",
       "      <td id=\"T_aeaa9_row2_col6\" class=\"data row2 col6\" >0.768369</td>\n",
       "      <td id=\"T_aeaa9_row2_col7\" class=\"data row2 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row2_col8\" class=\"data row2 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aeaa9_row3_col0\" class=\"data row3 col0\" >SE2019_word2vec_bilstm</td>\n",
       "      <td id=\"T_aeaa9_row3_col1\" class=\"data row3 col1\" >0.713075</td>\n",
       "      <td id=\"T_aeaa9_row3_col2\" class=\"data row3 col2\" >0.708568</td>\n",
       "      <td id=\"T_aeaa9_row3_col3\" class=\"data row3 col3\" >0.695976</td>\n",
       "      <td id=\"T_aeaa9_row3_col4\" class=\"data row3 col4\" >0.698712</td>\n",
       "      <td id=\"T_aeaa9_row3_col5\" class=\"data row3 col5\" >0.632928</td>\n",
       "      <td id=\"T_aeaa9_row3_col6\" class=\"data row3 col6\" >0.764495</td>\n",
       "      <td id=\"T_aeaa9_row3_col7\" class=\"data row3 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row3_col8\" class=\"data row3 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aeaa9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aeaa9_row4_col0\" class=\"data row4 col0\" >SE2019_word2vec_gru</td>\n",
       "      <td id=\"T_aeaa9_row4_col1\" class=\"data row4 col1\" >0.717185</td>\n",
       "      <td id=\"T_aeaa9_row4_col2\" class=\"data row4 col2\" >0.710524</td>\n",
       "      <td id=\"T_aeaa9_row4_col3\" class=\"data row4 col3\" >0.706840</td>\n",
       "      <td id=\"T_aeaa9_row4_col4\" class=\"data row4 col4\" >0.708230</td>\n",
       "      <td id=\"T_aeaa9_row4_col5\" class=\"data row4 col5\" >0.657116</td>\n",
       "      <td id=\"T_aeaa9_row4_col6\" class=\"data row4 col6\" >0.759344</td>\n",
       "      <td id=\"T_aeaa9_row4_col7\" class=\"data row4 col7\" >1653</td>\n",
       "      <td id=\"T_aeaa9_row4_col8\" class=\"data row4 col8\" >2240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1faff4f8510>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'word2vec'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/SE2019_fasttext_cnn\n",
      "models/SE2019_fasttext_rnn\n",
      "models/SE2019_fasttext_lstm\n",
      "models/SE2019_fasttext_bilstm\n",
      "models/SE2019_fasttext_gru\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd23c_row0_col7, #T_bd23c_row0_col8, #T_bd23c_row1_col0, #T_bd23c_row1_col7, #T_bd23c_row1_col8, #T_bd23c_row2_col6, #T_bd23c_row2_col7, #T_bd23c_row2_col8, #T_bd23c_row3_col1, #T_bd23c_row3_col2, #T_bd23c_row3_col3, #T_bd23c_row3_col4, #T_bd23c_row3_col5, #T_bd23c_row3_col7, #T_bd23c_row3_col8, #T_bd23c_row4_col7, #T_bd23c_row4_col8 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd23c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd23c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bd23c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_bd23c_level0_col2\" class=\"col_heading level0 col2\" >precision</th>\n",
       "      <th id=\"T_bd23c_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_bd23c_level0_col4\" class=\"col_heading level0 col4\" >f1-score</th>\n",
       "      <th id=\"T_bd23c_level0_col5\" class=\"col_heading level0 col5\" >hate f1</th>\n",
       "      <th id=\"T_bd23c_level0_col6\" class=\"col_heading level0 col6\" >non-hate f1</th>\n",
       "      <th id=\"T_bd23c_level0_col7\" class=\"col_heading level0 col7\" >hate support</th>\n",
       "      <th id=\"T_bd23c_level0_col8\" class=\"col_heading level0 col8\" >non-hate support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd23c_row0_col0\" class=\"data row0 col0\" >SE2019_fasttext_cnn</td>\n",
       "      <td id=\"T_bd23c_row0_col1\" class=\"data row0 col1\" >0.701259</td>\n",
       "      <td id=\"T_bd23c_row0_col2\" class=\"data row0 col2\" >0.696076</td>\n",
       "      <td id=\"T_bd23c_row0_col3\" class=\"data row0 col3\" >0.699025</td>\n",
       "      <td id=\"T_bd23c_row0_col4\" class=\"data row0 col4\" >0.696878</td>\n",
       "      <td id=\"T_bd23c_row0_col5\" class=\"data row0 col5\" >0.660438</td>\n",
       "      <td id=\"T_bd23c_row0_col6\" class=\"data row0 col6\" >0.733318</td>\n",
       "      <td id=\"T_bd23c_row0_col7\" class=\"data row0 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row0_col8\" class=\"data row0 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd23c_row1_col0\" class=\"data row1 col0\" >SE2019_fasttext_rnn</td>\n",
       "      <td id=\"T_bd23c_row1_col1\" class=\"data row1 col1\" >0.682764</td>\n",
       "      <td id=\"T_bd23c_row1_col2\" class=\"data row1 col2\" >0.679793</td>\n",
       "      <td id=\"T_bd23c_row1_col3\" class=\"data row1 col3\" >0.658064</td>\n",
       "      <td id=\"T_bd23c_row1_col4\" class=\"data row1 col4\" >0.659184</td>\n",
       "      <td id=\"T_bd23c_row1_col5\" class=\"data row1 col5\" >0.569536</td>\n",
       "      <td id=\"T_bd23c_row1_col6\" class=\"data row1 col6\" >0.748831</td>\n",
       "      <td id=\"T_bd23c_row1_col7\" class=\"data row1 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row1_col8\" class=\"data row1 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd23c_row2_col0\" class=\"data row2 col0\" >SE2019_fasttext_lstm</td>\n",
       "      <td id=\"T_bd23c_row2_col1\" class=\"data row2 col1\" >0.704598</td>\n",
       "      <td id=\"T_bd23c_row2_col2\" class=\"data row2 col2\" >0.697699</td>\n",
       "      <td id=\"T_bd23c_row2_col3\" class=\"data row2 col3\" >0.691701</td>\n",
       "      <td id=\"T_bd23c_row2_col4\" class=\"data row2 col4\" >0.693555</td>\n",
       "      <td id=\"T_bd23c_row2_col5\" class=\"data row2 col5\" >0.635384</td>\n",
       "      <td id=\"T_bd23c_row2_col6\" class=\"data row2 col6\" >0.751727</td>\n",
       "      <td id=\"T_bd23c_row2_col7\" class=\"data row2 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row2_col8\" class=\"data row2 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd23c_row3_col0\" class=\"data row3 col0\" >SE2019_fasttext_bilstm</td>\n",
       "      <td id=\"T_bd23c_row3_col1\" class=\"data row3 col1\" >0.711790</td>\n",
       "      <td id=\"T_bd23c_row3_col2\" class=\"data row3 col2\" >0.705390</td>\n",
       "      <td id=\"T_bd23c_row3_col3\" class=\"data row3 col3\" >0.706433</td>\n",
       "      <td id=\"T_bd23c_row3_col4\" class=\"data row3 col4\" >0.705855</td>\n",
       "      <td id=\"T_bd23c_row3_col5\" class=\"data row3 col5\" >0.664072</td>\n",
       "      <td id=\"T_bd23c_row3_col6\" class=\"data row3 col6\" >0.747638</td>\n",
       "      <td id=\"T_bd23c_row3_col7\" class=\"data row3 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row3_col8\" class=\"data row3 col8\" >2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd23c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd23c_row4_col0\" class=\"data row4 col0\" >SE2019_fasttext_gru</td>\n",
       "      <td id=\"T_bd23c_row4_col1\" class=\"data row4 col1\" >0.708965</td>\n",
       "      <td id=\"T_bd23c_row4_col2\" class=\"data row4 col2\" >0.702250</td>\n",
       "      <td id=\"T_bd23c_row4_col3\" class=\"data row4 col3\" >0.702471</td>\n",
       "      <td id=\"T_bd23c_row4_col4\" class=\"data row4 col4\" >0.702358</td>\n",
       "      <td id=\"T_bd23c_row4_col5\" class=\"data row4 col5\" >0.658014</td>\n",
       "      <td id=\"T_bd23c_row4_col6\" class=\"data row4 col6\" >0.746702</td>\n",
       "      <td id=\"T_bd23c_row4_col7\" class=\"data row4 col7\" >1653</td>\n",
       "      <td id=\"T_bd23c_row4_col8\" class=\"data row4 col8\" >2240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19dc079f490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'fasttext'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3f5ec_row1_col0, #T_3f5ec_row4_col1, #T_3f5ec_row4_col2, #T_3f5ec_row4_col3, #T_3f5ec_row4_col4 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3f5ec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f5ec_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3f5ec_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3f5ec_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_3f5ec_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3f5ec_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3f5ec_row0_col0\" class=\"data row0 col0\" >SE2019_glove_cnn</td>\n",
       "      <td id=\"T_3f5ec_row0_col1\" class=\"data row0 col1\" >0.709989</td>\n",
       "      <td id=\"T_3f5ec_row0_col2\" class=\"data row0 col2\" >0.707252</td>\n",
       "      <td id=\"T_3f5ec_row0_col3\" class=\"data row0 col3\" >0.709989</td>\n",
       "      <td id=\"T_3f5ec_row0_col4\" class=\"data row0 col4\" >0.707052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3f5ec_row1_col0\" class=\"data row1 col0\" >SE2019_glove_rnn</td>\n",
       "      <td id=\"T_3f5ec_row1_col1\" class=\"data row1 col1\" >0.661344</td>\n",
       "      <td id=\"T_3f5ec_row1_col2\" class=\"data row1 col2\" >0.661685</td>\n",
       "      <td id=\"T_3f5ec_row1_col3\" class=\"data row1 col3\" >0.661344</td>\n",
       "      <td id=\"T_3f5ec_row1_col4\" class=\"data row1 col4\" >0.661509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3f5ec_row2_col0\" class=\"data row2 col0\" >SE2019_glove_lstm</td>\n",
       "      <td id=\"T_3f5ec_row2_col1\" class=\"data row2 col1\" >0.732269</td>\n",
       "      <td id=\"T_3f5ec_row2_col2\" class=\"data row2 col2\" >0.746559</td>\n",
       "      <td id=\"T_3f5ec_row2_col3\" class=\"data row2 col3\" >0.732269</td>\n",
       "      <td id=\"T_3f5ec_row2_col4\" class=\"data row2 col4\" >0.734036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3f5ec_row3_col0\" class=\"data row3 col0\" >SE2019_glove_bilstm</td>\n",
       "      <td id=\"T_3f5ec_row3_col1\" class=\"data row3 col1\" >0.726328</td>\n",
       "      <td id=\"T_3f5ec_row3_col2\" class=\"data row3 col2\" >0.730623</td>\n",
       "      <td id=\"T_3f5ec_row3_col3\" class=\"data row3 col3\" >0.726328</td>\n",
       "      <td id=\"T_3f5ec_row3_col4\" class=\"data row3 col4\" >0.727574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f5ec_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3f5ec_row4_col0\" class=\"data row4 col0\" >SE2019_glove_gru</td>\n",
       "      <td id=\"T_3f5ec_row4_col1\" class=\"data row4 col1\" >0.756034</td>\n",
       "      <td id=\"T_3f5ec_row4_col2\" class=\"data row4 col2\" >0.754855</td>\n",
       "      <td id=\"T_3f5ec_row4_col3\" class=\"data row4 col3\" >0.756034</td>\n",
       "      <td id=\"T_3f5ec_row4_col4\" class=\"data row4 col4\" >0.755169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23b5dc99bd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 'SE2019'\n",
    "em = 'glove'\n",
    "get_result_nn([ds+\"_\"+em+\"_cnn\", ds+\"_\"+em+\"_rnn\", ds+\"_\"+em+\"_lstm\",ds+\"_\"+em+\"_bilstm\",ds+\"_\"+em+\"_gru\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_52f0a_row3_col1, #T_52f0a_row3_col2, #T_52f0a_row3_col3, #T_52f0a_row3_col4, #T_52f0a_row5_col0 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_52f0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_52f0a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_52f0a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_52f0a_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_52f0a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_52f0a_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_52f0a_row0_col0\" class=\"data row0 col0\" >dtc</td>\n",
       "      <td id=\"T_52f0a_row0_col1\" class=\"data row0 col1\" >0.749350</td>\n",
       "      <td id=\"T_52f0a_row0_col2\" class=\"data row0 col2\" >0.747932</td>\n",
       "      <td id=\"T_52f0a_row0_col3\" class=\"data row0 col3\" >0.749350</td>\n",
       "      <td id=\"T_52f0a_row0_col4\" class=\"data row0 col4\" >0.748249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_52f0a_row1_col0\" class=\"data row1 col0\" >dtc-tfid</td>\n",
       "      <td id=\"T_52f0a_row1_col1\" class=\"data row1 col1\" >0.743780</td>\n",
       "      <td id=\"T_52f0a_row1_col2\" class=\"data row1 col2\" >0.743531</td>\n",
       "      <td id=\"T_52f0a_row1_col3\" class=\"data row1 col3\" >0.743780</td>\n",
       "      <td id=\"T_52f0a_row1_col4\" class=\"data row1 col4\" >0.743649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_52f0a_row2_col0\" class=\"data row2 col0\" >dtc-w2v</td>\n",
       "      <td id=\"T_52f0a_row2_col1\" class=\"data row2 col1\" >0.586706</td>\n",
       "      <td id=\"T_52f0a_row2_col2\" class=\"data row2 col2\" >0.589898</td>\n",
       "      <td id=\"T_52f0a_row2_col3\" class=\"data row2 col3\" >0.586706</td>\n",
       "      <td id=\"T_52f0a_row2_col4\" class=\"data row2 col4\" >0.588024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_52f0a_row3_col0\" class=\"data row3 col0\" >svm</td>\n",
       "      <td id=\"T_52f0a_row3_col1\" class=\"data row3 col1\" >0.768659</td>\n",
       "      <td id=\"T_52f0a_row3_col2\" class=\"data row3 col2\" >0.767394</td>\n",
       "      <td id=\"T_52f0a_row3_col3\" class=\"data row3 col3\" >0.768659</td>\n",
       "      <td id=\"T_52f0a_row3_col4\" class=\"data row3 col4\" >0.766195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_52f0a_row4_col0\" class=\"data row4 col0\" >svm-tfid</td>\n",
       "      <td id=\"T_52f0a_row4_col1\" class=\"data row4 col1\" >0.746008</td>\n",
       "      <td id=\"T_52f0a_row4_col2\" class=\"data row4 col2\" >0.760112</td>\n",
       "      <td id=\"T_52f0a_row4_col3\" class=\"data row4 col3\" >0.746008</td>\n",
       "      <td id=\"T_52f0a_row4_col4\" class=\"data row4 col4\" >0.731861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_52f0a_row5_col0\" class=\"data row5 col0\" >svm-w2v</td>\n",
       "      <td id=\"T_52f0a_row5_col1\" class=\"data row5 col1\" >0.590048</td>\n",
       "      <td id=\"T_52f0a_row5_col2\" class=\"data row5 col2\" >0.611645</td>\n",
       "      <td id=\"T_52f0a_row5_col3\" class=\"data row5 col3\" >0.590048</td>\n",
       "      <td id=\"T_52f0a_row5_col4\" class=\"data row5 col4\" >0.461541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_52f0a_row6_col0\" class=\"data row6 col0\" >lr</td>\n",
       "      <td id=\"T_52f0a_row6_col1\" class=\"data row6 col1\" >0.684738</td>\n",
       "      <td id=\"T_52f0a_row6_col2\" class=\"data row6 col2\" >0.690064</td>\n",
       "      <td id=\"T_52f0a_row6_col3\" class=\"data row6 col3\" >0.684738</td>\n",
       "      <td id=\"T_52f0a_row6_col4\" class=\"data row6 col4\" >0.686326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_52f0a_row7_col0\" class=\"data row7 col0\" >lr-tfid</td>\n",
       "      <td id=\"T_52f0a_row7_col1\" class=\"data row7 col1\" >0.694393</td>\n",
       "      <td id=\"T_52f0a_row7_col2\" class=\"data row7 col2\" >0.697312</td>\n",
       "      <td id=\"T_52f0a_row7_col3\" class=\"data row7 col3\" >0.694393</td>\n",
       "      <td id=\"T_52f0a_row7_col4\" class=\"data row7 col4\" >0.695449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_52f0a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_52f0a_row8_col0\" class=\"data row8 col0\" >lr-w2v</td>\n",
       "      <td id=\"T_52f0a_row8_col1\" class=\"data row8 col1\" >0.708504</td>\n",
       "      <td id=\"T_52f0a_row8_col2\" class=\"data row8 col2\" >0.705758</td>\n",
       "      <td id=\"T_52f0a_row8_col3\" class=\"data row8 col3\" >0.708504</td>\n",
       "      <td id=\"T_52f0a_row8_col4\" class=\"data row8 col4\" >0.705809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f954ed6450>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
